{"title": "Dynamic Context Selection for Document-level Neural Machine Translation\n  via Reinforcement Learning", "abstract": "Document-level neural machine translation has yielded attractive\nimprovements. However, majority of existing methods roughly use all context\nsentences in a fixed scope. They neglect the fact that different source\nsentences need different sizes of context. To address this problem, we propose\nan effective approach to select dynamic context so that the document-level\ntranslation model can utilize the more useful selected context sentences to\nproduce better translations. Specifically, we introduce a selection module that\nis independent of the translation module to score each candidate context\nsentence. Then, we propose two strategies to explicitly select a variable\nnumber of context sentences and feed them into the translation module. We train\nthe two modules end-to-end via reinforcement learning. A novel reward is\nproposed to encourage the selection and utilization of dynamic context\nsentences. Experiments demonstrate that our approach can select adaptive\ncontext sentences for different source sentences, and significantly improves\nthe performance of document-level translation methods.", "published": "2020-10-09 01:05:32", "link": "http://arxiv.org/abs/2010.04314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Langsmith: An Interactive Academic Text Revision System", "abstract": "Despite the current diversity and inclusion initiatives in the academic\ncommunity, researchers with a non-native command of English still face\nsignificant obstacles when writing papers in English. This paper presents the\nLangsmith editor, which assists inexperienced, non-native researchers to write\nEnglish papers, especially in the natural language processing (NLP) field. Our\nsystem can suggest fluent, academic-style sentences to writers based on their\nrough, incomplete phrases or sentences. The system also encourages interaction\nbetween human writers and the computerized revision system. The experimental\nresults demonstrated that Langsmith helps non-native English-speaker students\nwrite papers in English. The system is available at https://emnlp-demo.editor.\nlangsmith.co.jp/.", "published": "2020-10-09 02:35:14", "link": "http://arxiv.org/abs/2010.04332v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constrained Decoding for Computationally Efficient Named Entity\n  Recognition Taggers", "abstract": "Current state-of-the-art models for named entity recognition (NER) are neural\nmodels with a conditional random field (CRF) as the final layer. Entities are\nrepresented as per-token labels with a special structure in order to decode\nthem into spans. Current work eschews prior knowledge of how the span encoding\nscheme works and relies on the CRF learning which transitions are illegal and\nwhich are not to facilitate global coherence. We find that by constraining the\noutput to suppress illegal transitions we can train a tagger with a\ncross-entropy loss twice as fast as a CRF with differences in F1 that are\nstatistically insignificant, effectively eliminating the need for a CRF. We\nanalyze the dynamics of tag co-occurrence to explain when these constraints are\nmost effective and provide open source implementations of our tagger in both\nPyTorch and TensorFlow.", "published": "2020-10-09 04:07:52", "link": "http://arxiv.org/abs/2010.04362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "iobes: A Library for Span-Level Processing", "abstract": "Many tasks in natural language processing, such as named entity recognition\nand slot-filling, involve identifying and labeling specific spans of text. In\norder to leverage common models, these tasks are often recast as sequence\nlabeling tasks. Each token is given a label and these labels are prefixed with\nspecial tokens such as B- or I-. After a model assigns labels to each token,\nthese prefixes are used to group the tokens into spans.\n  Properly parsing these annotations is critical for producing fair and\ncomparable metrics; however, despite its importance, there is not an\neasy-to-use, standardized, programmatically integratable library to help work\nwith span labeling. To remedy this, we introduce our open-source library,\niobes. iobes is used for parsing, converting, and processing spans represented\nas token level decisions.", "published": "2020-10-09 05:03:48", "link": "http://arxiv.org/abs/2010.04373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Q-learning with Language Model for Edit-based Unsupervised Summarization", "abstract": "Unsupervised methods are promising for abstractive text summarization in that\nthe parallel corpora is not required. However, their performance is still far\nfrom being satisfied, therefore research on promising solutions is on-going. In\nthis paper, we propose a new approach based on Q-learning with an edit-based\nsummarization. The method combines two key modules to form an Editorial Agent\nand Language Model converter (EALM). The agent predicts edit actions (e.t.,\ndelete, keep, and replace), and then the LM converter deterministically\ngenerates a summary on the basis of the action signals. Q-learning is leveraged\nto train the agent to produce proper edit actions. Experimental results show\nthat EALM delivered competitive performance compared with the previous\nencoder-decoder-based methods, even with truly zero paired data (i.e., no\nvalidation set). Defining the task as Q-learning enables us not only to develop\na competitive method but also to make the latest techniques in reinforcement\nlearning available for unsupervised summarization. We also conduct qualitative\nanalysis, providing insights into future study on unsupervised summarizers.", "published": "2020-10-09 05:47:00", "link": "http://arxiv.org/abs/2010.04379v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Token-level Adaptive Training for Neural Machine Translation", "abstract": "There exists a token imbalance phenomenon in natural language as different\ntokens appear with different frequencies, which leads to different learning\ndifficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT\nmodel usually adopts trivial equal-weighted objectives for target tokens with\ndifferent frequencies and tends to generate more high-frequency tokens and less\nlow-frequency tokens compared with the golden token distribution. However,\nlow-frequency tokens may carry critical semantic information that will affect\nthe translation quality once they are neglected. In this paper, we explored\ntarget token-level adaptive objectives based on token frequencies to assign\nappropriate weights for each target token during training. We aimed that those\nmeaningful but relatively low-frequency words could be assigned with larger\nweights in objectives to encourage the model to pay more attention to these\ntokens. Our method yields consistent improvements in translation quality on\nZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain\nmore low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases\ncompared with baseline, respectively. Further analyses show that our method can\nalso improve the lexical diversity of translation.", "published": "2020-10-09 05:55:05", "link": "http://arxiv.org/abs/2010.04380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text\n  Generation", "abstract": "AMR-to-text generation is used to transduce Abstract Meaning Representation\nstructures (AMR) into text. A key challenge in this task is to efficiently\nlearn effective graph representations. Previously, Graph Convolution Networks\n(GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to\ncapture non-local information and additionally, they follow a local\n(first-order) information aggregation scheme. To account for these issues,\nlarger and deeper GCN models are required to capture more complex interactions.\nIn this paper, we introduce a dynamic fusion mechanism, proposing Lightweight\nDynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local\ninteractions by synthesizing higher order information from the input graphs. We\nfurther develop two novel parameter saving strategies based on the group graph\nconvolutions and weight tied convolutions to reduce memory usage and model\ncomplexity. With the help of these strategies, we are able to train a model\nwith fewer parameters while maintaining the model capacity. Experiments\ndemonstrate that LDGCNs outperform state-of-the-art models on two benchmark\ndatasets for AMR-to-text generation with significantly fewer parameters.", "published": "2020-10-09 06:03:46", "link": "http://arxiv.org/abs/2010.04383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "gundapusunil at SemEval-2020 Task 9: Syntactic Semantic LSTM\n  Architecture for SENTIment Analysis of Code-MIXed Data", "abstract": "The phenomenon of mixing the vocabulary and syntax of multiple languages\nwithin the same utterance is called Code-Mixing. This is more evident in\nmultilingual societies. In this paper, we have developed a system for SemEval\n2020: Task 9 on Sentiment Analysis for Code-Mixed Social Media Text. Our system\nfirst generates two types of embeddings for the social media text. In those,\nthe first one is character level embeddings to encode the character level\ninformation and to handle the out-of-vocabulary entries and the second one is\nFastText word embeddings for capturing morphology and semantics. These two\nembeddings were passed to the LSTM network and the system outperformed the\nbaseline model.", "published": "2020-10-09 07:07:04", "link": "http://arxiv.org/abs/2010.04395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty-Aware Semantic Augmentation for Neural Machine Translation", "abstract": "As a sequence-to-sequence generation task, neural machine translation (NMT)\nnaturally contains intrinsic uncertainty, where a single sentence in one\nlanguage has multiple valid counterparts in the other. However, the dominant\nmethods for NMT only observe one of them from the parallel corpora for the\nmodel training but have to deal with adequate variations under the same meaning\nat inference. This leads to a discrepancy of the data distribution between the\ntraining and the inference phases. To address this problem, we propose\nuncertainty-aware semantic augmentation, which explicitly captures the\nuniversal semantic information among multiple semantically-equivalent source\nsentences and enhances the hidden representations with this information for\nbetter translations. Extensive experiments on various translation tasks reveal\nthat our approach significantly outperforms the strong baselines and the\nexisting methods.", "published": "2020-10-09 07:48:09", "link": "http://arxiv.org/abs/2010.04411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset", "abstract": "We present MLQE-PE, a new dataset for Machine Translation (MT) Quality\nEstimation (QE) and Automatic Post-Editing (APE). The dataset contains eleven\nlanguage pairs, with human labels for up to 10,000 translations per language\npair in the following formats: sentence-level direct assessments and\npost-editing effort, and word-level good/bad labels. It also contains the\npost-edited sentences, as well as titles of the articles where the sentences\nwere extracted from, and the neural MT models used to translate the text.", "published": "2020-10-09 10:12:02", "link": "http://arxiv.org/abs/2010.04480v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Level Language Identification in English Telugu Code Mixed Data", "abstract": "In a multilingual or sociolingual configuration Intra-sentential Code\nSwitching (ICS) or Code Mixing (CM) is frequently observed nowadays. In the\nworld, most of the people know more than one language. CM usage is especially\napparent in social media platforms. Moreover, ICS is particularly significant\nin the context of technology, health, and law where conveying the upcoming\ndevelopments are difficult in one's native language. In applications like\ndialog systems, machine translation, semantic parsing, shallow parsing, etc. CM\nand Code Switching pose serious challenges. To do any further advancement in\ncode-mixed data, the necessary step is Language Identification. In this paper,\nwe present a study of various models - Nave Bayes Classifier, Random Forest\nClassifier, Conditional Random Field (CRF), and Hidden Markov Model (HMM) for\nLanguage Identification in English - Telugu Code Mixed Data. Considering the\npaucity of resources in code mixed languages, we proposed the CRF model and HMM\nmodel for word level language identification. Our best performing system is\nCRF-based with an f1-score of 0.91.", "published": "2020-10-09 10:15:06", "link": "http://arxiv.org/abs/2010.04482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Online Back-Parsing for AMR-to-Text Generation", "abstract": "AMR-to-text generation aims to recover a text containing the same meaning as\nan input AMR graph. Current research develops increasingly powerful graph\nencoders to better represent AMR graphs, with decoders based on standard\nlanguage modeling being used to generate outputs. We propose a decoder that\nback predicts projected AMR graphs on the target sentence during text\ngeneration. As the result, our outputs can better preserve the input meaning\nthan standard decoders. Experiments on two AMR benchmarks show the superiority\nof our model over the previous state-of-the-art system based on graph\nTransformer.", "published": "2020-10-09 12:08:14", "link": "http://arxiv.org/abs/2010.04520v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Have We Achieved on Text Summarization?", "abstract": "Deep learning has led to significant improvement in text summarization with\nvarious methods investigated and improved ROUGE scores reported over the years.\nHowever, gaps still exist between summaries produced by automatic summarizers\nand human professionals. Aiming to gain more understanding of summarization\nsystems with respect to their strengths and limits on a fine-grained syntactic\nand semantic level, we consult the Multidimensional Quality Metric(MQM) and\nquantify 8 major sources of errors on 10 representative summarization models\nmanually. Primarily, we find that 1) under similar settings, extractive\nsummarizers are in general better than their abstractive counterparts thanks to\nstrength in faithfulness and factual-consistency; 2) milestone techniques such\nas copy, coverage and hybrid extractive/abstractive methods do bring specific\nimprovements but also demonstrate limitations; 3) pre-training techniques, and\nin particular sequence-to-sequence pre-training, are highly effective for\nimproving text summarization, with BART giving the best results.", "published": "2020-10-09 12:39:33", "link": "http://arxiv.org/abs/2010.04529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Denoising Multi-Source Weak Supervision for Neural Text Classification", "abstract": "We study the problem of learning neural text classifiers without using any\nlabeled data, but only easy-to-provide rules as multiple weak supervision\nsources. This problem is challenging because rule-induced weak labels are often\nnoisy and incomplete. To address these two challenges, we design a label\ndenoiser, which estimates the source reliability using a conditional soft\nattention mechanism and then reduces label noise by aggregating rule-annotated\nweak labels. The denoised pseudo labels then supervise a neural classifier to\npredicts soft labels for unmatched samples, which address the rule coverage\nissue. We evaluate our model on five benchmarks for sentiment, topic, and\nrelation classifications. The results show that our model outperforms\nstate-of-the-art weakly-supervised and semi-supervised methods consistently,\nand achieves comparable performance with fully-supervised methods even without\nany labeled data. Our code can be found at\nhttps://github.com/weakrules/Denoise-multi-weak-sources.", "published": "2020-10-09 13:57:52", "link": "http://arxiv.org/abs/2010.04582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recurrent babbling: evaluating the acquisition of grammar from limited\n  input data", "abstract": "Recurrent Neural Networks (RNNs) have been shown to capture various aspects\nof syntax from raw linguistic input. In most previous experiments, however,\nlearning happens over unrealistic corpora, which do not reflect the type and\namount of data a child would be exposed to. This paper remedies this state of\naffairs by training a Long Short-Term Memory network (LSTM) over a\nrealistically sized subset of child-directed input. The behaviour of the\nnetwork is analysed over time using a novel methodology which consists in\nquantifying the level of grammatical abstraction in the model's generated\noutput (its \"babbling\"), compared to the language it has been exposed to. We\nshow that the LSTM indeed abstracts new structuresas learning proceeds.", "published": "2020-10-09 15:30:05", "link": "http://arxiv.org/abs/2010.04637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction", "abstract": "Aspect-oriented Fine-grained Opinion Extraction (AFOE) aims at extracting\naspect terms and opinion terms from review in the form of opinion pairs or\nadditionally extracting sentiment polarity of aspect term to form opinion\ntriplet. Because of containing several opinion factors, the complete AFOE task\nis usually divided into multiple subtasks and achieved in the pipeline.\nHowever, pipeline approaches easily suffer from error propagation and\ninconvenience in real-world scenarios. To this end, we propose a novel tagging\nscheme, Grid Tagging Scheme (GTS), to address the AFOE task in an end-to-end\nfashion only with one unified grid tagging task. Additionally, we design an\neffective inference strategy on GTS to exploit mutual indication between\ndifferent opinion factors for more accurate extractions. To validate the\nfeasibility and compatibility of GTS, we implement three different GTS models\nrespectively based on CNN, BiLSTM, and BERT, and conduct experiments on the\naspect-oriented opinion pair extraction and opinion triplet extraction\ndatasets. Extensive experimental results indicate that GTS models outperform\nstrong baselines significantly and achieve state-of-the-art performance.", "published": "2020-10-09 15:33:50", "link": "http://arxiv.org/abs/2010.04640v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "High-order Semantic Role Labeling", "abstract": "Semantic role labeling is primarily used to identify predicates, arguments,\nand their semantic relationships. Due to the limitations of modeling methods\nand the conditions of pre-identified predicates, previous work has focused on\nthe relationships between predicates and arguments and the correlations between\narguments at most, while the correlations between predicates have been\nneglected for a long time. High-order features and structure learning were very\ncommon in modeling such correlations before the neural network era. In this\npaper, we introduce a high-order graph structure for the neural semantic role\nlabeling model, which enables the model to explicitly consider not only the\nisolated predicate-argument pairs but also the interaction between the\npredicate-argument pairs. Experimental results on 7 languages of the CoNLL-2009\nbenchmark show that the high-order structural learning techniques are\nbeneficial to the strong performing SRL models and further boost our baseline\nto achieve new state-of-the-art results.", "published": "2020-10-09 15:33:54", "link": "http://arxiv.org/abs/2010.04641v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Case Study: Deontological Ethics in NLP", "abstract": "Recent work in natural language processing (NLP) has focused on ethical\nchallenges such as understanding and mitigating bias in data and algorithms;\nidentifying objectionable content like hate speech, stereotypes and offensive\nlanguage; and building frameworks for better system design and data handling\npractices. However, there has been little discussion about the ethical\nfoundations that underlie these efforts. In this work, we study one ethical\ntheory, namely deontological ethics, from the perspective of NLP. In\nparticular, we focus on the generalization principle and the respect for\nautonomy through informed consent. We provide four case studies to demonstrate\nhow these principles can be used with NLP systems. We also recommend directions\nto avoid the ethical issues in these systems.", "published": "2020-10-09 16:04:51", "link": "http://arxiv.org/abs/2010.04658v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Context-Free Languages with Nondeterministic Stack RNNs", "abstract": "We present a differentiable stack data structure that simultaneously and\ntractably encodes an exponential number of stack configurations, based on\nLang's algorithm for simulating nondeterministic pushdown automata. We call the\ncombination of this data structure with a recurrent neural network (RNN)\ncontroller a Nondeterministic Stack RNN. We compare our model against existing\nstack RNNs on various formal languages, demonstrating that our model converges\nmore reliably to algorithmic behavior on deterministic tasks, and achieves\nlower cross-entropy on inherently nondeterministic tasks.", "published": "2020-10-09 16:48:41", "link": "http://arxiv.org/abs/2010.04674v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty over Uncertainty: Investigating the Assumptions,\n  Annotations, and Text Measurements of Economic Policy Uncertainty", "abstract": "Methods and applications are inextricably linked in science, and in\nparticular in the domain of text-as-data. In this paper, we examine one such\ntext-as-data application, an established economic index that measures economic\npolicy uncertainty from keyword occurrences in news. This index, which is shown\nto correlate with firm investment, employment, and excess market returns, has\nhad substantive impact in both the private sector and academia. Yet, as we\nrevisit and extend the original authors' annotations and text measurements we\nfind interesting text-as-data methodological research questions: (1) Are\nannotator disagreements a reflection of ambiguity in language? (2) Do\nalternative text measurements correlate with one another and with measures of\nexternal predictive validity? We find for this application (1) some annotator\ndisagreements of economic policy uncertainty can be attributed to ambiguity in\nlanguage, and (2) switching measurements from keyword-matching to supervised\nmachine learning classifiers results in low correlation, a concerning\nimplication for the validity of the index.", "published": "2020-10-09 17:50:29", "link": "http://arxiv.org/abs/2010.04706v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Pronounce Chinese Without a Pronunciation Dictionary", "abstract": "We demonstrate a program that learns to pronounce Chinese text in Mandarin,\nwithout a pronunciation dictionary. From non-parallel streams of Chinese\ncharacters and Chinese pinyin syllables, it establishes a many-to-many mapping\nbetween characters and pronunciations. Using unsupervised methods, the program\neffectively deciphers writing into speech. Its token-level\ncharacter-to-syllable accuracy is 89%, which significantly exceeds the 22%\naccuracy of prior work.", "published": "2020-10-09 18:03:49", "link": "http://arxiv.org/abs/2010.04744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solving Historical Dictionary Codes with a Neural Language Model", "abstract": "We solve difficult word-based substitution codes by constructing a decoding\nlattice and searching that lattice with a neural language model. We apply our\nmethod to a set of enciphered letters exchanged between US Army General James\nWilkinson and agents of the Spanish Crown in the late 1700s and early 1800s,\nobtained from the US Library of Congress. We are able to decipher 75.1% of the\ncipher-word tokens correctly.", "published": "2020-10-09 18:04:05", "link": "http://arxiv.org/abs/2010.04746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MEEP: An Open-Source Platform for Human-Human Dialog Collection and\n  End-to-End Agent Training", "abstract": "We create a new task-oriented dialog platform (MEEP) where agents are given\nconsiderable freedom in terms of utterances and API calls, but are constrained\nto work within a push-button environment. We include facilities for collecting\nhuman-human dialog corpora, and for training automatic agents in an end-to-end\nfashion. We demonstrate MEEP with a dialog assistant that lets users specify\ntrip destinations.", "published": "2020-10-09 18:04:17", "link": "http://arxiv.org/abs/2010.04747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Cross-Linguistic Adjective Ordering Tendencies with a\n  Latent-Variable Model", "abstract": "Across languages, multiple consecutive adjectives modifying a noun (e.g. \"the\nbig red dog\") follow certain unmarked ordering rules. While explanatory\naccounts have been put forward, much of the work done in this area has relied\nprimarily on the intuitive judgment of native speakers, rather than on corpus\ndata. We present the first purely corpus-driven model of multi-lingual\nadjective ordering in the form of a latent-variable model that can accurately\norder adjectives across 24 different languages, even when the training and\ntesting languages are different. We utilize this novel statistical model to\nprovide strong converging evidence for the existence of universal,\ncross-linguistic, hierarchical adjective ordering tendencies.", "published": "2020-10-09 18:27:55", "link": "http://arxiv.org/abs/2010.04755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactually-Augmented SNLI Training Data Does Not Yield Better\n  Generalization Than Unaugmented Data", "abstract": "A growing body of work shows that models exploit annotation artifacts to\nachieve state-of-the-art performance on standard crowdsourced\nbenchmarks---datasets collected from crowdworkers to create an evaluation\ntask---while still failing on out-of-domain examples for the same task. Recent\nwork has explored the use of counterfactually-augmented data---data built by\nminimally editing a set of seed examples to yield counterfactual labels---to\naugment training data associated with these benchmarks and build more robust\nclassifiers that generalize better. However, Khashabi et al. (2020) find that\nthis type of augmentation yields little benefit on reading comprehension tasks\nwhen controlling for dataset size and cost of collection. We build upon this\nwork by using English natural language inference data to test model\ngeneralization and robustness and find that models trained on a\ncounterfactually-augmented SNLI dataset do not generalize better than\nunaugmented datasets of similar size and that counterfactual augmentation can\nhurt performance, yielding models that are less robust to challenge examples.\nCounterfactual augmentation of natural language understanding data through\nstandard crowdsourcing techniques does not appear to be an effective way of\ncollecting training data and further innovation is required to make this\ngeneral line of work viable.", "published": "2020-10-09 18:44:02", "link": "http://arxiv.org/abs/2010.04762v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoQA: From Databases To QA Semantic Parsers With Only Synthetic\n  Training Data", "abstract": "We propose AutoQA, a methodology and toolkit to generate semantic parsers\nthat answer questions on databases, with no manual effort. Given a database\nschema and its data, AutoQA automatically generates a large set of high-quality\nquestions for training that covers different database operations. It uses\nautomatic paraphrasing combined with template-based parsing to find alternative\nexpressions of an attribute in different parts of speech. It also uses a novel\nfiltered auto-paraphraser to generate correct paraphrases of entire sentences.\nWe apply AutoQA to the Schema2QA dataset and obtain an average logical form\naccuracy of 62.9% when tested on natural questions, which is only 6.4% lower\nthan a model trained with expert natural language annotations and paraphrase\ndata collected from crowdworkers. To demonstrate the generality of AutoQA, we\nalso apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy,\n16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower\nthan the same model trained with human data.", "published": "2020-10-09 21:06:57", "link": "http://arxiv.org/abs/2010.04806v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Classification as Two-way Span-Prediction", "abstract": "The current supervised relation classification (RC) task uses a single\nembedding to represent the relation between a pair of entities. We argue that a\nbetter approach is to treat the RC task as span-prediction (SP) problem,\nsimilar to Question answering (QA). We present a span-prediction based system\nfor RC and evaluate its performance compared to the embedding based system. We\ndemonstrate that the supervised SP objective works significantly better then\nthe standard classification based objective. We achieve state-of-the-art\nresults on the TACRED and SemEval task 8 datasets.", "published": "2020-10-09 22:23:21", "link": "http://arxiv.org/abs/2010.04829v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mere account mein kitna balance hai? -- On building voice enabled\n  Banking Services for Multilingual Communities", "abstract": "Tremendous progress in speech and language processing has brought language\ntechnologies closer to daily human life. Voice technology has the potential to\nact as a horizontal enabling layer across all aspects of digitization. It is\nespecially beneficial to rural communities in scenarios like a pandemic. In\nthis work we present our initial exploratory work towards one such direction --\nbuilding voice enabled banking services for multilingual societies. Speech\ninteraction for typical banking transactions in multilingual communities\ninvolves the presence of filled pauses and is characterized by Code Mixing.\nCode Mixing is a phenomenon where lexical items from one language are embedded\nin the utterance of another. Therefore speech systems deployed for banking\napplications should be able to process such content. In our work we investigate\nvarious training strategies for building speech based intent recognition\nsystems. We present our results using a Naive Bayes classifier on approximate\nacoustic phone units using the Allosaurus library.", "published": "2020-10-09 01:20:09", "link": "http://arxiv.org/abs/2010.16411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plug-and-Play Conversational Models", "abstract": "There has been considerable progress made towards conversational models that\ngenerate coherent and fluent responses; however, this often involves training\nlarge language models on large dialogue datasets, such as Reddit. These large\nconversational models provide little control over the generated responses, and\nthis control is further limited in the absence of annotated conversational\ndatasets for attribute specific generation that can be used for fine-tuning the\nmodel. In this paper, we first propose and evaluate plug-and-play methods for\ncontrollable response generation, which does not require dialogue specific\ndatasets and does not rely on fine-tuning a large model. While effective, the\ndecoding procedure induces considerable computational overhead, rendering the\nconversational model unsuitable for interactive usage. To overcome this, we\nintroduce an approach that does not require further computation at decoding\ntime, while also does not require any fine-tuning of a large language model. We\ndemonstrate, through extensive automatic and human evaluation, a high degree of\ncontrol over the generated conversational responses with regard to multiple\ndesired attributes, while being fluent.", "published": "2020-10-09 03:17:51", "link": "http://arxiv.org/abs/2010.04344v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Event Representation with Sequential, Semi-Supervised Discrete Variables", "abstract": "Within the context of event modeling and understanding, we propose a new\nmethod for neural sequence modeling that takes partially-observed sequences of\ndiscrete, external knowledge into account. We construct a sequential neural\nvariational autoencoder, which uses Gumbel-Softmax reparametrization within a\ncarefully defined encoder, to allow for successful backpropagation during\ntraining. The core idea is to allow semi-supervised external discrete knowledge\nto guide, but not restrict, the variational latent parameters during training.\nOur experiments indicate that our approach not only outperforms multiple\nbaselines and the state-of-the-art in narrative script induction, but also\nconverges more quickly.", "published": "2020-10-09 04:05:49", "link": "http://arxiv.org/abs/2010.04361v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Pragmatically Informative Color Generation by Grounding Contextual\n  Modifiers", "abstract": "Grounding language in contextual information is crucial for fine-grained\nnatural language understanding. One important task that involves grounding\ncontextual modifiers is color generation. Given a reference color \"green\", and\na modifier \"bluey\", how does one generate a color that could represent \"bluey\ngreen\"? We propose a computational pragmatics model that formulates this color\ngeneration task as a recursive game between speakers and listeners. In our\nmodel, a pragmatic speaker reasons about the inferences that a listener would\nmake, and thus generates a modified color that is maximally informative to help\nthe listener recover the original referents. In this paper, we show that\nincorporating pragmatic information provides significant improvements in\nperformance compared with other state-of-the-art deep learning models where\npragmatic inference and flexibility in representing colors from a large\ncontinuous space are lacking. Our model has an absolute 98% increase in\nperformance for the test cases where the reference colors are unseen during\ntraining, and an absolute 40% increase in performance for the test cases where\nboth the reference colors and the modifiers are unseen during training.", "published": "2020-10-09 04:54:54", "link": "http://arxiv.org/abs/2010.04372v1", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "Self-Paced Learning for Neural Machine Translation", "abstract": "Recent studies have proven that the training of neural machine translation\n(NMT) can be facilitated by mimicking the learning process of humans.\nNevertheless, achievements of such kind of curriculum learning rely on the\nquality of artificial schedule drawn up with the handcrafted features, e.g.\nsentence length or word rarity. We ameliorate this procedure with a more\nflexible manner by proposing self-paced learning, where NMT model is allowed to\n1) automatically quantify the learning confidence over training examples; and\n2) flexibly govern its learning via regulating the loss in each iteration step.\nExperimental results over multiple translation tasks demonstrate that the\nproposed model yields better performance than strong baselines and those models\ntrained with human-designed curricula on both translation quality and\nconvergence speed.", "published": "2020-10-09 11:33:16", "link": "http://arxiv.org/abs/2010.04505v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring What Counts: The case of Rumour Stance Classification", "abstract": "Stance classification can be a powerful tool for understanding whether and\nwhich users believe in online rumours. The task aims to automatically predict\nthe stance of replies towards a given rumour, namely support, deny, question,\nor comment. Numerous methods have been proposed and their performance compared\nin the RumourEval shared tasks in 2017 and 2019. Results demonstrated that this\nis a challenging problem since naturally occurring rumour stance data is highly\nimbalanced. This paper specifically questions the evaluation metrics used in\nthese shared tasks. We re-evaluate the systems submitted to the two RumourEval\ntasks and show that the two widely adopted metrics -- accuracy and macro-F1 --\nare not robust for the four-class imbalanced task of rumour stance\nclassification, as they wrongly favour systems with highly skewed accuracy\ntowards the majority class. To overcome this problem, we propose new evaluation\nmetrics for rumour stance detection. These are not only robust to imbalanced\ndata but also score higher systems that are capable of recognising the two most\ninformative minority classes (support and deny).", "published": "2020-10-09 12:45:27", "link": "http://arxiv.org/abs/2010.04532v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scaling Systematic Literature Reviews with Machine Learning Pipelines", "abstract": "Systematic reviews, which entail the extraction of data from large numbers of\nscientific documents, are an ideal avenue for the application of machine\nlearning. They are vital to many fields of science and philanthropy, but are\nvery time-consuming and require experts. Yet the three main stages of a\nsystematic review are easily done automatically: searching for documents can be\ndone via APIs and scrapers, selection of relevant documents can be done via\nbinary classification, and extraction of data can be done via\nsequence-labelling classification. Despite the promise of automation for this\nfield, little research exists that examines the various ways to automate each\nof these tasks. We construct a pipeline that automates each of these aspects,\nand experiment with many human-time vs. system quality trade-offs. We test the\nability of classifiers to work well on small amounts of data and to generalise\nto data from countries not represented in the training data. We test different\ntypes of data extraction with varying difficulty in annotation, and five\ndifferent neural architectures to do the extraction. We find that we can get\nsurprising accuracy and generalisability of the whole pipeline system with only\n2 weeks of human-expert annotation, which is only 15% of the time it takes to\ndo the whole review manually and can be repeated and extended to new data with\nno additional effort.", "published": "2020-10-09 16:19:42", "link": "http://arxiv.org/abs/2010.04665v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Recursive Top-Down Production for Sentence Generation with Latent Trees", "abstract": "We model the recursive production property of context-free grammars for\nnatural and synthetic languages. To this end, we present a dynamic programming\nalgorithm that marginalises over latent binary tree structures with $N$ leaves,\nallowing us to compute the likelihood of a sequence of $N$ tokens under a\nlatent tree model, which we maximise to train a recursive neural function. We\ndemonstrate performance on two synthetic tasks: SCAN (Lake and Baroni, 2017),\nwhere it outperforms previous models on the LENGTH split, and English question\nformation (McCoy et al., 2020), where it performs comparably to decoders with\nthe ground-truth tree structure. We also present experimental results on\nGerman-English translation on the Multi30k dataset (Elliott et al., 2016), and\nqualitatively analyse the induced tree structures our model learns for the SCAN\ntasks and the German-English translation task.", "published": "2020-10-09 17:47:16", "link": "http://arxiv.org/abs/2010.04704v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChrEn: Cherokee-English Machine Translation for Endangered Language\n  Revitalization", "abstract": "Cherokee is a highly endangered Native American language spoken by the\nCherokee people. The Cherokee culture is deeply embedded in its language.\nHowever, there are approximately only 2,000 fluent first language Cherokee\nspeakers remaining in the world, and the number is declining every year. To\nhelp save this endangered language, we introduce ChrEn, a Cherokee-English\nparallel dataset, to facilitate machine translation research between Cherokee\nand English. Compared to some popular machine translation language pairs, ChrEn\nis extremely low-resource, only containing 14k sentence pairs in total. We\nsplit our parallel data in ways that facilitate both in-domain and\nout-of-domain evaluation. We also collect 5k Cherokee monolingual data to\nenable semi-supervised learning. Besides these datasets, we propose several\nCherokee-English and English-Cherokee machine translation systems. We compare\nSMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems;\nsupervised versus semi-supervised (via language model, back-translation, and\nBERT/Multilingual-BERT) methods; as well as transfer learning versus\nmultilingual joint training with 4 other languages. Our best results are\n15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/EnChr\ntranslations, respectively, and we hope that our dataset and systems will\nencourage future work by the community for Cherokee language revitalization.\nOur data, code, and demo will be publicly available at\nhttps://github.com/ZhangShiyue/ChrEn", "published": "2020-10-09 20:28:06", "link": "http://arxiv.org/abs/2010.04791v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Task-Level Dialogue Composition of Generative Transformer Model", "abstract": "Task-oriented dialogue systems help users accomplish tasks such as booking a\nmovie ticket and ordering food via conversation. Generative models\nparameterized by a deep neural network are widely used for next turn response\ngeneration in such systems. It is natural for users of the system to want to\naccomplish multiple tasks within the same conversation, but the ability of\ngenerative models to compose multiple tasks is not well studied. In this work,\nwe begin by studying the effect of training human-human task-oriented dialogues\ntowards improving the ability to compose multiple tasks on Transformer\ngenerative models. To that end, we propose and explore two solutions: (1)\ncreating synthetic multiple task dialogue data for training from human-human\nsingle task dialogue and (2) forcing the encoder representation to be invariant\nto single and multiple task dialogues using an auxiliary loss. The results from\nour experiments highlight the difficulty of even the sophisticated variant of\ntransformer model in learning to compose multiple tasks from single task\ndialogues.", "published": "2020-10-09 22:10:03", "link": "http://arxiv.org/abs/2010.04826v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conformal retrofitting via Riemannian manifolds: distilling\n  task-specific graphs into pretrained embeddings", "abstract": "Pretrained (language) embeddings are versatile, task-agnostic feature\nrepresentations of entities, like words, that are central to many machine\nlearning applications. These representations can be enriched through\nretrofitting, a class of methods that incorporate task-specific domain\nknowledge encoded as a graph over a subset of these entities. However, existing\nretrofitting algorithms face two limitations: they overfit the observed graph\nby failing to represent relationships with missing entities; and they underfit\nthe observed graph by only learning embeddings in Euclidean manifolds, which\ncannot faithfully represent even simple tree-structured or cyclic graphs. We\naddress these problems with two key contributions: (i) we propose a novel\nregularizer, a conformality regularizer, that preserves local geometry from the\npretrained embeddings---enabling generalization to missing entities and (ii) a\nnew Riemannian feedforward layer that learns to map pre-trained embeddings onto\na non-Euclidean manifold that can better represent the entire graph. Through\nexperiments on WordNet, we demonstrate that the conformality regularizer\nprevents even existing (Euclidean-only) methods from overfitting on link\nprediction for missing entities, and---together with the Riemannian feedforward\nlayer---learns non-Euclidean embeddings that outperform them.", "published": "2020-10-09 23:06:57", "link": "http://arxiv.org/abs/2010.04842v1", "categories": ["cs.LG", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "How Can Self-Attention Networks Recognize Dyck-n Languages?", "abstract": "We focus on the recognition of Dyck-n ($\\mathcal{D}_n$) languages with\nself-attention (SA) networks, which has been deemed to be a difficult task for\nthese networks. We compare the performance of two variants of SA, one with a\nstarting symbol (SA$^+$) and one without (SA$^-$). Our results show that SA$^+$\nis able to generalize to longer sequences and deeper dependencies. For\n$\\mathcal{D}_2$, we find that SA$^-$ completely breaks down on long sequences\nwhereas the accuracy of SA$^+$ is 58.82$\\%$. We find attention maps learned by\n$\\text{SA}{^+}$ to be amenable to interpretation and compatible with a\nstack-based language recognizer. Surprisingly, the performance of SA networks\nis at par with LSTMs, which provides evidence on the ability of SA to learn\nhierarchies without recursion.", "published": "2020-10-09 00:03:17", "link": "http://arxiv.org/abs/2010.04303v1", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NutCracker at WNUT-2020 Task 2: Robustly Identifying Informative\n  COVID-19 Tweets using Ensembling and Adversarial Training", "abstract": "We experiment with COVID-Twitter-BERT and RoBERTa models to identify\ninformative COVID-19 tweets. We further experiment with adversarial training to\nmake our models robust. The ensemble of COVID-Twitter-BERT and RoBERTa obtains\na F1-score of 0.9096 (on the positive class) on the test data of WNUT-2020 Task\n2 and ranks 1st on the leaderboard. The ensemble of the models trained using\nadversarial training also produces similar result.", "published": "2020-10-09 02:46:51", "link": "http://arxiv.org/abs/2010.04335v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Style Attuned Pre-training and Parameter Efficient Fine-tuning for\n  Spoken Language Understanding", "abstract": "Neural models have yielded state-of-the-art results in deciphering spoken\nlanguage understanding (SLU) problems; however, these models require a\nsignificant amount of domain-specific labeled examples for training, which is\nprohibitively expensive. While pre-trained language models like BERT have been\nshown to capture a massive amount of knowledge by learning from unlabeled\ncorpora and solve SLU using fewer labeled examples for adaption, the encoding\nof knowledge is implicit and agnostic to downstream tasks. Such encoding\nresults in model inefficiencies in parameter usage: an entirely new model is\nrequired for every domain. To address these challenges, we introduce a novel\nSLU framework, comprising a conversational language modeling (CLM) pre-training\ntask and a light encoder architecture. The CLM pre-training enables networks to\ncapture the representation of the language in conversation style with the\npresence of ASR errors. The light encoder architecture separates the shared\npre-trained networks from the mappings of generally encoded knowledge to\nspecific domains of SLU, allowing for the domain adaptation to be performed\nsolely at the light encoder and thus increasing efficiency. With the framework,\nwe match the performance of state-of-the-art SLU results on Alexa internal\ndatasets and on two public ones (ATIS, SNIPS), adding only 4.4% parameters per\ntask.", "published": "2020-10-09 03:53:37", "link": "http://arxiv.org/abs/2010.04355v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hate is the New Infodemic: A Topic-aware Modeling of Hate Speech\n  Diffusion on Twitter", "abstract": "Online hate speech, particularly over microblogging platforms like Twitter,\nhas emerged as arguably the most severe issue of the past decade. Several\ncountries have reported a steep rise in hate crimes infuriated by malicious\nhate campaigns. While the detection of hate speech is one of the emerging\nresearch areas, the generation and spread of topic-dependent hate in the\ninformation network remain under-explored. In this work, we focus on exploring\nuser behaviour, which triggers the genesis of hate speech on Twitter and how it\ndiffuses via retweets. We crawl a large-scale dataset of tweets, retweets, user\nactivity history, and follower networks, comprising over 161 million tweets\nfrom more than $41$ million unique users. We also collect over 600k\ncontemporary news articles published online. We characterize different signals\nof information that govern these dynamics. Our analyses differentiate the\ndiffusion dynamics in the presence of hate from usual information diffusion.\nThis motivates us to formulate the modelling problem in a topic-aware setting\nwith real-world knowledge. For predicting the initiation of hate speech for any\ngiven hashtag, we propose multiple feature-rich models, with the best\nperforming one achieving a macro F1 score of 0.65. Meanwhile, to predict the\nretweet dynamics on Twitter, we propose RETINA, a novel neural architecture\nthat incorporates exogenous influence using scaled dot-product attention.\nRETINA achieves a macro F1-score of 0.85, outperforming multiple\nstate-of-the-art models. Our analysis reveals the superlative power of RETINA\nto predict the retweet dynamics of hateful content compared to the existing\ndiffusion models.", "published": "2020-10-09 05:43:08", "link": "http://arxiv.org/abs/2010.04377v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Sentence, Phrase, and Triple Annotations to Build a Knowledge Graph of\n  Natural Language Processing Contributions -- A Trial Dataset", "abstract": "Purpose: The aim of this work is to normalize the NLPCONTRIBUTIONS scheme\n(henceforward, NLPCONTRIBUTIONGRAPH) to structure, directly from article\nsentences, the contributions information in Natural Language Processing (NLP)\nscholarly articles via a two-stage annotation methodology: 1) pilot stage - to\ndefine the scheme (described in prior work); and 2) adjudication stage - to\nnormalize the graphing model (the focus of this paper).\n  Design/methodology/approach: We re-annotate, a second time, the\ncontributions-pertinent information across 50 prior-annotated NLP scholarly\narticles in terms of a data pipeline comprising: contribution-centered\nsentences, phrases, and triple statements. To this end, specifically, care was\ntaken in the adjudication annotation stage to reduce annotation noise while\nformulating the guidelines for our proposed novel NLP contributions structuring\nand graphing scheme.\n  Findings: The application of NLPCONTRIBUTIONGRAPH on the 50 articles resulted\nfinally in a dataset of 900 contribution-focused sentences, 4,702\ncontribution-information-centered phrases, and 2,980 surface-structured\ntriples. The intra-annotation agreement between the first and second stages, in\nterms of F1, was 67.92% for sentences, 41.82% for phrases, and 22.31% for\ntriple statements indicating that with increased granularity of the\ninformation, the annotation decision variance is greater.\n  Practical Implications: We demonstrate NLPCONTRIBUTIONGRAPH data integrated\ninto the Open Research Knowledge Graph (ORKG), a next-generation KG-based\ndigital library with intelligent computations enabled over structured scholarly\nknowledge, as a viable aid to assist researchers in their day-to-day tasks.", "published": "2020-10-09 06:45:35", "link": "http://arxiv.org/abs/2010.04388v3", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Survey of Knowledge-Enhanced Text Generation", "abstract": "The goal of text generation is to make machines express in human language. It\nis one of the most important yet challenging tasks in natural language\nprocessing (NLP). Since 2014, various neural encoder-decoder models pioneered\nby Seq2Seq have been proposed to achieve the goal by learning to map input text\nto output text. However, the input text alone often provides limited knowledge\nto generate the desired output, so the performance of text generation is still\nfar from satisfaction in many real-world scenarios. To address this issue,\nresearchers have considered incorporating various forms of knowledge beyond the\ninput text into the generation models. This research direction is known as\nknowledge-enhanced text generation. In this survey, we present a comprehensive\nreview of the research on knowledge enhanced text generation over the past five\nyears. The main content includes two parts: (i) general methods and\narchitectures for integrating knowledge into text generation; (ii) specific\ntechniques and applications according to different forms of knowledge data.\nThis survey can have broad audiences, researchers and practitioners, in\nacademia and industry.", "published": "2020-10-09 06:46:46", "link": "http://arxiv.org/abs/2010.04389v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Baseline System of Voice Conversion Challenge 2020 with Cyclic\n  Variational Autoencoder and Parallel WaveGAN", "abstract": "In this paper, we present a description of the baseline system of Voice\nConversion Challenge (VCC) 2020 with a cyclic variational autoencoder\n(CycleVAE) and Parallel WaveGAN (PWG), i.e., CycleVAEPWG. CycleVAE is a\nnonparallel VAE-based voice conversion that utilizes converted acoustic\nfeatures to consider cyclically reconstructed spectra during optimization. On\nthe other hand, PWG is a non-autoregressive neural vocoder that is based on a\ngenerative adversarial network for a high-quality and fast waveform generator.\nIn practice, the CycleVAEPWG system can be straightforwardly developed with the\nVCC 2020 dataset using a unified model for both Task 1 (intralingual) and Task\n2 (cross-lingual), where our open-source implementation is available at\nhttps://github.com/bigpon/vcc20_baseline_cyclevae. The results of VCC 2020 have\ndemonstrated that the CycleVAEPWG baseline achieves the following: 1) a mean\nopinion score (MOS) of 2.87 in naturalness and a speaker similarity percentage\n(Sim) of 75.37% for Task 1, and 2) a MOS of 2.56 and a Sim of 56.46% for Task\n2, showing an approximately or nearly average score for naturalness and an\nabove average score for speaker similarity.", "published": "2020-10-09 08:25:38", "link": "http://arxiv.org/abs/2010.04429v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multichannel Generative Language Model: Learning All Possible\n  Factorizations Within and Across Channels", "abstract": "A channel corresponds to a viewpoint or transformation of an underlying\nmeaning. A pair of parallel sentences in English and French express the same\nunderlying meaning, but through two separate channels corresponding to their\nlanguages. In this work, we present the Multichannel Generative Language Model\n(MGLM). MGLM is a generative joint distribution model over channels. MGLM\nmarginalizes over all possible factorizations within and across all channels.\nMGLM endows flexible inference, including unconditional generation, conditional\ngeneration (where 1 channel is observed and other channels are generated), and\npartially observed generation (where incomplete observations are spread across\nall the channels). We experiment with the Multi30K dataset containing English,\nFrench, Czech, and German. We demonstrate experiments with unconditional,\nconditional, and partially conditional generation. We provide qualitative\nsamples sampled unconditionally from the generative joint distribution. We also\nquantitatively analyze the quality-diversity trade-offs and find MGLM\noutperforms traditional bilingual discriminative models.", "published": "2020-10-09 08:52:24", "link": "http://arxiv.org/abs/2010.04438v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The NU Voice Conversion System for the Voice Conversion Challenge 2020:\n  On the Effectiveness of Sequence-to-sequence Models and Autoregressive Neural\n  Vocoders", "abstract": "In this paper, we present the voice conversion (VC) systems developed at\nNagoya University (NU) for the Voice Conversion Challenge 2020 (VCC2020). We\naim to determine the effectiveness of two recent significant technologies in\nVC: sequence-to-sequence (seq2seq) models and autoregressive (AR) neural\nvocoders. Two respective systems were developed for the two tasks in the\nchallenge: for task 1, we adopted the Voice Transformer Network, a\nTransformer-based seq2seq VC model, and extended it with synthetic parallel\ndata to tackle nonparallel data; for task 2, we used the frame-based cyclic\nvariational autoencoder (CycleVAE) to model the spectral features of a speech\nwaveform and the AR WaveNet vocoder with additional fine-tuning. By comparing\nwith the baseline systems, we confirmed that the seq2seq modeling can improve\nthe conversion similarity and that the use of AR vocoders can improve the\nnaturalness of the converted speech.", "published": "2020-10-09 09:19:37", "link": "http://arxiv.org/abs/2010.04446v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Top-Rank-Focused Adaptive Vote Collection for the Evaluation of\n  Domain-Specific Semantic Models", "abstract": "The growth of domain-specific applications of semantic models, boosted by the\nrecent achievements of unsupervised embedding learning algorithms, demands\ndomain-specific evaluation datasets. In many cases, content-based recommenders\nbeing a prime example, these models are required to rank words or texts\naccording to their semantic relatedness to a given concept, with particular\nfocus on top ranks. In this work, we give a threefold contribution to address\nthese requirements: (i) we define a protocol for the construction, based on\nadaptive pairwise comparisons, of a relatedness-based evaluation dataset\ntailored on the available resources and optimized to be particularly accurate\nin top-rank evaluation; (ii) we define appropriate metrics, extensions of\nwell-known ranking correlation coefficients, to evaluate a semantic model via\nthe aforementioned dataset by taking into account the greater significance of\ntop ranks. Finally, (iii) we define a stochastic transitivity model to simulate\nsemantic-driven pairwise comparisons, which confirms the effectiveness of the\nproposed dataset construction protocol.", "published": "2020-10-09 10:20:58", "link": "http://arxiv.org/abs/2010.04486v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML", "68T50 (Primary), 62P99, 60G15 (Secondary)", "I.2.7; G.3; I.6.3; I.2.1; J.4"], "primary_category": "cs.CL"}
{"title": "Toxic Language Detection in Social Media for Brazilian Portuguese: New\n  Dataset and Multilingual Analysis", "abstract": "Hate speech and toxic comments are a common concern of social media platform\nusers. Although these comments are, fortunately, the minority in these\nplatforms, they are still capable of causing harm. Therefore, identifying these\ncomments is an important task for studying and preventing the proliferation of\ntoxicity in social media. Previous work in automatically detecting toxic\ncomments focus mainly in English, with very few work in languages like\nBrazilian Portuguese. In this paper, we propose a new large-scale dataset for\nBrazilian Portuguese with tweets annotated as either toxic or non-toxic or in\ndifferent types of toxicity. We present our dataset collection and annotation\nprocess, where we aimed to select candidates covering multiple demographic\ngroups. State-of-the-art BERT models were able to achieve 76% macro-F1 score\nusing monolingual data in the binary case. We also show that large-scale\nmonolingual data is still needed to create more accurate models, despite recent\nadvances in multilingual approaches. An error analysis and experiments with\nmulti-label classification show the difficulty of classifying certain types of\ntoxic comments that appear less frequently in our data and highlights the need\nto develop models that are aware of different categories of toxicity.", "published": "2020-10-09 13:05:19", "link": "http://arxiv.org/abs/2010.04543v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "HENIN: Learning Heterogeneous Neural Interaction Networks for\n  Explainable Cyberbullying Detection on Social Media", "abstract": "In the computational detection of cyberbullying, existing work largely\nfocused on building generic classifiers that rely exclusively on text analysis\nof social media sessions. Despite their empirical success, we argue that a\ncritical missing piece is the model explainability, i.e., why a particular\npiece of media session is detected as cyberbullying. In this paper, therefore,\nwe propose a novel deep model, HEterogeneous Neural Interaction Networks\n(HENIN), for explainable cyberbullying detection. HENIN contains the following\ncomponents: a comment encoder, a post-comment co-attention sub-network, and\nsession-session and post-post interaction extractors. Extensive experiments\nconducted on real datasets exhibit not only the promising performance of HENIN,\nbut also highlight evidential comments so that one can understand why a media\nsession is identified as cyberbullying.", "published": "2020-10-09 13:44:34", "link": "http://arxiv.org/abs/2010.04576v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Mark-Evaluate: Assessing Language Generation using Population Estimation\n  Methods", "abstract": "We propose a family of metrics to assess language generation derived from\npopulation estimation methods widely used in ecology. More specifically, we use\nmark-recapture and maximum-likelihood methods that have been applied over the\npast several decades to estimate the size of closed populations in the wild. We\npropose three novel metrics: ME$_\\text{Petersen}$ and ME$_\\text{CAPTURE}$,\nwhich retrieve a single-valued assessment, and ME$_\\text{Schnabel}$ which\nreturns a double-valued metric to assess the evaluation set in terms of quality\nand diversity, separately. In synthetic experiments, our family of methods is\nsensitive to drops in quality and diversity. Moreover, our methods show a\nhigher correlation to human evaluation than existing metrics on several\nchallenging tasks, namely unconditional language generation, machine\ntranslation, and text summarization.", "published": "2020-10-09 14:31:53", "link": "http://arxiv.org/abs/2010.04606v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Causal Feature Selection with Dimension Reduction for Interpretable Text\n  Classification", "abstract": "Text features that are correlated with class labels, but do not directly\ncause them, are sometimesuseful for prediction, but they may not be insightful.\nAs an alternative to traditional correlation-basedfeature selection, causal\ninference could reveal more principled, meaningful relationships betweentext\nfeatures and labels. To help researchers gain insight into text data, e.g. for\nsocial scienceapplications, in this paper we investigate a class of\nmatching-based causal inference methods fortext feature selection. Features\nused in document classification are often high dimensional, howeverexisting\ncausal feature selection methods use Propensity Score Matching (PSM) which is\nknown to beless effective in high-dimensional spaces. We propose a new causal\nfeature selection framework thatcombines dimension reduction with causal\ninference to improve text feature selection. Experiments onboth synthetic and\nreal-world data demonstrate the promise of our methods in improving\nclassificationand enhancing interpretability.", "published": "2020-10-09 14:36:49", "link": "http://arxiv.org/abs/2010.04609v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Examining the Ordering of Rhetorical Strategies in Persuasive Requests", "abstract": "Interpreting how persuasive language influences audiences has implications\nacross many domains like advertising, argumentation, and propaganda. Persuasion\nrelies on more than a message's content. Arranging the order of the message\nitself (i.e., ordering specific rhetorical strategies) also plays an important\nrole. To examine how strategy orderings contribute to persuasiveness, we first\nutilize a Variational Autoencoder model to disentangle content and rhetorical\nstrategies in textual requests from a large-scale loan request corpus. We then\nvisualize interplay between content and strategy through an attentional LSTM\nthat predicts the success of textual requests. We find that specific (orderings\nof) strategies interact uniquely with a request's content to impact success\nrate, and thus the persuasiveness of a request.", "published": "2020-10-09 15:10:44", "link": "http://arxiv.org/abs/2010.04625v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic\n  with Natural Language Processing (NLP)", "abstract": "The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.", "published": "2020-10-09 22:10:43", "link": "http://arxiv.org/abs/2010.16413v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating and Characterizing Human Rationales", "abstract": "Two main approaches for evaluating the quality of machine-generated\nrationales are: 1) using human rationales as a gold standard; and 2) automated\nmetrics based on how rationales affect model behavior. An open question,\nhowever, is how human rationales fare with these automatic metrics. Analyzing a\nvariety of datasets and models, we find that human rationales do not\nnecessarily perform well on these metrics. To unpack this finding, we propose\nimproved metrics to account for model-dependent baseline performance. We then\npropose two methods to further characterize rationale quality, one based on\nmodel retraining and one on using \"fidelity curves\" to reveal properties such\nas irrelevance and redundancy. Our work leads to actionable suggestions for\nevaluating and characterizing rationales.", "published": "2020-10-09 18:00:04", "link": "http://arxiv.org/abs/2010.04736v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How well does surprisal explain N400 amplitude under different\n  experimental conditions?", "abstract": "We investigate the extent to which word surprisal can be used to predict a\nneural measure of human language processing difficulty - the N400. To do this,\nwe use recurrent neural networks to calculate the surprisal of stimuli from\npreviously published neurolinguistic studies of the N400. We find that\nsurprisal can predict N400 amplitude in a wide range of cases, and the cases\nwhere it cannot do so provide valuable insight into the neurocognitive\nprocesses underlying the response.", "published": "2020-10-09 23:18:23", "link": "http://arxiv.org/abs/2010.04844v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "math.IT", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Phase-aware music super-resolution using generative adversarial networks", "abstract": "Audio super-resolution is a challenging task of recovering the missing\nhigh-resolution features from a low-resolution signal. To address this,\ngenerative adversarial networks (GAN) have been used to achieve promising\nresults by training the mappings between magnitudes of the low and\nhigh-frequency components. However, phase information is not well-considered\nfor waveform reconstruction in conventional methods. In this paper, we tackle\nthe problem of music super-resolution and conduct a thorough investigation on\nthe importance of phase for this task. We use GAN to predict the magnitudes of\nthe high-frequency components. The corresponding phase information can be\nextracted using either a GAN-based waveform synthesis system or a modified\nGriffin-Lim algorithm. Experimental results show that phase information plays\nan important role in the improvement of the reconstructed music quality.\nMoreover, our proposed method significantly outperforms other state-of-the-art\nmethods in terms of objective evaluations.", "published": "2020-10-09 11:34:39", "link": "http://arxiv.org/abs/2010.04506v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Audio-Visual Speech Inpainting with Deep Learning", "abstract": "In this paper, we present a deep-learning-based framework for audio-visual\nspeech inpainting, i.e., the task of restoring the missing parts of an acoustic\nspeech signal from reliable audio context and uncorrupted visual information.\nRecent work focuses solely on audio-only methods and generally aims at\ninpainting music signals, which show highly different structure than speech.\nInstead, we inpaint speech signals with gaps ranging from 100 ms to 1600 ms to\ninvestigate the contribution that vision can provide for gaps of different\nduration. We also experiment with a multi-task learning approach where a phone\nrecognition task is learned together with speech inpainting. Results show that\nthe performance of audio-only speech inpainting approaches degrades rapidly\nwhen gaps get large, while the proposed audio-visual approach is able to\nplausibly restore missing information. In addition, we show that multi-task\nlearning is effective, although the largest contribution to performance comes\nfrom vision.", "published": "2020-10-09 13:23:01", "link": "http://arxiv.org/abs/2010.04556v2", "categories": ["eess.AS", "cs.LG", "eess.IV"], "primary_category": "eess.AS"}
