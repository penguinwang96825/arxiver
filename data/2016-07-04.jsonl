{"title": "Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent\n  Unit for Summarization", "abstract": "In this work, we introduce temporal hierarchies to the sequence to sequence\n(seq2seq) model to tackle the problem of abstractive summarization of\nscientific articles. The proposed Multiple Timescale model of the Gated\nRecurrent Unit (MTGRU) is implemented in the encoder-decoder setting to better\ndeal with the presence of multiple compositionalities in larger texts. The\nproposed model is compared to the conventional RNN encoder-decoder, and the\nresults demonstrate that our model trains faster and shows significant\nperformance gains. The results also show that the temporal hierarchies help\nimprove the ability of seq2seq models to capture compositionalities better\nwithout the presence of highly complex architectural hierarchies.", "published": "2016-07-04 01:55:17", "link": "http://arxiv.org/abs/1607.00718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence to Backward and Forward Sequences: A Content-Introducing\n  Approach to Generative Short-Text Conversation", "abstract": "Using neural networks to generate replies in human-computer dialogue systems\nis attracting increasing attention over the past few years. However, the\nperformance is not satisfactory: the neural network tends to generate safe,\nuniversally relevant replies which carry little meaning. In this paper, we\npropose a content-introducing approach to neural network-based generative\ndialogue systems. We first use pointwise mutual information (PMI) to predict a\nnoun as a keyword, reflecting the main gist of the reply. We then propose\nseq2BF, a \"sequence to backward and forward sequences\" model, which generates a\nreply containing the given keyword. Experimental results show that our approach\nsignificantly outperforms traditional sequence-to-sequence models in terms of\nhuman evaluation and the entropy measure, and that the predicted keyword can\nappear at an appropriate position in the reply.", "published": "2016-07-04 17:42:52", "link": "http://arxiv.org/abs/1607.00970v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modelling Context with User Embeddings for Sarcasm Detection in Social\n  Media", "abstract": "We introduce a deep neural network for automated sarcasm detection. Recent\nwork has emphasized the need for models to capitalize on contextual features,\nbeyond lexical and syntactic cues present in utterances. For example, different\nspeakers will tend to employ sarcasm regarding different subjects and, thus,\nsarcasm detection models ought to encode such speaker information. Current\nmethods have achieved this by way of laborious feature engineering. By\ncontrast, we propose to automatically learn and then exploit user embeddings,\nto be used in concert with lexical signals to recognize sarcasm. Our approach\ndoes not require elaborate feature engineering (and concomitant data scraping);\nfitting user embeddings requires only the text from their previous posts. The\nexperimental results show that our model outperforms a state-of-the-art\napproach leveraging an extensive set of carefully crafted features.", "published": "2016-07-04 18:04:18", "link": "http://arxiv.org/abs/1607.00976v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generic Statistical Relational Entity Resolution in Knowledge Graphs", "abstract": "Entity resolution, the problem of identifying the underlying entity of\nreferences found in data, has been researched for many decades in many\ncommunities. A common theme in this research has been the importance of\nincorporating relational features into the resolution process. Relational\nentity resolution is particularly important in knowledge graphs (KGs), which\nhave a regular structure capturing entities and their interrelationships. We\nidentify three major problems in KG entity resolution: (1) intra-KG reference\nambiguity; (2) inter-KG reference ambiguity; and (3) ambiguity when extending\nKGs with new facts. We implement a framework that generalizes across these\nthree settings and exploits this regular structure of KGs. Our framework has\nmany advantages over custom solutions widely deployed in industry, including\ncollective inference, scalability, and interpretability. We apply our framework\nto two real-world KG entity resolution problems, ambiguity in NELL and merging\ndata from Freebase and MusicBrainz, demonstrating the importance of relational\nfeatures.", "published": "2016-07-04 19:02:47", "link": "http://arxiv.org/abs/1607.00992v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Temporal Topic Analysis with Endogenous and Exogenous Processes", "abstract": "We consider the problem of modeling temporal textual data taking endogenous\nand exogenous processes into account. Such text documents arise in real world\napplications, including job advertisements and economic news articles, which\nare influenced by the fluctuations of the general economy. We propose a\nhierarchical Bayesian topic model which imposes a \"group-correlated\"\nhierarchical structure on the evolution of topics over time incorporating both\nprocesses, and show that this model can be estimated from Markov chain Monte\nCarlo sampling methods. We further demonstrate that this model captures the\nintrinsic relationships between the topic distribution and the time-dependent\nfactors, and compare its performance with latent Dirichlet allocation (LDA) and\ntwo other related models. The model is applied to two collections of documents\nto illustrate its empirical performance: online job advertisements from\nDirectEmployers Association and journalists' postings on BusinessInsider.com.", "published": "2016-07-04 01:16:55", "link": "http://arxiv.org/abs/1607.01274v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
