{"title": "A Cross-Task Analysis of Text Span Representations", "abstract": "Many natural language processing (NLP) tasks involve reasoning with textual\nspans, including question answering, entity recognition, and coreference\nresolution. While extensive research has focused on functional architectures\nfor representing words and sentences, there is less work on representing\narbitrary spans of text within sentences. In this paper, we conduct a\ncomprehensive empirical evaluation of six span representation methods using\neight pretrained language representation models across six tasks, including two\ntasks that we introduce. We find that, although some simple span\nrepresentations are fairly reliable across tasks, in general the optimal span\nrepresentation varies by task, and can also vary within different facets of\nindividual tasks. We also find that the choice of span representation has a\nbigger impact with a fixed pretrained encoder than with a fine-tuned encoder.", "published": "2020-06-06 13:37:51", "link": "http://arxiv.org/abs/2006.03866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges and Thrills of Legal Arguments", "abstract": "State-of-the-art attention based models, mostly centered around the\ntransformer architecture, solve the problem of sequence-to-sequence translation\nusing the so-called scaled dot-product attention. While this technique is\nhighly effective for estimating inter-token attention, it does not answer the\nquestion of inter-sequence attention when we deal with conversation-like\nscenarios. We propose an extension, HumBERT, that attempts to perform\ncontinuous contextual argument generation using locally trained transformers.", "published": "2020-06-06 03:43:15", "link": "http://arxiv.org/abs/2006.03773v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "StackOverflow vs Kaggle: A Study of Developer Discussions About Data\n  Science", "abstract": "Software developers are increasingly required to understand fundamental Data\nscience (DS) concepts. Recently, the presence of machine learning (ML) and deep\nlearning (DL) has dramatically increased in the development of user\napplications, whether they are leveraged through frameworks or implemented from\nscratch. These topics attract much discussion on online platforms. This paper\nconducts large-scale qualitative and quantitative experiments to study the\ncharacteristics of 197836 posts from StackOverflow and Kaggle. Latent Dirichlet\nAllocation topic modelling is used to extract twenty-four DS discussion topics.\nThe main findings include that TensorFlow-related topics were most prevalent in\nStackOverflow, while meta discussion topics were the prevalent ones on Kaggle.\nStackOverflow tends to include lower-level troubleshooting, while Kaggle\nfocuses on practicality and optimising leaderboard performance. In addition,\nacross both communities, DS discussion is increasing at a dramatic rate. While\nTensorFlow discussion on StackOverflow is slowing, interest in Keras is rising.\nFinally, ensemble algorithms are the most mentioned ML/DL algorithms in Kaggle\nbut are rarely discussed on StackOverflow. These findings can help educators\nand researchers to more effectively tailor and prioritise efforts in\nresearching and communicating DS concepts towards different developer\ncommunities.", "published": "2020-06-06 06:51:11", "link": "http://arxiv.org/abs/2006.08334v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report\n  Generation", "abstract": "Beyond the common difficulties faced in the natural image captioning, medical\nreport generation specifically requires the model to describe a medical image\nwith a fine-grained and semantic-coherence paragraph that should satisfy both\nmedical commonsense and logic. Previous works generally extract the global\nimage features and attempt to generate a paragraph that is similar to\nreferenced reports; however, this approach has two limitations. Firstly, the\nregions of primary interest to radiologists are usually located in a small area\nof the global image, meaning that the remainder parts of the image could be\nconsidered as irrelevant noise in the training procedure. Secondly, there are\nmany similar sentences used in each medical report to describe the normal\nregions of the image, which causes serious data bias. This deviation is likely\nto teach models to generate these inessential sentences on a regular basis. To\naddress these problems, we propose an Auxiliary Signal-Guided Knowledge\nEncoder-Decoder (ASGK) to mimic radiologists' working patterns. In more detail,\nASGK integrates internal visual feature fusion and external medical linguistic\ninformation to guide medical knowledge transfer and learning. The core\nstructure of ASGK consists of a medical graph encoder and a natural language\ndecoder, inspired by advanced Generative Pre-Training (GPT). Experiments on the\nCX-CHR dataset and our COVID-19 CT Report dataset demonstrate that our proposed\nASGK is able to generate a robust and accurate report, and moreover outperforms\nstate-of-the-art methods on both medical terminology classification and\nparagraph generation metrics.", "published": "2020-06-06 01:00:15", "link": "http://arxiv.org/abs/2006.03744v1", "categories": ["cs.CV", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MAGNet: Multi-Region Attention-Assisted Grounding of Natural Language\n  Queries at Phrase Level", "abstract": "Grounding free-form textual queries necessitates an understanding of these\ntextual phrases and its relation to the visual cues to reliably reason about\nthe described locations. Spatial attention networks are known to learn this\nrelationship and focus its gaze on salient objects in the image. Thus, we\npropose to utilize spatial attention networks for image-level visual-textual\nfusion preserving local (word) and global (phrase) information to refine region\nproposals with an in-network Region Proposal Network (RPN) and detect single or\nmultiple regions for a phrase query. We focus only on the phrase query - ground\ntruth pair (referring expression) for a model independent of the constraints of\nthe datasets i.e. additional attributes, context etc. For such referring\nexpression dataset ReferIt game, our Multi-region Attention-assisted Grounding\nnetwork (MAGNet) achieves over 12\\% improvement over the state-of-the-art.\nWithout the context from image captions and attribute information in Flickr30k\nEntities, we still achieve competitive results compared to the\nstate-of-the-art.", "published": "2020-06-06 04:14:15", "link": "http://arxiv.org/abs/2006.03776v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across\n  Languages and Over Centuries", "abstract": "Word embeddings learn implicit biases from linguistic regularities captured\nby word co-occurrence statistics. By extending methods that quantify human-like\nbiases in word embeddings, we introduceValNorm, a novel intrinsic evaluation\ntask and method to quantify the valence dimension of affect in human-rated word\nsets from social psychology. We apply ValNorm on static word embeddings from\nseven languages (Chinese, English, German, Polish, Portuguese, Spanish, and\nTurkish) and from historical English text spanning 200 years. ValNorm achieves\nconsistently high accuracy in quantifying the valence of non-discriminatory,\nnon-social group word sets. Specifically, ValNorm achieves a Pearson\ncorrelation of r=0.88 for human judgment scores of valence for 399 words\ncollected to establish pleasantness norms in English. In contrast, we measure\ngender stereotypes using the same set of word embeddings and find that social\nbiases vary across languages. Our results indicate that valence associations of\nnon-discriminatory, non-social group words represent widely-shared\nassociations, in seven languages and over 200 years.", "published": "2020-06-06 19:29:36", "link": "http://arxiv.org/abs/2006.03950v5", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Detecting Emergent Intersectional Biases: Contextualized Word Embeddings\n  Contain a Distribution of Human-like Biases", "abstract": "With the starting point that implicit human biases are reflected in the\nstatistical regularities of language, it is possible to measure biases in\nEnglish static word embeddings. State-of-the-art neural language models\ngenerate dynamic word embeddings dependent on the context in which the word\nappears. Current methods measure pre-defined social and intersectional biases\nthat appear in particular contexts defined by sentence templates. Dispensing\nwith templates, we introduce the Contextualized Embedding Association Test\n(CEAT), that can summarize the magnitude of overall bias in neural language\nmodels by incorporating a random-effects model. Experiments on social and\nintersectional biases show that CEAT finds evidence of all tested biases and\nprovides comprehensive information on the variance of effect magnitudes of the\nsame bias in different contexts. All the models trained on English corpora that\nwe study contain biased representations.\n  Furthermore, we develop two methods, Intersectional Bias Detection (IBD) and\nEmergent Intersectional Bias Detection (EIBD), to automatically identify the\nintersectional biases and emergent intersectional biases from static word\nembeddings in addition to measuring them in contextualized word embeddings. We\npresent the first algorithmic bias detection findings on how intersectional\ngroup members are strongly associated with unique emergent biases that do not\noverlap with the biases of their constituent minority identities. IBD and EIBD\nachieve high accuracy when detecting the intersectional and emergent biases of\nAfrican American females and Mexican American females. Our results indicate\nthat biases at the intersection of race and gender associated with members of\nmultiple minority groups, such as African American females and Mexican American\nfemales, have the highest magnitude across all neural language models.", "published": "2020-06-06 19:49:50", "link": "http://arxiv.org/abs/2006.03955v5", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Generative Adversarial Phonology: Modeling unsupervised phonetic and\n  phonological learning with neural networks", "abstract": "Training deep neural networks on well-understood dependencies in speech data\ncan provide new insights into how they learn internal representations. This\npaper argues that acquisition of speech can be modeled as a dependency between\nrandom space and generated speech data in the Generative Adversarial Network\narchitecture and proposes a methodology to uncover the network's internal\nrepresentations that correspond to phonetic and phonological properties. The\nGenerative Adversarial architecture is uniquely appropriate for modeling\nphonetic and phonological learning because the network is trained on\nunannotated raw acoustic data and learning is unsupervised without any\nlanguage-specific assumptions or pre-assumed levels of abstraction. A\nGenerative Adversarial Network was trained on an allophonic distribution in\nEnglish. The network successfully learns the allophonic alternation: the\nnetwork's generated speech signal contains the conditional distribution of\naspiration duration. The paper proposes a technique for establishing the\nnetwork's internal representations that identifies latent variables that\ncorrespond to, for example, presence of [s] and its spectral properties. By\nmanipulating these variables, we actively control the presence of [s] and its\nfrication amplitude in the generated outputs. This suggests that the network\nlearns to use latent variables as an approximation of phonetic and phonological\nrepresentations. Crucially, we observe that the dependencies learned in\ntraining extend beyond the training interval, which allows for additional\nexploration of learning representations. The paper also discusses how the\nnetwork's architecture and innovative outputs resemble and differ from\nlinguistic behavior in language acquisition, speech disorders, and speech\nerrors, and how well-understood dependencies in speech data can help us\ninterpret how neural networks learn their representations.", "published": "2020-06-06 20:31:23", "link": "http://arxiv.org/abs/2006.03965v1", "categories": ["cs.CL", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
