{"title": "METAL: Towards Multilingual Meta-Evaluation", "abstract": "With the rising human-like precision of Large Language Models (LLMs) in\nnumerous tasks, their utilization in a variety of real-world applications is\nbecoming more prevalent. Several studies have shown that LLMs excel on many\nstandard NLP benchmarks. However, it is challenging to evaluate LLMs due to\ntest dataset contamination and the limitations of traditional metrics. Since\nhuman evaluations are difficult to collect, there is a growing interest in the\ncommunity to use LLMs themselves as reference-free evaluators for subjective\nmetrics. However, past work has shown that LLM-based evaluators can exhibit\nbias and have poor alignment with human judgments. In this study, we propose a\nframework for an end-to-end assessment of LLMs as evaluators in multilingual\nscenarios. We create a carefully curated dataset, covering 10 languages\ncontaining native speaker judgments for the task of summarization. This dataset\nis created specifically to evaluate LLM-based evaluators, which we refer to as\nmeta-evaluation (METAL). We compare the performance of LLM-based evaluators\ncreated using GPT-3.5-Turbo, GPT-4, and PaLM2. Our results indicate that\nLLM-based evaluators based on GPT-4 perform the best across languages, while\nGPT-3.5-Turbo performs poorly. Additionally, we perform an analysis of the\nreasoning provided by LLM-based evaluators and find that it often does not\nmatch the reasoning provided by human judges.", "published": "2024-04-02 06:14:54", "link": "http://arxiv.org/abs/2404.01667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Role of Summary Content Units in Text Summarization Evaluation", "abstract": "At the heart of the Pyramid evaluation method for text summarization lie\nhuman written summary content units (SCUs). These SCUs are concise sentences\nthat decompose a summary into small facts. Such SCUs can be used to judge the\nquality of a candidate summary, possibly partially automated via natural\nlanguage inference (NLI) systems. Interestingly, with the aim to fully automate\nthe Pyramid evaluation, Zhang and Bansal (2021) show that SCUs can be\napproximated by automatically generated semantic role triplets (STUs). However,\nseveral questions currently lack answers, in particular: i) Are there other\nways of approximating SCUs that can offer advantages? ii) Under which\nconditions are SCUs (or their approximations) offering the most value? In this\nwork, we examine two novel strategies to approximate SCUs: generating SCU\napproximations from AMR meaning representations (SMUs) and from large language\nmodels (SGUs), respectively. We find that while STUs and SMUs are competitive,\nthe best approximation quality is achieved by SGUs. We also show through a\nsimple sentence-decomposition baseline (SSUs) that SCUs (and their\napproximations) offer the most value when ranking short summaries, but may not\nhelp as much when ranking systems or longer summaries.", "published": "2024-04-02 07:09:44", "link": "http://arxiv.org/abs/2404.01701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polarity Calibration for Opinion Summarization", "abstract": "Opinion summarization is automatically generating summaries from a variety of\nsubjective information, such as product reviews or political opinions. The\nchallenge of opinions summarization lies in presenting divergent or even\nconflicting opinions. We conduct an analysis of previous summarization models,\nwhich reveals their inclination to amplify the polarity bias, emphasizing the\nmajority opinions while ignoring the minority opinions. To address this issue\nand make the summarizer express both sides of opinions, we introduce the\nconcept of polarity calibration, which aims to align the polarity of output\nsummary with that of input text. Specifically, we develop a reinforcement\ntraining approach for polarity calibration. This approach feeds the polarity\ndistance between output summary and input text as reward into the summarizer,\nand also balance polarity calibration with content preservation and language\nnaturality. We evaluate our Polarity Calibration model (PoCa) on two types of\nopinions summarization tasks: summarizing product reviews and political\nopinions articles. Automatic and human evaluation demonstrate that our approach\ncan mitigate the polarity mismatch between output summary and input text, as\nwell as maintain the content semantic and language quality.", "published": "2024-04-02 07:43:12", "link": "http://arxiv.org/abs/2404.01706v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMONA: Event-level Moral Opinions in News Articles", "abstract": "Most previous research on moral frames has focused on social media short\ntexts, little work has explored moral sentiment within news articles. In news\narticles, authors often express their opinions or political stance through\nmoral judgment towards events, specifically whether the event is right or wrong\naccording to social moral rules. This paper initiates a new task to understand\nmoral opinions towards events in news articles. We have created a new dataset,\nEMONA, and annotated event-level moral opinions in news articles. This dataset\nconsists of 400 news articles containing over 10k sentences and 45k events,\namong which 9,613 events received moral foundation labels. Extracting event\nmorality is a challenging task, as moral judgment towards events can be very\nimplicit. Baseline models were built for event moral identification and\nclassification. In addition, we also conduct extrinsic evaluations to integrate\nevent-level moral opinions into three downstream tasks. The statistical\nanalysis and experiments show that moral opinions of events can serve as\ninformative features for identifying ideological bias or subjective events.", "published": "2024-04-02 07:57:19", "link": "http://arxiv.org/abs/2404.01715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Improvement Programming for Temporal Knowledge Graph Question\n  Answering", "abstract": "Temporal Knowledge Graph Question Answering (TKGQA) aims to answer questions\nwith temporal intent over Temporal Knowledge Graphs (TKGs). The core challenge\nof this task lies in understanding the complex semantic information regarding\nmultiple types of time constraints (e.g., before, first) in questions. Existing\nend-to-end methods implicitly model the time constraints by learning time-aware\nembeddings of questions and candidate answers, which is far from understanding\nthe question comprehensively. Motivated by semantic-parsing-based approaches\nthat explicitly model constraints in questions by generating logical forms with\nsymbolic operators, we design fundamental temporal operators for time\nconstraints and introduce a novel self-improvement Programming method for TKGQA\n(Prog-TQA). Specifically, Prog-TQA leverages the in-context learning ability of\nLarge Language Models (LLMs) to understand the combinatory time constraints in\nthe questions and generate corresponding program drafts with a few examples\ngiven. Then, it aligns these drafts to TKGs with the linking module and\nsubsequently executes them to generate the answers. To enhance the ability to\nunderstand questions, Prog-TQA is further equipped with a self-improvement\nstrategy to effectively bootstrap LLMs using high-quality self-generated\ndrafts. Extensive experiments demonstrate the superiority of the proposed\nProg-TQA on MultiTQ and CronQuestions datasets, especially in the Hits@1\nmetric.", "published": "2024-04-02 08:14:27", "link": "http://arxiv.org/abs/2404.01720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence-level Media Bias Analysis with Event Relation Graph", "abstract": "Media outlets are becoming more partisan and polarized nowadays. In this\npaper, we identify media bias at the sentence level, and pinpoint bias\nsentences that intend to sway readers' opinions. As bias sentences are often\nexpressed in a neutral and factual way, considering broader context outside a\nsentence can help reveal the bias. In particular, we observe that events in a\nbias sentence need to be understood in associations with other events in the\ndocument. Therefore, we propose to construct an event relation graph to\nexplicitly reason about event-event relations for sentence-level bias\nidentification. The designed event relation graph consists of events as nodes\nand four common types of event relations: coreference, temporal, causal, and\nsubevent relations. Then, we incorporate event relation graph for bias\nsentences identification in two steps: an event-aware language model is built\nto inject the events and event relations knowledge into the basic language\nmodel via soft labels; further, a relation-aware graph attention network is\ndesigned to update sentence embedding with events and event relations\ninformation based on hard labels. Experiments on two benchmark datasets\ndemonstrate that our approach with the aid of event relation graph improves\nboth precision and recall of bias sentence identification.", "published": "2024-04-02 08:16:03", "link": "http://arxiv.org/abs/2404.01722v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Octopus v2: On-device language model for super agent", "abstract": "Language models have shown effectiveness in a variety of software\napplications, particularly in tasks related to automatic workflow. These models\npossess the crucial ability to call functions, which is essential in creating\nAI agents. Despite the high performance of large-scale language models in cloud\nenvironments, they are often associated with concerns over privacy and cost.\nCurrent on-device models for function calling face issues with latency and\naccuracy. Our research presents a new method that empowers an on-device model\nwith 2 billion parameters to surpass the performance of GPT-4 in both accuracy\nand latency, and decrease the context length by 95\\%. When compared to Llama-7B\nwith a RAG-based function calling mechanism, our method enhances latency by\n35-fold. This method reduces the latency to levels deemed suitable for\ndeployment across a variety of edge devices in production environments,\naligning with the performance requisites for real-world applications.", "published": "2024-04-02 09:01:32", "link": "http://arxiv.org/abs/2404.01744v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets", "abstract": "In recent years, multimodal natural language processing, aimed at learning\nfrom diverse data types, has garnered significant attention. However, there\nneeds to be more clarity when it comes to analysing multimodal tasks in\nmulti-lingual contexts. While prior studies on sentiment analysis of tweets\nhave predominantly focused on the English language, this paper addresses this\ngap by transforming an existing textual Twitter sentiment dataset into a\nmultimodal format through a straightforward curation process. Our work opens up\nnew avenues for sentiment-related research within the research community.\nAdditionally, we conduct baseline experiments utilising this augmented dataset\nand report the findings. Notably, our evaluations reveal that when comparing\nunimodal and multimodal configurations, using a sentiment-tuned large language\nmodel as a text encoder performs exceptionally well.", "published": "2024-04-02 09:11:58", "link": "http://arxiv.org/abs/2404.01753v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Class-Incremental Few-Shot Event Detection", "abstract": "Event detection is one of the fundamental tasks in information extraction and\nknowledge graph. However, a realistic event detection system often needs to\ndeal with new event classes constantly. These new classes usually have only a\nfew labeled instances as it is time-consuming and labor-intensive to annotate a\nlarge number of unlabeled instances. Therefore, this paper proposes a new task,\ncalled class-incremental few-shot event detection. Nevertheless, this task\nfaces two problems, i.e., old knowledge forgetting and new class overfitting.\nTo solve these problems, this paper further presents a novel knowledge\ndistillation and prompt learning based method, called Prompt-KD. Specifically,\nto handle the forgetting problem about old knowledge, Prompt-KD develops an\nattention based multi-teacher knowledge distillation framework, where the\nancestor teacher model pre-trained on base classes is reused in all learning\nsessions, and the father teacher model derives the current student model via\nadaptation. On the other hand, in order to cope with the few-shot learning\nscenario and alleviate the corresponding new class overfitting problem,\nPrompt-KD is also equipped with a prompt learning mechanism. Extensive\nexperiments on two benchmark datasets, i.e., FewEvent and MAVEN, demonstrate\nthe superior performance of Prompt-KD.", "published": "2024-04-02 09:31:14", "link": "http://arxiv.org/abs/2404.01767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Humans Identify Domains?", "abstract": "Textual domain is a crucial property within the Natural Language Processing\n(NLP) community due to its effects on downstream model performance. The concept\nitself is, however, loosely defined and, in practice, refers to any\nnon-typological property, such as genre, topic, medium or style of a document.\nWe investigate the core notion of domains via human proficiency in identifying\nrelated intrinsic textual properties, specifically the concepts of genre\n(communicative purpose) and topic (subject matter). We publish our annotations\nin *TGeGUM*: A collection of 9.1k sentences from the GUM dataset (Zeldes, 2017)\nwith single sentence and larger context (i.e., prose) annotations for one of 11\ngenres (source type), and its topic/subtopic as per the Dewey Decimal library\nclassification system (Dewey, 1979), consisting of 10/100 hierarchical topics\nof increased granularity. Each instance is annotated by three annotators, for a\ntotal of 32.7k annotations, allowing us to examine the level of human\ndisagreement and the relative difficulty of each annotation task. With a\nFleiss' kappa of at most 0.53 on the sentence level and 0.66 at the prose\nlevel, it is evident that despite the ubiquity of domains in NLP, there is\nlittle human consensus on how to define them. By training classifiers to\nperform the same task, we find that this uncertainty also extends to NLP\nmodels.", "published": "2024-04-02 09:49:07", "link": "http://arxiv.org/abs/2404.01785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative AI-Based Text Generation Methods Using Pre-Trained GPT-2\n  Model", "abstract": "This work delved into the realm of automatic text generation, exploring a\nvariety of techniques ranging from traditional deterministic approaches to more\nmodern stochastic methods. Through analysis of greedy search, beam search,\ntop-k sampling, top-p sampling, contrastive searching, and locally typical\nsearching, this work has provided valuable insights into the strengths,\nweaknesses, and potential applications of each method. Each text-generating\nmethod is evaluated using several standard metrics and a comparative study has\nbeen made on the performance of the approaches. Finally, some future directions\nof research in the field of automatic text generation are also identified.", "published": "2024-04-02 09:49:53", "link": "http://arxiv.org/abs/2404.01786v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IndoCulture: Exploring Geographically-Influenced Cultural Commonsense\n  Reasoning Across Eleven Indonesian Provinces", "abstract": "Although commonsense reasoning is greatly shaped by cultural and geographical\nfactors, previous studies have predominantly centered on cultures grounded in\nthe English language, potentially resulting in an Anglocentric bias. In this\npaper, we introduce IndoCulture, aimed at understanding the influence of\ngeographical factors on language model reasoning ability, with a specific\nemphasis on the diverse cultures found within eleven Indonesian provinces. In\ncontrast to prior work that has relied on templates (Yin et al., 2022) and\nonline scrapping (Fung et al., 2024), we create IndoCulture by asking local\npeople to manually develop a cultural context and plausible options, across a\nset of predefined topics. Evaluation of 27 language models reveals several\ninsights: (1) the open-weight Llama-3 is competitive with GPT-4, while other\nopen-weight models struggle, with accuracies below 50%; (2) there is a general\npattern of models generally performing better for some provinces, such as Bali\nand West Java, and less well for others; and (3) the inclusion of location\ncontext enhances performance, especially for larger models like GPT-4,\nemphasizing the significance of geographical context in commonsense reasoning.", "published": "2024-04-02 11:32:58", "link": "http://arxiv.org/abs/2404.01854v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Poro 34B and the Blessing of Multilinguality", "abstract": "The pretraining of state-of-the-art large language models now requires\ntrillions of words of text, which is orders of magnitude more than available\nfor the vast majority of languages. While including text in more than one\nlanguage is an obvious way to acquire more pretraining data, multilinguality is\noften seen as a curse, and most model training efforts continue to focus\nnear-exclusively on individual large languages. We believe that multilinguality\ncan be a blessing and that it should be possible to substantially improve over\nthe capabilities of monolingual models for small languages through multilingual\ntraining. In this study, we introduce Poro 34B, a 34 billion parameter model\ntrained for 1 trillion tokens of Finnish, English, and programming languages,\nand demonstrate that a multilingual training approach can produce a model that\nnot only substantially advances over the capabilities of existing models for\nFinnish, but also excels in translation and is competitive in its class in\ngenerating English and programming languages. We release the model parameters,\nscripts, and data under open licenses at\nhttps://huggingface.co/LumiOpen/Poro-34B.", "published": "2024-04-02 11:34:12", "link": "http://arxiv.org/abs/2404.01856v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-StrAE at SemEval-2024 Task 1: Making Self-Structuring AutoEncoders\n  Learn More With Less", "abstract": "This paper presents two simple improvements to the Self-Structuring\nAutoEncoder (Self-StrAE). Firstly, we show that including reconstruction to the\nvocabulary as an auxiliary objective improves representation quality. Secondly,\nwe demonstrate that increasing the number of independent channels leads to\nsignificant improvements in embedding quality, while simultaneously reducing\nthe number of parameters. Surprisingly, we demonstrate that this trend can be\nfollowed to the extreme, even to point of reducing the total number of\nnon-embedding parameters to seven. Our system can be pre-trained from scratch\nwith as little as 10M tokens of input data, and proves effective across\nEnglish, Spanish and Afrikaans.", "published": "2024-04-02 11:38:11", "link": "http://arxiv.org/abs/2404.01860v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Rationale-centric Counterfactual Data Augmentation Method for\n  Cross-Document Event Coreference Resolution", "abstract": "Based on Pre-trained Language Models (PLMs), event coreference resolution\n(ECR) systems have demonstrated outstanding performance in clustering\ncoreferential events across documents. However, the existing system exhibits an\nexcessive reliance on the `triggers lexical matching' spurious pattern in the\ninput mention pair text. We formalize the decision-making process of the\nbaseline ECR system using a Structural Causal Model (SCM), aiming to identify\nspurious and causal associations (i.e., rationales) within the ECR task.\nLeveraging the debiasing capability of counterfactual data augmentation, we\ndevelop a rationale-centric counterfactual data augmentation method with\nLLM-in-the-loop. This method is specialized for pairwise input in the ECR\nsystem, where we conduct direct interventions on triggers and context to\nmitigate the spurious association while emphasizing the causation. Our approach\nachieves state-of-the-art performance on three popular cross-document ECR\nbenchmarks and demonstrates robustness in out-of-domain scenarios.", "published": "2024-04-02 13:15:07", "link": "http://arxiv.org/abs/2404.01921v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs\n  in Translation", "abstract": "Understanding cybercrime communications is paramount for cybersecurity\ndefence. This often involves translating communications into English for\nprocessing, interpreting, and generating timely intelligence. The problem is\nthat translation is hard. Human translation is slow, expensive, and scarce.\nMachine translation is inaccurate and biased. We propose using fine-tuned Large\nLanguage Models (LLM) to generate translations that can accurately capture the\nnuances of cybercrime language. We apply our technique to public chats from the\nNoName057(16) Russian-speaking hacktivist group. Our results show that our\nfine-tuned LLM model is better, faster, more accurate, and able to capture\nnuances of the language. Our method shows it is possible to achieve\nhigh-fidelity translations and significantly reduce costs by a factor ranging\nfrom 430 to 23,000 compared to a human translator.", "published": "2024-04-02 13:33:23", "link": "http://arxiv.org/abs/2404.01940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument\n  Reasoning in Civil Procedures with GPT4", "abstract": "In this paper, we present our system for the SemEval Task 5, The Legal\nArgument Reasoning Task in Civil Procedure Challenge. Legal argument reasoning\nis an essential skill that all law students must master. Moreover, it is\nimportant to develop natural language processing solutions that can reason\nabout a question given terse domain-specific contextual information. Our system\nexplores a prompt-based solution using GPT4 to reason over legal arguments. We\nalso evaluate an ensemble of prompting strategies, including chain-of-thought\nreasoning and in-context learning. Overall, our system results in a Macro F1 of\n.8095 on the validation dataset and .7315 (5th out of 21 teams) on the final\ntest set. Code for this project is available at\nhttps://github.com/danschumac1/CivilPromptReasoningGPT4.", "published": "2024-04-02 13:55:05", "link": "http://arxiv.org/abs/2404.01961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kallaama: A Transcribed Speech Dataset about Agriculture in the Three\n  Most Widely Spoken Languages in Senegal", "abstract": "This work is part of the Kallaama project, whose objective is to produce and\ndisseminate national languages corpora for speech technologies developments, in\nthe field of agriculture. Except for Wolof, which benefits from some language\ndata for natural language processing, national languages of Senegal are largely\nignored by language technology providers. However, such technologies are keys\nto the protection, promotion and teaching of these languages. Kallaama focuses\non the 3 main spoken languages by Senegalese people: Wolof, Pulaar and Sereer.\nThese languages are widely spoken by the population, with around 10 million of\nnative Senegalese speakers, not to mention those outside the country. However,\nthey remain under-resourced in terms of machine-readable data that can be used\nfor automatic processing and language technologies, all the more so in the\nagricultural sector. We release a transcribed speech dataset containing 125\nhours of recordings, about agriculture, in each of the above-mentioned\nlanguages. These resources are specifically designed for Automatic Speech\nRecognition purpose, including traditional approaches. To build such\ntechnologies, we provide textual corpora in Wolof and Pulaar, and a\npronunciation lexicon containing 49,132 entries from the Wolof dataset.", "published": "2024-04-02 14:31:14", "link": "http://arxiv.org/abs/2404.01991v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dissecting Paraphrases: The Impact of Prompt Syntax and supplementary\n  Information on Knowledge Retrieval from Pretrained Language Models", "abstract": "Pre-trained Language Models (PLMs) are known to contain various kinds of\nknowledge. One method to infer relational knowledge is through the use of\ncloze-style prompts, where a model is tasked to predict missing subjects or\nobjects. Typically, designing these prompts is a tedious task because small\ndifferences in syntax or semantics can have a substantial impact on knowledge\nretrieval performance. Simultaneously, evaluating the impact of either prompt\nsyntax or information is challenging due to their interdependence. We designed\nCONPARE-LAMA - a dedicated probe, consisting of 34 million distinct prompts\nthat facilitate comparison across minimal paraphrases. These paraphrases follow\na unified meta-template enabling the controlled variation of syntax and\nsemantics across arbitrary relations. CONPARE-LAMA enables insights into the\nindependent impact of either syntactical form or semantic information of\nparaphrases on the knowledge retrieval performance of PLMs. Extensive knowledge\nretrieval experiments using our probe reveal that prompts following clausal\nsyntax have several desirable properties in comparison to appositive syntax: i)\nthey are more useful when querying PLMs with a combination of supplementary\ninformation, ii) knowledge is more consistently recalled across different\ncombinations of supplementary information, and iii) they decrease response\nuncertainty when retrieving known facts. In addition, range information can\nboost knowledge retrieval performance more than domain information, even though\ndomain information is more reliably helpful across syntactic forms.", "published": "2024-04-02 14:35:08", "link": "http://arxiv.org/abs/2404.01992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breaking the Silence Detecting and Mitigating Gendered Abuse in Hindi,\n  Tamil, and Indian English Online Spaces", "abstract": "Online gender-based harassment is a widespread issue limiting the free\nexpression and participation of women and marginalized genders in digital\nspaces. Detecting such abusive content can enable platforms to curb this\nmenace. We participated in the Gendered Abuse Detection in Indic Languages\nshared task at ICON2023 that provided datasets of annotated Twitter posts in\nEnglish, Hindi and Tamil for building classifiers to identify gendered abuse.\nOur team CNLP-NITS-PP developed an ensemble approach combining CNN and BiLSTM\nnetworks that can effectively model semantic and sequential patterns in textual\ndata. The CNN captures localized features indicative of abusive language\nthrough its convolution filters applied on embedded input text. To determine\ncontext-based offensiveness, the BiLSTM analyzes this sequence for dependencies\namong words and phrases. Multiple variations were trained using FastText and\nGloVe word embeddings for each language dataset comprising over 7,600\ncrowdsourced annotations across labels for explicit abuse, targeted minority\nattacks and general offences. The validation scores showed strong performance\nacross f1-measures, especially for English 0.84. Our experiments reveal how\ncustomizing embeddings and model hyperparameters can improve detection\ncapability. The proposed architecture ranked 1st in the competition, proving\nits ability to handle real-world noisy text with code-switching. This technique\nhas a promising scope as platforms aim to combat cyber harassment facing Indic\nlanguage internet users. Our Code is at\nhttps://github.com/advaithavetagiri/CNLP-NITS-PP", "published": "2024-04-02 14:55:47", "link": "http://arxiv.org/abs/2404.02013v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Retrieval Augmented Open-Domain Question-Answering with\n  Vectorized Contexts", "abstract": "In the era of large language models, applying techniques such as Retrieval\nAugmented Generation can better address Open-Domain Question-Answering\nproblems. Due to constraints including model sizes and computing resources, the\nlength of context is often limited, and it becomes challenging to empower the\nmodel to cover overlong contexts while answering questions from open domains.\nThis paper proposes a general and convenient method to covering longer contexts\nin Open-Domain Question-Answering tasks. It leverages a small encoder language\nmodel that effectively encodes contexts, and the encoding applies\ncross-attention with origin inputs. With our method, the origin language models\ncan cover several times longer contexts while keeping the computing\nrequirements close to the baseline. Our experiments demonstrate that after\nfine-tuning, there is improved performance across two held-in datasets, four\nheld-out datasets, and also in two In Context Learning settings.", "published": "2024-04-02 15:10:11", "link": "http://arxiv.org/abs/2404.02022v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deconstructing In-Context Learning: Understanding Prompts via Corruption", "abstract": "The ability of large language models (LLMs) to $``$learn in context$\"$ based\non the provided prompt has led to an explosive growth in their use, culminating\nin the proliferation of AI assistants such as ChatGPT, Claude, and Bard. These\nAI assistants are known to be robust to minor prompt modifications, mostly due\nto alignment techniques that use human feedback. In contrast, the underlying\npre-trained LLMs they use as a backbone are known to be brittle in this\nrespect. Building high-quality backbone models remains a core challenge, and a\ncommon approach to assessing their quality is to conduct few-shot evaluation.\nSuch evaluation is notorious for being highly sensitive to minor prompt\nmodifications, as well as the choice of specific in-context examples. Prior\nwork has examined how modifying different elements of the prompt can affect\nmodel performance. However, these earlier studies tended to concentrate on a\nlimited number of specific prompt attributes and often produced contradictory\nresults. Additionally, previous research either focused on models with fewer\nthan 15 billion parameters or exclusively examined black-box models like GPT-3\nor PaLM, making replication challenging. In the present study, we decompose the\nentire prompt into four components: task description, demonstration inputs,\nlabels, and inline instructions provided for each demonstration. We investigate\nthe effects of structural and semantic corruptions of these elements on model\nperformance. We study models ranging from 1.5B to 70B in size, using ten\ndatasets covering classification and generation tasks. We find that repeating\ntext within the prompt boosts model performance, and bigger models ($\\geq$30B)\nare more sensitive to the semantics of the prompt. Finally, we observe that\nadding task and inline instructions to the demonstrations enhances model\nperformance even when the instructions are semantically corrupted.", "published": "2024-04-02 15:50:55", "link": "http://arxiv.org/abs/2404.02054v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Interpretation Methods for Model Enhancement", "abstract": "In the age of neural natural language processing, there are plenty of works\ntrying to derive interpretations of neural models. Intuitively, when gold\nrationales exist during training, one can additionally train the model to match\nits interpretation with the rationales. However, this intuitive idea has not\nbeen fully explored. In this paper, we propose a framework of utilizing\ninterpretation methods and gold rationales to enhance models. Our framework is\nvery general in the sense that it can incorporate various interpretation\nmethods. Previously proposed gradient-based methods can be shown as an instance\nof our framework. We also propose two novel instances utilizing two other types\nof interpretation methods, erasure/replace-based and extractor-based methods,\nfor model enhancement. We conduct comprehensive experiments on a variety of\ntasks. Experimental results show that our framework is effective especially in\nlow-resource settings in enhancing models with various interpretation methods,\nand our two newly-proposed methods outperform gradient-based methods in most\nsettings. Code is available at https://github.com/Chord-Chen-30/UIMER.", "published": "2024-04-02 16:10:29", "link": "http://arxiv.org/abs/2404.02068v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions\n  for RAG systems", "abstract": "Retrieval Augmented Generation (RAG) has become a popular application for\nlarge language models. It is preferable that successful RAG systems provide\naccurate answers that are supported by being grounded in a passage without any\nhallucinations. While considerable work is required for building a full RAG\npipeline, being able to benchmark performance is also necessary. We present\nClapNQ, a benchmark Long-form Question Answering dataset for the full RAG\npipeline. ClapNQ includes long answers with grounded gold passages from Natural\nQuestions (NQ) and a corpus to perform either retrieval, generation, or the\nfull RAG pipeline. The ClapNQ answers are concise, 3x smaller than the full\npassage, and cohesive, meaning that the answer is composed fluently, often by\nintegrating multiple pieces of the passage that are not contiguous. RAG models\nmust adapt to these properties to be successful at ClapNQ. We present baseline\nexperiments and analysis for ClapNQ that highlight areas where there is still\nsignificant room for improvement in grounded RAG. CLAPNQ is publicly available\nat https://github.com/primeqa/clapnq", "published": "2024-04-02 17:00:11", "link": "http://arxiv.org/abs/2404.02103v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Automated Distractor Generation for Math Multiple-choice\n  Questions via Large Language Models", "abstract": "Multiple-choice questions (MCQs) are ubiquitous in almost all levels of\neducation since they are easy to administer, grade, and are a reliable format\nin assessments and practices. One of the most important aspects of MCQs is the\ndistractors, i.e., incorrect options that are designed to target common errors\nor misconceptions among real students. To date, the task of crafting\nhigh-quality distractors largely remains a labor and time-intensive process for\nteachers and learning content designers, which has limited scalability. In this\nwork, we study the task of automated distractor generation in the domain of\nmath MCQs and explore a wide variety of large language model (LLM)-based\napproaches, from in-context learning to fine-tuning. We conduct extensive\nexperiments using a real-world math MCQ dataset and find that although LLMs can\ngenerate some mathematically valid distractors, they are less adept at\nanticipating common errors or misconceptions among real students.", "published": "2024-04-02 17:31:58", "link": "http://arxiv.org/abs/2404.02124v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Informal Language Processing: Knowledge of Slang in Large\n  Language Models", "abstract": "Recent advancement in large language models (LLMs) has offered a strong\npotential for natural language systems to process informal language. A\nrepresentative form of informal language is slang, used commonly in daily\nconversations and online social media. To date, slang has not been\ncomprehensively evaluated in LLMs due partly to the absence of a carefully\ndesigned and publicly accessible benchmark. Using movie subtitles, we construct\na dataset that supports evaluation on a diverse set of tasks pertaining to\nautomatic processing of slang. For both evaluation and finetuning, we show the\neffectiveness of our dataset on two core applications: 1) slang detection, and\n2) identification of regional and historical sources of slang from natural\nsentences. We also show how our dataset can be used to probe the output\ndistributions of LLMs for interpretive insights. We find that while LLMs such\nas GPT-4 achieve good performance in a zero-shot setting, smaller BERT-like\nmodels finetuned on our dataset achieve comparable performance. Furthermore, we\nshow that our dataset enables finetuning of LLMs such as GPT-3.5 that achieve\nsubstantially better performance than strong zero-shot baselines. Our work\noffers a comprehensive evaluation and a high-quality benchmark on English slang\nbased on the OpenSubtitles corpus, serving both as a publicly accessible\nresource and a platform for applying tools for informal language processing.", "published": "2024-04-02 21:50:18", "link": "http://arxiv.org/abs/2404.02323v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corpus Considerations for Annotator Modeling and Scaling", "abstract": "Recent trends in natural language processing research and annotation tasks\naffirm a paradigm shift from the traditional reliance on a single ground truth\nto a focus on individual perspectives, particularly in subjective tasks. In\nscenarios where annotation tasks are meant to encompass diversity, models that\nsolely rely on the majority class labels may inadvertently disregard valuable\nminority perspectives. This oversight could result in the omission of crucial\ninformation and, in a broader context, risk disrupting the balance within\nlarger ecosystems. As the landscape of annotator modeling unfolds with diverse\nrepresentation techniques, it becomes imperative to investigate their\neffectiveness with the fine-grained features of the datasets in view. This\nstudy systematically explores various annotator modeling techniques and\ncompares their performance across seven corpora.\n  From our findings, we show that the commonly used user token model\nconsistently outperforms more complex models. We introduce a composite\nembedding approach and show distinct differences in which model performs best\nas a function of the agreement with a given dataset. Our findings shed light on\nthe relationship between corpus statistics and annotator modeling performance,\nwhich informs future work on corpus construction and perspectivist NLP.", "published": "2024-04-02 22:27:24", "link": "http://arxiv.org/abs/2404.02340v2", "categories": ["cs.CL", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Two Heads are Better than One: Nested PoE for Robust Defense Against\n  Multi-Backdoors", "abstract": "Data poisoning backdoor attacks can cause undesirable behaviors in large\nlanguage models (LLMs), and defending against them is of increasing importance.\nExisting defense mechanisms often assume that only one type of trigger is\nadopted by the attacker, while defending against multiple simultaneous and\nindependent trigger types necessitates general defense frameworks and is\nrelatively unexplored. In this paper, we propose Nested Product of\nExperts(NPoE) defense framework, which involves a mixture of experts (MoE) as a\ntrigger-only ensemble within the PoE defense framework to simultaneously defend\nagainst multiple trigger types. During NPoE training, the main model is trained\nin an ensemble with a mixture of smaller expert models that learn the features\nof backdoor triggers. At inference time, only the main model is used.\nExperimental results on sentiment analysis, hate speech detection, and question\nclassification tasks demonstrate that NPoE effectively defends against a\nvariety of triggers both separately and in trigger mixtures. Due to the\nversatility of the MoE structure in NPoE, this framework can be further\nexpanded to defend against other attack settings", "published": "2024-04-02 22:58:38", "link": "http://arxiv.org/abs/2404.02356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Octopus: On-device language model for function calling of software APIs", "abstract": "In the rapidly evolving domain of artificial intelligence, Large Language\nModels (LLMs) play a crucial role due to their advanced text processing and\ngeneration abilities. This study introduces a new strategy aimed at harnessing\non-device LLMs in invoking software APIs. We meticulously compile a dataset\nderived from software API documentation and apply fine-tuning to LLMs with\ncapacities of 2B, 3B and 7B parameters, specifically to enhance their\nproficiency in software API interactions. Our approach concentrates on refining\nthe models' grasp of API structures and syntax, significantly enhancing the\naccuracy of API function calls. Additionally, we propose \\textit{conditional\nmasking} techniques to ensure outputs in the desired formats and reduce error\nrates while maintaining inference speeds. We also propose a novel benchmark\ndesigned to evaluate the effectiveness of LLMs in API interactions,\nestablishing a foundation for subsequent research. Octopus, the fine-tuned\nmodel, is proved to have better performance than GPT-4 for the software APIs\ncalling. This research aims to advance automated software development and API\nintegration, representing substantial progress in aligning LLM capabilities\nwith the demands of practical software engineering applications.", "published": "2024-04-02 01:29:28", "link": "http://arxiv.org/abs/2404.01549v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Classifying Cancer Stage with Open-Source Clinical Large Language Models", "abstract": "Cancer stage classification is important for making treatment and care\nmanagement plans for oncology patients. Information on staging is often\nincluded in unstructured form in clinical, pathology, radiology and other\nfree-text reports in the electronic health record system, requiring extensive\nwork to parse and obtain. To facilitate the extraction of this information,\nprevious NLP approaches rely on labeled training datasets, which are\nlabor-intensive to prepare. In this study, we demonstrate that without any\nlabeled training data, open-source clinical large language models (LLMs) can\nextract pathologic tumor-node-metastasis (pTNM) staging information from\nreal-world pathology reports. Our experiments compare LLMs and a BERT-based\nmodel fine-tuned using the labeled data. Our findings suggest that while LLMs\nstill exhibit subpar performance in Tumor (T) classification, with the\nappropriate adoption of prompting strategies, they can achieve comparable\nperformance on Metastasis (M) classification and improved performance on Node\n(N) classification.", "published": "2024-04-02 02:30:47", "link": "http://arxiv.org/abs/2404.01589v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entity Disambiguation via Fusion Entity Decoding", "abstract": "Entity disambiguation (ED), which links the mentions of ambiguous entities to\ntheir referent entities in a knowledge base, serves as a core component in\nentity linking (EL). Existing generative approaches demonstrate improved\naccuracy compared to classification approaches under the standardized ZELDA\nbenchmark. Nevertheless, generative approaches suffer from the need for\nlarge-scale pre-training and inefficient generation. Most importantly, entity\ndescriptions, which could contain crucial information to distinguish similar\nentities from each other, are often overlooked. We propose an encoder-decoder\nmodel to disambiguate entities with more detailed entity descriptions. Given\ntext and candidate entities, the encoder learns interactions between the text\nand each candidate entity, producing representations for each entity candidate.\nThe decoder then fuses the representations of entity candidates together and\nselects the correct entity. Our experiments, conducted on various entity\ndisambiguation benchmarks, demonstrate the strong and robust performance of\nthis model, particularly +1.5% in the ZELDA benchmark compared with GENRE.\nFurthermore, we integrate this approach into the retrieval/reader framework and\nobserve +1.5% improvements in end-to-end entity linking in the GERBIL benchmark\ncompared with EntQA.", "published": "2024-04-02 04:27:54", "link": "http://arxiv.org/abs/2404.01626v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards Better Generalization in Open-Domain Question Answering by\n  Mitigating Context Memorization", "abstract": "Open-domain Question Answering (OpenQA) aims at answering factual questions\nwith an external large-scale knowledge corpus. However, real-world knowledge is\nnot static; it updates and evolves continually. Such a dynamic characteristic\nof knowledge poses a vital challenge for these models, as the trained models\nneed to constantly adapt to the latest information to make sure that the\nanswers remain accurate. In addition, it is still unclear how well an OpenQA\nmodel can transfer to completely new knowledge domains. In this paper, we\ninvestigate the generalization performance of a retrieval-augmented QA model in\ntwo specific scenarios: 1) adapting to updated versions of the same knowledge\ncorpus; 2) switching to completely different knowledge domains. We observe that\nthe generalization challenges of OpenQA models stem from the reader's\nover-reliance on memorizing the knowledge from the external corpus, which\nhinders the model from generalizing to a new knowledge corpus. We introduce\nCorpus-Invariant Tuning (CIT), a simple but effective training strategy, to\nmitigate the knowledge over-memorization by controlling the likelihood of\nretrieved contexts during training. Extensive experimental results on multiple\nOpenQA benchmarks show that CIT achieves significantly better generalizability\nwithout compromising the model's performance in its original corpus and domain.", "published": "2024-04-02 05:44:50", "link": "http://arxiv.org/abs/2404.01652v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Generalizable and Faithful Logic Reasoning over Natural Language\n  via Resolution Refutation", "abstract": "Large language models (LLMs) have achieved significant performance in various\nnatural language reasoning tasks. However, they still struggle with performing\nfirst-order logic reasoning over formal logical theories expressed in natural\nlanguage. This is because the previous LLMs-based reasoning systems have the\ntheoretical incompleteness issue. As a result, it can only address a limited\nset of simple reasoning problems, which significantly decreases their\ngeneralization ability. To address this issue, we propose a novel framework,\nnamed Generalizable and Faithful Reasoner (GFaiR), which introduces the\nparadigm of resolution refutation. Resolution refutation has the capability to\nsolve all first-order logic reasoning problems by extending reasoning rules and\nemploying the principle of proof by contradiction, so our system's completeness\ncan be improved by introducing resolution refutation. Experimental results\ndemonstrate that our system outperforms previous works by achieving\nstate-of-the-art performances in complex scenarios while maintaining\nperformances in simple scenarios. Besides, we observe that GFaiR is faithful to\nits reasoning process.", "published": "2024-04-02 06:28:44", "link": "http://arxiv.org/abs/2404.01677v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Stereotype Detection in LLMs: A Multiclass, Explainable, and\n  Benchmark-Driven Approach", "abstract": "Stereotype detection is a challenging and subjective task, as certain\nstatements, such as \"Black people like to play basketball,\" may not appear\novertly toxic but still reinforce racial stereotypes. With the increasing\nprevalence of large language models (LLMs) in human-facing artificial\nintelligence (AI) applications, detecting these types of biases is essential.\nHowever, LLMs risk perpetuating and amplifying stereotypical outputs derived\nfrom their training data. A reliable stereotype detector is crucial for\nbenchmarking bias, monitoring model input and output, filtering training data,\nand ensuring fairer model behavior in downstream applications. This paper\nintroduces the Multi-Grain Stereotype (MGS) dataset, consisting of 51,867\ninstances across gender, race, profession, religion, and other stereotypes,\ncurated from multiple existing datasets. We evaluate various machine learning\napproaches to establish baselines and fine-tune language models of different\narchitectures and sizes, presenting a suite of stereotype multiclass\nclassifiers trained on the MGS dataset. Given the subjectivity of stereotypes,\nexplainability is essential to align model learning with human understanding of\nstereotypes. We employ explainable AI (XAI) tools, including SHAP, LIME, and\nBertViz, to assess whether the model's learned patterns align with human\nintuitions about stereotypes.Additionally, we develop stereotype elicitation\nprompts and benchmark the presence of stereotypes in text generation tasks\nusing popular LLMs, employing the best-performing stereotype classifiers.", "published": "2024-04-02 09:31:32", "link": "http://arxiv.org/abs/2404.01768v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PATCH! Psychometrics-AssisTed benCHmarking of Large Language Models: A\n  Case Study of Proficiency in 8th Grade Mathematics", "abstract": "Many existing benchmarks of large (multimodal) language models (LLMs) focus\non measuring LLMs' academic proficiency, often with also an interest in\ncomparing model performance with human test takers. While these benchmarks have\nproven key to the development of LLMs, they suffer from several limitations,\nincluding questionable measurement quality (e.g., Do they measure what they are\nsupposed to in a reliable way?), lack of quality assessment on the item level\n(e.g., Are some items more important or difficult than others?) and unclear\nhuman population reference (e.g., To whom can the model be compared?). In\nresponse to these challenges, we propose leveraging knowledge from\npsychometrics - a field dedicated to the measurement of latent variables like\nacademic proficiency - into LLM benchmarking. We make three primary\ncontributions. First, we introduce PATCH: a novel framework for\n{P}sychometrics-{A}ssis{T}ed ben{CH}marking of LLMs. PATCH addresses the\naforementioned limitations, presenting a new direction for LLM benchmark\nresearch. Second, we implement PATCH by measuring GPT-4 and Gemini-Pro-Vision's\nproficiency in 8th grade mathematics against 56 human populations. We show that\nadopting a psychometrics-based approach yields evaluation outcomes that diverge\nfrom those based on existing benchmarking practices. Third, we release 4\nhigh-quality datasets to support measuring and comparing LLM proficiency in\ngrade school mathematics and science against human populations.", "published": "2024-04-02 09:58:57", "link": "http://arxiv.org/abs/2404.01799v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Citations in Scientific Articles Using ChatGPT:\n  Identifying Potential Biases and Conflicts of Interest", "abstract": "Scientific articles play a crucial role in advancing knowledge and informing\nresearch directions. One key aspect of evaluating scientific articles is the\nanalysis of citations, which provides insights into the impact and reception of\nthe cited works. This article introduces the innovative use of large language\nmodels, particularly ChatGPT, for comprehensive sentiment analysis of citations\nwithin scientific articles. By leveraging advanced natural language processing\n(NLP) techniques, ChatGPT can discern the nuanced positivity or negativity of\ncitations, offering insights into the reception and impact of cited works.\nFurthermore, ChatGPT's capabilities extend to detecting potential biases and\nconflicts of interest in citations, enhancing the objectivity and reliability\nof scientific literature evaluation. This study showcases the transformative\npotential of artificial intelligence (AI)-powered tools in enhancing citation\nanalysis and promoting integrity in scholarly research.", "published": "2024-04-02 09:59:49", "link": "http://arxiv.org/abs/2404.01800v2", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Detecting Gender Bias in Course Evaluations", "abstract": "An outtake from the findnings of a master thesis studying gender bias in\ncourse evaluations through the lense of machine learning and nlp. We use\ndifferent methods to examine and explore the data and find differences in what\nstudents write about courses depending on gender of the examiner. Data from\nEnglish and Swedish courses are evaluated and compared, in order to capture\nmore nuance in the gender bias that might be found. Here we present the results\nfrom the work so far, but this is an ongoing project and there is more work to\ndo.", "published": "2024-04-02 11:35:05", "link": "http://arxiv.org/abs/2404.01857v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language\n  Models -- A Survey", "abstract": "Large language models (LLMs) have recently shown impressive performance on\ntasks involving reasoning, leading to a lively debate on whether these models\npossess reasoning capabilities similar to humans. However, despite these\nsuccesses, the depth of LLMs' reasoning abilities remains uncertain. This\nuncertainty partly stems from the predominant focus on task performance,\nmeasured through shallow accuracy metrics, rather than a thorough investigation\nof the models' reasoning behavior. This paper seeks to address this gap by\nproviding a comprehensive review of studies that go beyond task accuracy,\noffering deeper insights into the models' reasoning processes. Furthermore, we\nsurvey prevalent methodologies to evaluate the reasoning behavior of LLMs,\nemphasizing current trends and efforts towards more nuanced reasoning analyses.\nOur review suggests that LLMs tend to rely on surface-level patterns and\ncorrelations in their training data, rather than on sophisticated reasoning\nabilities. Additionally, we identify the need for further research that\ndelineates the key differences between human and LLM-based reasoning. Through\nthis survey, we aim to shed light on the complex reasoning processes within\nLLMs.", "published": "2024-04-02 11:46:31", "link": "http://arxiv.org/abs/2404.01869v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity\n  Recognition of Unseen Entities", "abstract": "Recent advances in named entity recognition (NER) have pushed the boundary of\nthe task to incorporate visual signals, leading to many variants, including\nmulti-modal NER (MNER) or grounded MNER (GMNER). A key challenge to these tasks\nis that the model should be able to generalize to the entities unseen during\nthe training, and should be able to handle the training samples with noisy\nannotations. To address this obstacle, we propose SCANNER (Span CANdidate\ndetection and recognition for NER), a model capable of effectively handling all\nthree NER variants. SCANNER is a two-stage structure; we extract entity\ncandidates in the first stage and use it as a query to get knowledge,\neffectively pulling knowledge from various sources. We can boost our\nperformance by utilizing this entity-centric extracted knowledge to address\nunseen entities. Furthermore, to tackle the challenges arising from noisy\nannotations in NER datasets, we introduce a novel self-distillation method,\nenhancing the robustness and accuracy of our model in processing training data\nwith inherent uncertainties. Our approach demonstrates competitive performance\non the NER benchmark and surpasses existing methods on both MNER and GMNER\nbenchmarks. Further analysis shows that the proposed distillation and knowledge\nutilization methods improve the performance of our model on various benchmarks.", "published": "2024-04-02 13:05:41", "link": "http://arxiv.org/abs/2404.01914v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SGSH: Stimulate Large Language Models with Skeleton Heuristics for\n  Knowledge Base Question Generation", "abstract": "Knowledge base question generation (KBQG) aims to generate natural language\nquestions from a set of triplet facts extracted from KB. Existing methods have\nsignificantly boosted the performance of KBQG via pre-trained language models\n(PLMs) thanks to the richly endowed semantic knowledge. With the advance of\npre-training techniques, large language models (LLMs) (e.g., GPT-3.5)\nundoubtedly possess much more semantic knowledge. Therefore, how to effectively\norganize and exploit the abundant knowledge for KBQG becomes the focus of our\nstudy. In this work, we propose SGSH--a simple and effective framework to\nStimulate GPT-3.5 with Skeleton Heuristics to enhance KBQG. The framework\nincorporates \"skeleton heuristics\", which provides more fine-grained guidance\nassociated with each input to stimulate LLMs to generate optimal questions,\nencompassing essential elements like the question phrase and the auxiliary\nverb.More specifically, we devise an automatic data construction strategy\nleveraging ChatGPT to construct a skeleton training dataset, based on which we\nemploy a soft prompting approach to train a BART model dedicated to generating\nthe skeleton associated with each input. Subsequently, skeleton heuristics are\nencoded into the prompt to incentivize GPT-3.5 to generate desired questions.\nExtensive experiments demonstrate that SGSH derives the new state-of-the-art\nperformance on the KBQG tasks.", "published": "2024-04-02 13:17:36", "link": "http://arxiv.org/abs/2404.01923v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classifying Graphemes in English Words Through the Application of a\n  Fuzzy Inference System", "abstract": "In Linguistics, a grapheme is a written unit of a writing system\ncorresponding to a phonological sound. In Natural Language Processing tasks,\nwritten language is analysed through two different mediums, word analysis, and\ncharacter analysis. This paper focuses on a third approach, the analysis of\ngraphemes. Graphemes have advantages over word and character analysis by being\nself-contained representations of phonetic sounds. Due to the nature of\nsplitting a word into graphemes being based on complex, non-binary rules, the\napplication of fuzzy logic would provide a suitable medium upon which to\npredict the number of graphemes in a word. This paper proposes the application\nof a Fuzzy Inference System to split words into their graphemes. This Fuzzy\nInference System results in a correct prediction of the number of graphemes in\na word 50.18% of the time, with 93.51% being within a margin of +- 1 from the\ncorrect classification. Given the variety in language, graphemes are tied with\npronunciation and therefore can change depending on a regional accent/dialect,\nthe +- 1 accuracy represents the impreciseness of grapheme classification when\nregional variances are accounted for. To give a baseline of comparison, a\nsecond method involving a recursive IPA mapping exercise using a pronunciation\ndictionary was developed to allow for comparisons to be made.", "published": "2024-04-02 13:47:52", "link": "http://arxiv.org/abs/2404.01953v1", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "HyperCLOVA X Technical Report", "abstract": "We introduce HyperCLOVA X, a family of large language models (LLMs) tailored\nto the Korean language and culture, along with competitive capabilities in\nEnglish, math, and coding. HyperCLOVA X was trained on a balanced mix of\nKorean, English, and code data, followed by instruction-tuning with\nhigh-quality human-annotated datasets while abiding by strict safety guidelines\nreflecting our commitment to responsible AI. The model is evaluated across\nvarious benchmarks, including comprehensive reasoning, knowledge, commonsense,\nfactuality, coding, math, chatting, instruction-following, and harmlessness, in\nboth Korean and English. HyperCLOVA X exhibits strong reasoning capabilities in\nKorean backed by a deep understanding of the language and cultural nuances.\nFurther analysis of the inherent bilingual nature and its extension to\nmultilingualism highlights the model's cross-lingual proficiency and strong\ngeneralization ability to untargeted languages, including machine translation\nbetween several language pairs and cross-lingual inference tasks. We believe\nthat HyperCLOVA X can provide helpful guidance for regions or countries in\ndeveloping their sovereign LLMs.", "published": "2024-04-02 13:48:49", "link": "http://arxiv.org/abs/2404.01954v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Preuve de concept d'un bot vocal dialoguant en wolof", "abstract": "This paper presents the proof-of-concept of the first automatic voice\nassistant ever built in Wolof language, the main vehicular language spoken in\nSenegal. This voicebot is the result of a collaborative research project\nbetween Orange Innovation in France, Orange Senegal (aka Sonatel) and ADNCorp,\na small IT company based in Dakar, Senegal. The purpose of the voicebot is to\nprovide information to Orange customers about the Sargal loyalty program of\nOrange Senegal by using the most natural mean to communicate: speech. The\nvoicebot receives in input the customer's oral request that is then processed\nby a SLU system to reply to the customer's request using audio recordings. The\nfirst results of this proof-of-concept are encouraging as we achieved 22\\% of\nWER for the ASR task and 78\\% of F1-score on the NLU task.", "published": "2024-04-02 14:53:41", "link": "http://arxiv.org/abs/2404.02009v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MultiParaDetox: Extending Text Detoxification with Parallel Data to New\n  Languages", "abstract": "Text detoxification is a textual style transfer (TST) task where a text is\nparaphrased from a toxic surface form, e.g. featuring rude words, to the\nneutral register. Recently, text detoxification methods found their\napplications in various task such as detoxification of Large Language Models\n(LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic\nspeech combating in social networks (Deng et al., 2023; Mun et al., 2023;\nAgarwal et al., 2023). All these applications are extremely important to ensure\nsafe communication in modern digital worlds. However, the previous approaches\nfor parallel text detoxification corpora collection -- ParaDetox (Logacheva et\nal., 2022) and APPADIA (Atwell et al., 2022) -- were explored only in\nmonolingual setup. In this work, we aim to extend ParaDetox pipeline to\nmultiple languages presenting MultiParaDetox to automate parallel\ndetoxification corpus collection for potentially any language. Then, we\nexperiment with different text detoxification models -- from unsupervised\nbaselines to LLMs and fine-tuned models on the presented parallel corpora --\nshowing the great benefit of parallel corpus presence to obtain\nstate-of-the-art text detoxification models for any language.", "published": "2024-04-02 15:32:32", "link": "http://arxiv.org/abs/2404.02037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Text Classification Transfer: The Case of Ukrainian", "abstract": "Despite the extensive amount of labeled datasets in the NLP text\nclassification field, the persistent imbalance in data availability across\nvarious languages remains evident. To support further fair development of NLP\nmodels, exploring the possibilities of effective knowledge transfer to new\nlanguages is crucial. Ukrainian, in particular, stands as a language that still\ncan benefit from the continued refinement of cross-lingual methodologies. Due\nto our knowledge, there is a tremendous lack of Ukrainian corpora for typical\ntext classification tasks, i.e., different types of style, or harmful speech,\nor texts relationships. However, the amount of resources required for such\ncorpora collection from scratch is understandable. In this work, we leverage\nthe state-of-the-art advances in NLP, exploring cross-lingual knowledge\ntransfer methods avoiding manual data curation: large multilingual encoders and\ntranslation systems, LLMs, and language adapters. We test the approaches on\nthree text classification tasks -- toxicity classification, formality\nclassification, and natural language inference (NLI) -- providing the\n``recipe'' for the optimal setups for each task.", "published": "2024-04-02 15:37:09", "link": "http://arxiv.org/abs/2404.02043v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Long-context LLMs Struggle with Long In-context Learning", "abstract": "Large Language Models (LLMs) have made significant strides in handling long\nsequences. Some models like Gemini could even to be capable of dealing with\nmillions of tokens. However, their performance evaluation has largely been\nconfined to metrics like perplexity and synthetic tasks, which may not fully\ncapture their true abilities in more challenging, real-world scenarios. We\nintroduce a benchmark (LongICLBench) for long in-context learning in\nextreme-label classification using six datasets with 28 to 174 classes and\ninput lengths from 2K to 50K tokens. Our benchmark requires LLMs to comprehend\nthe entire input to recognize the massive label spaces to make correct\npredictions. We evaluate on 15 long-context LLMs and find that they perform\nwell on less challenging classification tasks with smaller label space and\nshorter demonstrations. However, they struggle with more challenging task like\nDiscovery with 174 labels, suggesting a gap in their ability to process long,\ncontext-rich sequences. Further analysis reveals a bias towards labels\npresented later in the sequence and a need for improved reasoning over multiple\npieces of information. Our study reveals that long context understanding and\nreasoning is still a challenging task for the existing LLMs. We believe\nLongICLBench could serve as a more realistic evaluation for the future\nlong-context LLMs.", "published": "2024-04-02 15:59:11", "link": "http://arxiv.org/abs/2404.02060v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GINopic: Topic Modeling with Graph Isomorphism Network", "abstract": "Topic modeling is a widely used approach for analyzing and exploring large\ndocument collections. Recent research efforts have incorporated pre-trained\ncontextualized language models, such as BERT embeddings, into topic modeling.\nHowever, they often neglect the intrinsic informational value conveyed by\nmutual dependencies between words. In this study, we introduce GINopic, a topic\nmodeling framework based on graph isomorphism networks to capture the\ncorrelation between words. By conducting intrinsic (quantitative as well as\nqualitative) and extrinsic evaluations on diverse benchmark datasets, we\ndemonstrate the effectiveness of GINopic compared to existing topic models and\nhighlight its potential for advancing topic modeling.", "published": "2024-04-02 17:18:48", "link": "http://arxiv.org/abs/2404.02115v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rematch: Robust and Efficient Matching of Local Knowledge Graphs to\n  Improve Structural and Semantic Similarity", "abstract": "Knowledge graphs play a pivotal role in various applications, such as\nquestion-answering and fact-checking. Abstract Meaning Representation (AMR)\nrepresents text as knowledge graphs. Evaluating the quality of these graphs\ninvolves matching them structurally to each other and semantically to the\nsource text. Existing AMR metrics are inefficient and struggle to capture\nsemantic similarity. We also lack a systematic evaluation benchmark for\nassessing structural similarity between AMR graphs. To overcome these\nlimitations, we introduce a novel AMR similarity metric, rematch, alongside a\nnew evaluation for structural similarity called RARE. Among state-of-the-art\nmetrics, rematch ranks second in structural similarity; and first in semantic\nsimilarity by 1--5 percentage points on the STS-B and SICK-R benchmarks.\nRematch is also five times faster than the next most efficient metric.", "published": "2024-04-02 17:33:00", "link": "http://arxiv.org/abs/2404.02126v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Emergent Abilities in Reduced-Scale Generative Language Models", "abstract": "Large language models can solve new tasks without task-specific fine-tuning.\nThis ability, also known as in-context learning (ICL), is considered an\nemergent ability and is primarily seen in large language models with billions\nof parameters. This study investigates if such emergent properties are strictly\ntied to model size or can be demonstrated by smaller models trained on\nreduced-scale data. To explore this, we simplify pre-training data and\npre-train 36 causal language models with parameters varying from 1 million to\n165 million parameters. We show that models trained on this simplified\npre-training data demonstrate enhanced zero-shot capabilities across various\ntasks in simplified language, achieving performance comparable to that of\npre-trained models six times larger on unrestricted language. This suggests\nthat downscaling the language allows zero-shot learning capabilities to emerge\nin models with limited size. Additionally, we find that these smaller models\npre-trained on simplified data demonstrate a power law relationship between the\nevaluation loss and the three scaling factors: compute, dataset size, and model\nsize.", "published": "2024-04-02 18:00:28", "link": "http://arxiv.org/abs/2404.02204v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "$\\texttt{LM}^\\texttt{2}$: A Simple Society of Language Models Solves\n  Complex Reasoning", "abstract": "Despite demonstrating emergent reasoning abilities, Large Language Models\n(LLMS) often lose track of complex, multi-step reasoning. Existing studies show\nthat providing guidance via decomposing the original question into multiple\nsubproblems elicits more robustness in LLM reasoning -- a decomposer generates\nthe subproblems, and a solver solves each of these subproblems. However, these\ntechniques fail to accommodate coordination between the decomposer and the\nsolver modules (either in a single model or different specialized ones) -- the\ndecomposer does not keep track of the ability of the solver to follow the\ndecomposed reasoning. In this paper, we propose LM2 to address these\nchallenges. LM2 modularizes the decomposition, solution, and verification into\nthree different language models. The decomposer module identifies the key\nconcepts necessary to solve the problem and generates step-by-step subquestions\naccording to the reasoning requirement. The solver model generates the solution\nto the subproblems that are then checked by the verifier module; depending upon\nthe feedback from the verifier, the reasoning context is constructed using the\nsubproblems and the solutions. These models are trained to coordinate using\npolicy learning. Exhaustive experimentation suggests the superiority of LM2\nover existing methods on in- and out-domain reasoning problems, outperforming\nthe best baselines by $8.1\\%$ on MATH, $7.71\\%$ on JEEBench, and $9.7\\%$ on\nMedQA problems (code available at\nhttps://github.com/LCS2-IIITD/Language_Model_Multiplex).", "published": "2024-04-02 19:23:10", "link": "http://arxiv.org/abs/2404.02255v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mixture-of-Depths: Dynamically allocating compute in transformer-based\n  language models", "abstract": "Transformer-based language models spread FLOPs uniformly across input\nsequences. In this work we demonstrate that transformers can instead learn to\ndynamically allocate FLOPs (or compute) to specific positions in a sequence,\noptimising the allocation along the sequence for different layers across the\nmodel depth. Our method enforces a total compute budget by capping the number\nof tokens ($k$) that can participate in the self-attention and MLP computations\nat a given layer. The tokens to be processed are determined by the network\nusing a top-$k$ routing mechanism. Since $k$ is defined a priori, this simple\nprocedure uses a static computation graph with known tensor sizes, unlike other\nconditional computation techniques. Nevertheless, since the identities of the\n$k$ tokens are fluid, this method can expend FLOPs non-uniformly across the\ntime and model depth dimensions. Thus, compute expenditure is entirely\npredictable in sum total, but dynamic and context-sensitive at the token-level.\nNot only do models trained in this way learn to dynamically allocate compute,\nthey do so efficiently. These models match baseline performance for equivalent\nFLOPS and wall-clock times to train, but require a fraction of the FLOPs per\nforward pass, and can be upwards of 50\\% faster to step during post-training\nsampling.", "published": "2024-04-02 19:28:11", "link": "http://arxiv.org/abs/2404.02258v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Extracting Norms from Contracts Via ChatGPT: Opportunities and\n  Challenges", "abstract": "We investigate the effectiveness of ChatGPT in extracting norms from\ncontracts. Norms provide a natural way to engineer multiagent systems by\ncapturing how to govern the interactions between two or more autonomous\nparties. We extract norms of commitment, prohibition, authorization, and power,\nalong with associated norm elements (the parties involved, antecedents, and\nconsequents) from contracts. Our investigation reveals ChatGPT's effectiveness\nand limitations in norm extraction from contracts. ChatGPT demonstrates\npromising performance in norm extraction without requiring training or\nfine-tuning, thus obviating the need for annotated data, which is not generally\navailable in this domain. However, we found some limitations of ChatGPT in\nextracting these norms that lead to incorrect norm extractions. The limitations\ninclude oversight of crucial details, hallucination, incorrect parsing of\nconjunctions, and empty norm elements. Enhanced norm extraction from contracts\ncan foster the development of more transparent and trustworthy formal agent\ninteraction specifications, thereby contributing to the improvement of\nmultiagent systems.", "published": "2024-04-02 19:49:34", "link": "http://arxiv.org/abs/2404.02269v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Collapse of Self-trained Language Models", "abstract": "In various fields of knowledge creation, including science, new ideas often\nbuild on pre-existing information. In this work, we explore this concept within\nthe context of language models. Specifically, we explore the potential of\nself-training models on their own outputs, akin to how humans learn and build\non their previous thoughts and actions. While this approach is intuitively\nappealing, our research reveals its practical limitations. We find that\nextended self-training of the GPT-2 model leads to a significant degradation in\nperformance, resulting in repetitive and collapsed token output.", "published": "2024-04-02 21:03:37", "link": "http://arxiv.org/abs/2404.02305v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparative Study of Domain Driven Terms Extraction Using Large Language\n  Models", "abstract": "Keywords play a crucial role in bridging the gap between human understanding\nand machine processing of textual data. They are essential to data enrichment\nbecause they form the basis for detailed annotations that provide a more\ninsightful and in-depth view of the underlying data. Keyword/domain driven term\nextraction is a pivotal task in natural language processing, facilitating\ninformation retrieval, document summarization, and content categorization. This\nreview focuses on keyword extraction methods, emphasizing the use of three\nmajor Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. We\nemployed a custom Python package to interface with these LLMs, simplifying\nkeyword extraction. Our study, utilizing the Inspec and PubMed datasets,\nevaluates the performance of these models. The Jaccard similarity index was\nused for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) for\nGPT-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. This\npaper underlines the role of prompt engineering in LLMs for better keyword\nextraction and discusses the impact of hallucination in LLMs on result\nevaluation. It also sheds light on the challenges in using LLMs for keyword\nextraction, including model complexity, resource demands, and optimization\ntechniques.", "published": "2024-04-02 22:04:51", "link": "http://arxiv.org/abs/2404.02330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource\n  Multi-Domain Adaptation", "abstract": "The rapid expansion of texts' volume and diversity presents formidable\nchallenges in multi-domain settings. These challenges are also visible in the\nPersian name entity recognition (NER) settings. Traditional approaches, either\nemploying a unified model for multiple domains or individual models for each\ndomain, frequently pose significant limitations. Single models often struggle\nto capture the nuances of diverse domains, while utilizing multiple large\nmodels can lead to resource constraints, rendering the training of a model for\neach domain virtually impractical. Therefore, this paper introduces a novel\napproach composed of one core model with multiple sets of domain-specific\nparameters. We utilize techniques such as prompt tuning and adapters, combined\nwith the incorporation of additional layers, to add parameters that we can\ntrain for the specific domains. This enables the model to perform comparably to\nindividual models for each domain. Experimental results on different formal and\ninformal datasets show that by employing these added parameters, the proposed\nmodel significantly surpasses existing practical models in performance.\nRemarkably, the proposed model requires only one instance for training and\nstorage, yet achieves outstanding results across all domains, even surpassing\nthe state-of-the-art in some. Moreover, we analyze each adaptation strategy,\ndelineating its strengths, weaknesses, and optimal hyper-parameters for the\nPersian NER settings. Finally, we introduce a document-based domain detection\npipeline tailored for scenarios with unknown text domains, enhancing the\nadaptability and practicality of this paper in real-world applications.", "published": "2024-04-02 22:15:48", "link": "http://arxiv.org/abs/2404.02335v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Large Language Models to Understand Telecom Standards", "abstract": "The Third Generation Partnership Project (3GPP) has successfully introduced\nstandards for global mobility. However, the volume and complexity of these\nstandards has increased over time, thus complicating access to relevant\ninformation for vendors and service providers. Use of Generative Artificial\nIntelligence (AI) and in particular Large Language Models (LLMs), may provide\nfaster access to relevant information. In this paper, we evaluate the\ncapability of state-of-art LLMs to be used as Question Answering (QA)\nassistants for 3GPP document reference. Our contribution is threefold. First,\nwe provide a benchmark and measuring methods for evaluating performance of\nLLMs. Second, we do data preprocessing and fine-tuning for one of these LLMs\nand provide guidelines to increase accuracy of the responses that apply to all\nLLMs. Third, we provide a model of our own, TeleRoBERTa, that performs on-par\nwith foundation LLMs but with an order of magnitude less number of parameters.\nResults show that LLMs can be used as a credible reference tool on telecom\ntechnical documents, and thus have potential for a number of different\napplications from troubleshooting and maintenance, to network operations and\nsoftware product development.", "published": "2024-04-02 09:54:51", "link": "http://arxiv.org/abs/2404.02929v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "READ: Improving Relation Extraction from an ADversarial Perspective", "abstract": "Recent works in relation extraction (RE) have achieved promising benchmark\naccuracy; however, our adversarial attack experiments show that these works\nexcessively rely on entities, making their generalization capability\nquestionable. To address this issue, we propose an adversarial training method\nspecifically designed for RE. Our approach introduces both sequence- and\ntoken-level perturbations to the sample and uses a separate perturbation\nvocabulary to improve the search for entity and context perturbations.\nFurthermore, we introduce a probabilistic strategy for leaving clean tokens in\nthe context during adversarial training. This strategy enables a larger attack\nbudget for entities and coaxes the model to leverage relational patterns\nembedded in the context. Extensive experiments show that compared to various\nadversarial training methods, our method significantly improves both the\naccuracy and robustness of the model. Additionally, experiments on different\ndata availability settings highlight the effectiveness of our method in\nlow-resource scenarios. We also perform in-depth analyses of our proposed\nmethod and provide further hints. We will release our code at\nhttps://github.com/David-Li0406/READ.", "published": "2024-04-02 16:42:44", "link": "http://arxiv.org/abs/2404.02931v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When Abel Kills Cain: What Machine Translation Cannot Capture", "abstract": "The article aims at identifying what, from a structural point of view, AI\nbased automatic translators cannot fully capture. It focuses on the machine's\nmistakes, in order to try to explain its causes. The biblical story of Ca\\\"in\nand Abel has been chosen because of its rich interpretive and critical\ntradition, but also because of its semantic difficulty. The investigation\nbegins with the observation, for the translation of this text, of the language\npairs and interfaces offered by the best known machine translation services\n(Google Translate, DeepL). A typology of the most frequent translation errors\nis then established. Finally, contemporary translations are compared, in order\nto underline the unique contribution of each. In conclusion, the article\nsuggests a revision of translation theory and, corArtificial Intelligence,\nTranslation, Limitations, Interpretation, Comparison, Unicityelatively, a\nreformulation of its technology concerning cultural texts.", "published": "2024-04-02 12:46:00", "link": "http://arxiv.org/abs/2404.04279v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal\n  Model Inference", "abstract": "In response to the rising interest in large multimodal models, we introduce\nCross-Attention Token Pruning (CATP), a precision-focused token pruning method.\nOur approach leverages cross-attention layers in multimodal models, exemplified\nby BLIP-2, to extract valuable information for token importance determination.\nCATP employs a refined voting strategy across model heads and layers. In\nevaluations, CATP achieves up to 12.1X higher accuracy compared to existing\ntoken pruning methods, addressing the trade-off between computational\nefficiency and model precision.", "published": "2024-04-02 04:35:35", "link": "http://arxiv.org/abs/2404.08567v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Planning Domain Generators", "abstract": "Developing domain models is one of the few remaining places that require\nmanual human labor in AI planning. Thus, in order to make planning more\naccessible, it is desirable to automate the process of domain model generation.\nTo this end, we investigate if large language models (LLMs) can be used to\ngenerate planning domain models from simple textual descriptions. Specifically,\nwe introduce a framework for automated evaluation of LLM-generated domains by\ncomparing the sets of plans for domain instances. Finally, we perform an\nempirical analysis of 7 large language models, including coding and chat models\nacross 9 different planning domains, and under three classes of natural\nlanguage domain descriptions. Our results indicate that LLMs, particularly\nthose with high parameter counts, exhibit a moderate level of proficiency in\ngenerating correct planning domains from natural language descriptions. Our\ncode is available at https://github.com/IBM/NL2PDDL.", "published": "2024-04-02 19:39:23", "link": "http://arxiv.org/abs/2405.06650v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Laying Anchors: Semantically Priming Numerals in Language Modeling", "abstract": "Off-the-shelf pre-trained language models have become the de facto standard\nin NLP pipelines for a multitude of downstream tasks. However, the inability of\nthese models to properly encode numerals limits their performance on tasks\nrequiring numeric comprehension. We introduce strategies to semantically prime\nnumerals in any corpus by generating anchors governed by the distribution of\nnumerals in said corpus, thereby enabling mathematically grounded\nrepresentations of these numeral tokens. We establish the superiority of our\nproposed techniques through evaluation on a range of numeracy tasks for both\nin-domain (seen) and out-domain (unseen) numerals. Further, we expand our\nempirical evaluations to numerals ranging from 1 to 10 billion, a significantly\nbroader range compared to previous studies of the same nature, and we\ndemonstrate significant improvements in the mathematical grounding of our\nlearned embeddings.", "published": "2024-04-02 00:02:00", "link": "http://arxiv.org/abs/2404.01536v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models Using Contrast Sets: An Experimental\n  Approach", "abstract": "In the domain of Natural Language Inference (NLI), especially in tasks\ninvolving the classification of multiple input texts, the Cross-Entropy Loss\nmetric is widely employed as a standard for error measurement. However, this\nmetric falls short in effectively evaluating a model's capacity to understand\nlanguage entailments. In this study, we introduce an innovative technique for\ngenerating a contrast set for the Stanford Natural Language Inference (SNLI)\ndataset. Our strategy involves the automated substitution of verbs, adverbs,\nand adjectives with their synonyms to preserve the original meaning of\nsentences. This method aims to assess whether a model's performance is based on\ngenuine language comprehension or simply on pattern recognition. We conducted\nour analysis using the ELECTRA-small model. The model achieved an accuracy of\n89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5%\non our contrast set, indicating a substantial 17% decline. This outcome led us\nto conduct a detailed examination of the model's learning behaviors. Following\nthis, we improved the model's resilience by fine-tuning it with a\ncontrast-enhanced training dataset specifically designed for SNLI, which\nincreased its accuracy to 85.5% on the contrast sets. Our findings highlight\nthe importance of incorporating diverse linguistic expressions into datasets\nfor NLI tasks. We hope that our research will encourage the creation of more\ninclusive datasets, thereby contributing to the development of NLI models that\nare both more sophisticated and effective.", "published": "2024-04-02 02:03:28", "link": "http://arxiv.org/abs/2404.01569v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hallucination Diversity-Aware Active Learning for Text Summarization", "abstract": "Large Language Models (LLMs) have shown propensity to generate hallucinated\noutputs, i.e., texts that are factually incorrect or unsupported. Existing\nmethods for alleviating hallucinations typically require costly human\nannotations to identify and correct hallucinations in LLM outputs. Moreover,\nmost of these methods focus on a specific type of hallucination, e.g., entity\nor token errors, which limits their effectiveness in addressing various types\nof hallucinations exhibited in LLM outputs. To our best knowledge, in this\npaper we propose the first active learning framework to alleviate LLM\nhallucinations, reducing costly human annotations of hallucination needed. By\nmeasuring fine-grained hallucinations from errors in semantic frame, discourse\nand content verifiability in text summarization, we propose HAllucination\nDiversity-Aware Sampling (HADAS) to select diverse hallucinations for\nannotations in active learning for LLM finetuning. Extensive experiments on\nthree datasets and different backbone models demonstrate advantages of our\nmethod in effectively and efficiently mitigating LLM hallucinations.", "published": "2024-04-02 02:30:27", "link": "http://arxiv.org/abs/2404.01588v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Helmsman of the Masses? Evaluate the Opinion Leadership of Large\n  Language Models in the Werewolf Game", "abstract": "Large language models (LLMs) have exhibited memorable strategic behaviors in\nsocial deductive games. However, the significance of opinion leadership\nexhibited by LLM-based agents has been largely overlooked, which is crucial for\npractical applications in multi-agent and human-AI interaction settings.\nOpinion leaders are individuals who have a noticeable impact on the beliefs and\nbehaviors of others within a social group. In this work, we employ the Werewolf\ngame as a simulation platform to assess the opinion leadership of LLMs. The\ngame includes the role of the Sheriff, tasked with summarizing arguments and\nrecommending decision options, and therefore serves as a credible proxy for an\nopinion leader. We develop a framework integrating the Sheriff role and devise\ntwo novel metrics based on the critical characteristics of opinion leaders. The\nfirst metric measures the reliability of the opinion leader, and the second\nassesses the influence of the opinion leader on other players' decisions. We\nconduct extensive experiments to evaluate LLMs of different scales. In\naddition, we collect a Werewolf question-answering dataset (WWQA) to assess and\nenhance LLM's grasp of the game rules, and we also incorporate human\nparticipants for further analysis. The results suggest that the Werewolf game\nis a suitable test bed to evaluate the opinion leadership of LLMs, and few LLMs\npossess the capacity for opinion leadership.", "published": "2024-04-02 02:46:18", "link": "http://arxiv.org/abs/2404.01602v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Transforming LLMs into Cross-modal and Cross-lingual Retrieval Systems", "abstract": "Large language models (LLMs) are trained on text-only data that go far beyond\nthe languages with paired speech and text data. At the same time, Dual Encoder\n(DE) based retrieval systems project queries and documents into the same\nembedding space and have demonstrated their success in retrieval and bi-text\nmining. To match speech and text in many languages, we propose using LLMs to\ninitialize multi-modal DE retrieval systems. Unlike traditional methods, our\nsystem doesn't require speech data during LLM pre-training and can exploit\nLLM's multilingual text understanding capabilities to match speech and text in\nlanguages unseen during retrieval training. Our multi-modal LLM-based retrieval\nsystem is capable of matching speech and text in 102 languages despite only\ntraining on 21 languages. Our system outperforms previous systems trained\nexplicitly on all 102 languages. We achieve a 10% absolute improvement in\nRecall@1 averaged across these languages. Additionally, our model demonstrates\ncross-lingual speech and text matching, which is further enhanced by readily\navailable machine translation data.", "published": "2024-04-02 03:42:28", "link": "http://arxiv.org/abs/2404.01616v3", "categories": ["cs.CL", "cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but\n  Teaching the Distinction Helps", "abstract": "The use of words to convey speaker's intent is traditionally distinguished\nfrom the `mention' of words for quoting what someone said, or pointing out\nproperties of a word. Here we show that computationally modeling this\nuse-mention distinction is crucial for dealing with counterspeech online.\nCounterspeech that refutes problematic content often mentions harmful language\nbut is not harmful itself (e.g., calling a vaccine dangerous is not the same as\nexpressing disapproval of someone for calling vaccines dangerous). We show that\neven recent language models fail at distinguishing use from mention, and that\nthis failure propagates to two key downstream tasks: misinformation and hate\nspeech detection, resulting in censorship of counterspeech. We introduce\nprompting mitigations that teach the use-mention distinction, and show they\nreduce these errors. Our work highlights the importance of the use-mention\ndistinction for NLP and CSS and offers ways to address it.", "published": "2024-04-02 05:36:41", "link": "http://arxiv.org/abs/2404.01651v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.SI"], "primary_category": "cs.CL"}
{"title": "CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small\n  Language Models", "abstract": "Open large language models (LLMs) have significantly advanced the field of\nnatural language processing, showcasing impressive performance across various\ntasks.Despite the significant advancements in LLMs, their effective operation\nstill relies heavily on human input to accurately guide the dialogue flow, with\nagent tuning being a crucial optimization technique that involves human\nadjustments to the model for better response to such guidance.Addressing this\ndependency, our work introduces the TinyAgent model, trained on a meticulously\ncurated high-quality dataset. We also present the Collaborative Multi-Agent\nTuning (CMAT) framework, an innovative system designed to augment language\nagent capabilities through adaptive weight updates based on environmental\nfeedback. This framework fosters collaborative learning and real-time\nadaptation among multiple intelligent agents, enhancing their context-awareness\nand long-term memory. In this research, we propose a new communication agent\nframework that integrates multi-agent systems with environmental feedback\nmechanisms, offering a scalable method to explore cooperative behaviors.\nNotably, our TinyAgent-7B model exhibits performance on par with GPT-3.5,\ndespite having fewer parameters, signifying a substantial improvement in the\nefficiency and effectiveness of LLMs.", "published": "2024-04-02 06:07:35", "link": "http://arxiv.org/abs/2404.01663v5", "categories": ["cs.CL", "cs.AI", "cs.CC"], "primary_category": "cs.CL"}
{"title": "Event Detection from Social Media for Epidemic Prediction", "abstract": "Social media is an easy-to-access platform providing timely updates about\nsocietal trends and events. Discussions regarding epidemic-related events such\nas infections, symptoms, and social interactions can be crucial for informing\npolicymaking during epidemic outbreaks. In our work, we pioneer exploiting\nEvent Detection (ED) for better preparedness and early warnings of any upcoming\nepidemic by developing a framework to extract and analyze epidemic-related\nevents from social media posts. To this end, we curate an epidemic event\nontology comprising seven disease-agnostic event types and construct a Twitter\ndataset SPEED with human-annotated events focused on the COVID-19 pandemic.\nExperimentation reveals how ED models trained on COVID-based SPEED can\neffectively detect epidemic events for three unseen epidemics of Monkeypox,\nZika, and Dengue; while models trained on existing ED datasets fail miserably.\nFurthermore, we show that reporting sharp increases in the extracted events by\nour framework can provide warnings 4-9 weeks earlier than the WHO epidemic\ndeclaration for Monkeypox. This utility of our framework lays the foundations\nfor better preparedness against emerging epidemics.", "published": "2024-04-02 06:31:17", "link": "http://arxiv.org/abs/2404.01679v2", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Effective internal language model training and fusion for factorized\n  transducer model", "abstract": "The internal language model (ILM) of the neural transducer has been widely\nstudied. In most prior work, it is mainly used for estimating the ILM score and\nis subsequently subtracted during inference to facilitate improved integration\nwith external language models. Recently, various of factorized transducer\nmodels have been proposed, which explicitly embrace a standalone internal\nlanguage model for non-blank token prediction. However, even with the adoption\nof factorized transducer models, limited improvement has been observed compared\nto shallow fusion. In this paper, we propose a novel ILM training and decoding\nstrategy for factorized transducer models, which effectively combines the\nblank, acoustic and ILM scores. Our experiments show a 17% relative improvement\nover the standard decoding method when utilizing a well-trained ILM and the\nproposed decoding strategy on LibriSpeech datasets. Furthermore, when compared\nto a strong RNN-T baseline enhanced with external LM fusion, the proposed model\nyields a 5.5% relative improvement on general-sets and an 8.9% WER reduction\nfor rare words. The proposed model can achieve superior performance without\nrelying on external language models, rendering it highly efficient for\nproduction use-cases. To further improve the performance, we propose a novel\nand memory-efficient ILM-fusion-aware minimum word error rate (MWER) training\nmethod which improves ILM integration significantly.", "published": "2024-04-02 08:01:05", "link": "http://arxiv.org/abs/2404.01716v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Transfer Learning from Whisper for Microscopic Intelligibility\n  Prediction", "abstract": "Macroscopic intelligibility models predict the expected human word-error-rate\nfor a given speech-in-noise stimulus. In contrast, microscopic intelligibility\nmodels aim to make fine-grained predictions about listeners' perception, e.g.\npredicting phonetic or lexical responses. State-of-the-art macroscopic models\nuse transfer learning from large scale deep learning models for speech\nprocessing, whereas such methods have rarely been used for microscopic\nmodeling. In this paper, we study the use of transfer learning from Whisper, a\nstate-of-the-art deep learning model for automatic speech recognition, for\nmicroscopic intelligibility prediction at the level of lexical responses. Our\nmethod outperforms the considered baselines, even in a zero-shot setup, and\nyields a relative improvement of up to 66\\% when fine-tuned to predict\nlisteners' responses. Our results showcase the promise of large scale deep\nlearning based methods for microscopic intelligibility prediction.", "published": "2024-04-02 08:53:51", "link": "http://arxiv.org/abs/2404.01737v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A (More) Realistic Evaluation Setup for Generalisation of Community\n  Models on Malicious Content Detection", "abstract": "Community models for malicious content detection, which take into account the\ncontext from a social graph alongside the content itself, have shown remarkable\nperformance on benchmark datasets. Yet, misinformation and hate speech continue\nto propagate on social media networks. This mismatch can be partially\nattributed to the limitations of current evaluation setups that neglect the\nrapid evolution of online content and the underlying social graph. In this\npaper, we propose a novel evaluation setup for model generalisation based on\nour few-shot subgraph sampling approach. This setup tests for generalisation\nthrough few labelled examples in local explorations of a larger graph,\nemulating more realistic application settings. We show this to be a challenging\ninductive setup, wherein strong performance on the training graph is not\nindicative of performance on unseen tasks, domains, or graph structures.\nLastly, we show that graph meta-learners trained with our proposed few-shot\nsubgraph sampling outperform standard community models in the inductive setup.\nWe make our code publicly available.", "published": "2024-04-02 10:32:21", "link": "http://arxiv.org/abs/2404.01822v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Understanding How CodeLLMs (Mis)Predict Types with Activation Steering", "abstract": "CodeLLMs are transforming software development as we know it. This is\nespecially true for tasks where rule-based approaches fall short, like type\nprediction. The type prediction task consists in adding a new type annotation\nto a partially typed program, such that the resulting program is closer to\nbeing fully typed. The intractability of rule-based approaches and high cost of\nmanual annotation make CodeLLMs an attractive solution to the problem. However,\nCodeLLMs are still far from being deployed on the large-scale due to doubts\nsurrounding their reliability.\n  To shed some light on how CodeLLMs approach type prediction, we investigate\nwhat happens when a model mispredicts a type. We show that by applying\nsemantics-preserving edits to code, CodeLLMs are eventually misled into\nmispredicting type annotations. However, by leveraging activation steering we\nare able to \"steer\" the model back to the correct prediction, making models\nmore robust against semantically irrelevant prompt features. We show that\nsteering achieves comparable performance to fine-tuning directly on the type\nprediction task. Furthermore, we find that steering vectors computed from\nPython code are effective at correcting TypeScript mispredictions, and vice\nversa. To our knowledge, this is the first evidence of its kind to suggest that\nCodeLLMs learn task representations that transfer across languages.", "published": "2024-04-02 12:44:44", "link": "http://arxiv.org/abs/2404.01903v2", "categories": ["cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Humanizing Machine-Generated Content: Evading AI-Text Detection through\n  Adversarial Attack", "abstract": "With the development of large language models (LLMs), detecting whether text\nis generated by a machine becomes increasingly challenging in the face of\nmalicious use cases like the spread of false information, protection of\nintellectual property, and prevention of academic plagiarism. While\nwell-trained text detectors have demonstrated promising performance on unseen\ntest data, recent research suggests that these detectors have vulnerabilities\nwhen dealing with adversarial attacks such as paraphrasing. In this paper, we\npropose a framework for a broader class of adversarial attacks, designed to\nperform minor perturbations in machine-generated content to evade detection. We\nconsider two attack settings: white-box and black-box, and employ adversarial\nlearning in dynamic scenarios to assess the potential enhancement of the\ncurrent detection model's robustness against such attacks. The empirical\nresults reveal that the current detection models can be compromised in as\nlittle as 10 seconds, leading to the misclassification of machine-generated\ntext as human-written content. Furthermore, we explore the prospect of\nimproving the model's robustness over iterative adversarial learning. Although\nsome improvements in model robustness are observed, practical applications\nstill face significant challenges. These findings shed light on the future\ndevelopment of AI-text detectors, emphasizing the need for more accurate and\nrobust detection methods.", "published": "2024-04-02 12:49:22", "link": "http://arxiv.org/abs/2404.01907v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DELAN: Dual-Level Alignment for Vision-and-Language Navigation by\n  Cross-Modal Contrastive Learning", "abstract": "Vision-and-Language navigation (VLN) requires an agent to navigate in unseen\nenvironment by following natural language instruction. For task completion, the\nagent needs to align and integrate various navigation modalities, including\ninstruction, observation and navigation history. Existing works primarily\nconcentrate on cross-modal attention at the fusion stage to achieve this\nobjective. Nevertheless, modality features generated by disparate uni-encoders\nreside in their own spaces, leading to a decline in the quality of cross-modal\nfusion and decision. To address this problem, we propose a Dual-levEL AligNment\n(DELAN) framework by cross-modal contrastive learning. This framework is\ndesigned to align various navigation-related modalities before fusion, thereby\nenhancing cross-modal interaction and action decision-making. Specifically, we\ndivide the pre-fusion alignment into dual levels: instruction-history level and\nlandmark-observation level according to their semantic correlations. We also\nreconstruct a dual-level instruction for adaptation to the dual-level\nalignment. As the training signals for pre-fusion alignment are extremely\nlimited, self-supervised contrastive learning strategies are employed to\nenforce the matching between different modalities. Our approach seamlessly\nintegrates with the majority of existing models, resulting in improved\nnavigation performance on various VLN benchmarks, including R2R, R4R, RxR and\nCVDN.", "published": "2024-04-02 14:40:04", "link": "http://arxiv.org/abs/2404.01994v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Africa-Centric Self-Supervised Pre-Training for Multilingual Speech\n  Representation in a Sub-Saharan Context", "abstract": "We present the first self-supervised multilingual speech model trained\nexclusively on African speech. The model learned from nearly 60 000 hours of\nunlabeled speech segments in 21 languages and dialects spoken in sub-Saharan\nAfrica. On the SSA subset of the FLEURS-102 dataset, our approach based on a\nHuBERT$_{base}$ (0.09B) architecture shows competitive results, for ASR\ndownstream task, compared to the w2v-bert-51 (0.6B) pre-trained model proposed\nin the FLEURS benchmark, while being more efficient by using 7x less data and\n6x less parameters. Furthermore, in the context of a LID downstream task, our\napproach outperforms FLEURS baselines accuracy by over 22\\%.", "published": "2024-04-02 14:43:36", "link": "http://arxiv.org/abs/2404.02000v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "BERTopic-Driven Stock Market Predictions: Unraveling Sentiment Insights", "abstract": "This paper explores the intersection of Natural Language Processing (NLP) and\nfinancial analysis, focusing on the impact of sentiment analysis in stock price\nprediction. We employ BERTopic, an advanced NLP technique, to analyze the\nsentiment of topics derived from stock market comments. Our methodology\nintegrates this sentiment analysis with various deep learning models, renowned\nfor their effectiveness in time series and stock prediction tasks. Through\ncomprehensive experiments, we demonstrate that incorporating topic sentiment\nnotably enhances the performance of these models. The results indicate that\ntopics in stock market comments provide implicit, valuable insights into stock\nmarket volatility and price trends. This study contributes to the field by\nshowcasing the potential of NLP in enriching financial analysis and opens up\navenues for further research into real-time sentiment analysis and the\nexploration of emotional and contextual aspects of market sentiment. The\nintegration of advanced NLP techniques like BERTopic with traditional financial\nanalysis methods marks a step forward in developing more sophisticated tools\nfor understanding and predicting market behaviors.", "published": "2024-04-02 15:50:10", "link": "http://arxiv.org/abs/2404.02053v2", "categories": ["cs.CL", "cs.CE", "q-fin.ST"], "primary_category": "cs.CL"}
{"title": "Advancing LLM Reasoning Generalists with Preference Trees", "abstract": "We introduce Eurus, a suite of large language models (LLMs) optimized for\nreasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve\nstate-of-the-art results among open-source models on a diverse set of\nbenchmarks covering mathematics, code generation, and logical reasoning\nproblems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a\ncomprehensive benchmarking across 12 tests covering five tasks, and achieves a\n33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging\nbenchmarks, substantially outperforming existing open-source models by margins\nmore than 13.3%. The strong performance of Eurus can be primarily attributed to\nUltraInteract, our newly-curated large-scale, high-quality alignment dataset\nspecifically designed for complex reasoning tasks. UltraInteract can be used in\nboth supervised fine-tuning and preference learning. For each instruction, it\nincludes a preference tree consisting of (1) reasoning chains with diverse\nplanning strategies in a unified format, (2) multi-turn interaction\ntrajectories with the environment and the critique, and (3) pairwise data to\nfacilitate preference learning. UltraInteract allows us to conduct an in-depth\nexploration of preference learning for reasoning tasks. Our investigation\nreveals that some well-established preference learning algorithms may be less\nsuitable for reasoning tasks compared to their effectiveness in general\nconversations. Inspired by this, we derive a novel reward modeling objective\nwhich, together with UltraInteract, leads to a strong reward model.", "published": "2024-04-02 16:25:30", "link": "http://arxiv.org/abs/2404.02078v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "LastResort at SemEval-2024 Task 3: Exploring Multimodal Emotion Cause\n  Pair Extraction as Sequence Labelling Task", "abstract": "Conversation is the most natural form of human communication, where each\nutterance can range over a variety of possible emotions. While significant work\nhas been done towards the detection of emotions in text, relatively little work\nhas been done towards finding the cause of the said emotions, especially in\nmultimodal settings. SemEval 2024 introduces the task of Multimodal Emotion\nCause Analysis in Conversations, which aims to extract emotions reflected in\nindividual utterances in a conversation involving multiple modalities (textual,\naudio, and visual modalities) along with the corresponding utterances that were\nthe cause for the emotion. In this paper, we propose models that tackle this\ntask as an utterance labeling and a sequence labeling problem and perform a\ncomparative study of these models, involving baselines using different\nencoders, using BiLSTM for adding contextual information of the conversation,\nand finally adding a CRF layer to try to model the inter-dependencies between\nadjacent utterances more effectively. In the official leaderboard for the task,\nour architecture was ranked 8th, achieving an F1-score of 0.1759 on the\nleaderboard.", "published": "2024-04-02 16:32:49", "link": "http://arxiv.org/abs/2404.02088v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LawInstruct: A Resource for Studying Language Model Adaptation to the\n  Legal Domain", "abstract": "Instruction tuning is an important step in making language models useful for\ndirect user interaction. However, the legal domain is underrepresented in\ntypical instruction datasets (e.g., only 10 out of 1600+ tasks in\nSuper-NaturalInstructions). To study whether instruction tuning on legal\ndatasets is necessary for strong legal reasoning, we aggregate 58 annotated\nlegal datasets and write instructions for each, creating LawInstruct.\nLawInstruct covers 17 global jurisdictions, 24 languages and a total of 12M\nexamples across diverse tasks such as legal QA, summarization of court cases,\nand legal argument mining. We evaluate our models on LegalBench, measuring\nlegal reasoning across five categories in 162 challenging and realistic legal\ntasks, and MMLU, to measure potential drops in general reasoning capabilities.\nWe find that legal-specific instruction tuning on Flan-T5 - yielding FLawN-T5 -\nimproves performance on LegalBench across all model sizes, with an aggregate\nincrease of 15 points or 50% over Flan-T5 for the base size. No model size\nshows performance drops in MMLU. We publish LawInstruct as a resource for\nfurther study of instruction tuning in the legal domain.", "published": "2024-04-02 17:33:34", "link": "http://arxiv.org/abs/2404.02127v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2"], "primary_category": "cs.CL"}
{"title": "Topic-Based Watermarks for Large Language Models", "abstract": "The indistinguishability of Large Language Model (LLM) output from\nhuman-authored content poses significant challenges, raising concerns about\npotential misuse of AI-generated text and its influence on future AI model\ntraining. Watermarking algorithms offer a viable solution by embedding\ndetectable signatures into generated text. However, existing watermarking\nmethods often entail trade-offs among attack robustness, generation quality,\nand additional overhead such as specialized frameworks or complex integrations.\nWe propose a lightweight, topic-guided watermarking scheme for LLMs that\npartitions the vocabulary into topic-aligned token subsets. Given an input\nprompt, the scheme selects a relevant topic-specific token list, effectively\n\"green-listing\" semantically aligned tokens to embed robust marks while\npreserving the text's fluency and coherence. Experimental results across\nmultiple LLMs and state-of-the-art benchmarks demonstrate that our method\nachieves comparable perplexity to industry-leading systems, including Google's\nSynthID-Text, yet enhances watermark robustness against paraphrasing and\nlexical perturbation attacks while introducing minimal performance overhead.\nOur approach avoids reliance on additional mechanisms beyond standard text\ngeneration pipelines, facilitating straightforward adoption, suggesting a\npractical path toward globally consistent watermarking of AI-generated content.", "published": "2024-04-02 17:49:40", "link": "http://arxiv.org/abs/2404.02138v4", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "LLMs in the Loop: Leveraging Large Language Model Annotations for Active\n  Learning in Low-Resource Languages", "abstract": "Low-resource languages face significant barriers in AI development due to\nlimited linguistic resources and expertise for data labeling, rendering them\nrare and costly. The scarcity of data and the absence of preexisting tools\nexacerbate these challenges, especially since these languages may not be\nadequately represented in various NLP datasets. To address this gap, we propose\nleveraging the potential of LLMs in the active learning loop for data\nannotation. Initially, we conduct evaluations to assess inter-annotator\nagreement and consistency, facilitating the selection of a suitable LLM\nannotator. The chosen annotator is then integrated into a training loop for a\nclassifier using an active learning paradigm, minimizing the amount of queried\ndata required. Empirical evaluations, notably employing GPT-4-Turbo,\ndemonstrate near-state-of-the-art performance with significantly reduced data\nrequirements, as indicated by estimated potential cost savings of at least\n42.45 times compared to human annotation. Our proposed solution shows promising\npotential to substantially reduce both the monetary and computational costs\nassociated with automation in low-resource settings. By bridging the gap\nbetween low-resource languages and AI, this approach fosters broader inclusion\nand shows the potential to enable automation across diverse linguistic\nlandscapes.", "published": "2024-04-02 19:34:22", "link": "http://arxiv.org/abs/2404.02261v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient\n  Compile-Time Prompt Optimization", "abstract": "In many modern LLM applications, such as retrieval augmented generation,\nprompts have become programs themselves. In these settings, prompt programs are\nrepeatedly called with different user queries or data instances. A big\npractical challenge is optimizing such prompt programs. Recent work has mostly\nfocused on either simple prompt programs or assumed that the general structure\nof a prompt program is fixed.\n  We introduce SAMMO, a framework to perform symbolic prompt program search for\ncompile-time optimizations of prompt programs. SAMMO represents prompt programs\non a symbolic level which allows for a rich set of transformations that can be\nsearched over during optimization. We show that SAMMO generalizes previous\nmethods and improves the performance of complex prompts on (1) instruction\ntuning, (2) RAG pipeline tuning, and (3) prompt compression, across several\ndifferent LLMs. We make all code available open-source at\nhttps://github.com/microsoft/sammo .", "published": "2024-04-02 21:35:54", "link": "http://arxiv.org/abs/2404.02319v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Computational Analysis of Lyric Similarity Perception", "abstract": "In musical compositions that include vocals, lyrics significantly contribute\nto artistic expression. Consequently, previous studies have introduced the\nconcept of a recommendation system that suggests lyrics similar to a user's\nfavorites or personalized preferences, aiding in the discovery of lyrics among\nmillions of tracks. However, many of these systems do not fully consider human\nperceptions of lyric similarity, primarily due to limited research in this\narea. To bridge this gap, we conducted a comparative analysis of computational\nmethods for modeling lyric similarity with human perception. Results indicated\nthat computational models based on similarities between embeddings from\npre-trained BERT-based models, the audio from which the lyrics are derived, and\nphonetic components are indicative of perceptual lyric similarity. This finding\nunderscores the importance of semantic, stylistic, and phonetic similarities in\nhuman perception about lyric similarity. We anticipate that our findings will\nenhance the development of similarity-based lyric recommendation systems by\noffering pseudo-labels for neural network development and introducing objective\nevaluation metrics.", "published": "2024-04-02 22:31:38", "link": "http://arxiv.org/abs/2404.02342v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Inference Efficiency of Large Language Models: Investigating\n  Optimization Strategies and Architectural Innovations", "abstract": "Large Language Models are growing in size, and we expect them to continue to\ndo so, as larger models train quicker. However, this increase in size will\nseverely impact inference costs. Therefore model compression is important, to\nretain the performance of larger models, but with a reduced cost of running\nthem. In this thesis we explore the methods of model compression, and we\nempirically demonstrate that the simple method of skipping latter attention\nsublayers in Transformer LLMs is an effective method of model compression, as\nthese layers prove to be redundant, whilst also being incredibly\ncomputationally expensive. We observed a 21% speed increase in one-token\ngeneration for Llama 2 7B, whilst surprisingly and unexpectedly improving\nperformance over several common benchmarks.", "published": "2024-04-02 19:53:54", "link": "http://arxiv.org/abs/2404.05741v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Risks from Language Models for Automated Mental Healthcare: Ethics and\n  Structure for Implementation", "abstract": "Amidst the growing interest in developing task-autonomous AI for automated\nmental health care, this paper addresses the ethical and practical challenges\nassociated with the issue and proposes a structured framework that delineates\nlevels of autonomy, outlines ethical requirements, and defines beneficial\ndefault behaviors for AI agents in the context of mental health support. We\nalso evaluate fourteen state-of-the-art language models (ten off-the-shelf,\nfour fine-tuned) using 16 mental health-related questionnaires designed to\nreflect various mental health conditions, such as psychosis, mania, depression,\nsuicidal thoughts, and homicidal tendencies. The questionnaire design and\nresponse evaluations were conducted by mental health clinicians (M.D.s). We\nfind that existing language models are insufficient to match the standard\nprovided by human professionals who can navigate nuances and appreciate\ncontext. This is due to a range of issues, including overly cautious or\nsycophantic responses and the absence of necessary safeguards. Alarmingly, we\nfind that most of the tested models could cause harm if accessed in mental\nhealth emergencies, failing to protect users and potentially exacerbating\nexisting symptoms. We explore solutions to enhance the safety of current\nmodels. Before the release of increasingly task-autonomous AI systems in mental\nhealth, it is crucial to ensure that these models can reliably detect and\nmanage symptoms of common psychiatric disorders to prevent harm to users. This\ninvolves aligning with the ethical framework and default behaviors outlined in\nour study. We contend that model developers are responsible for refining their\nsystems per these guidelines to safeguard against the risks posed by current AI\ntechnologies to user mental health and safety.\n  Trigger warning: Contains and discusses examples of sensitive mental health\ntopics, including suicide and self-harm.", "published": "2024-04-02 15:05:06", "link": "http://arxiv.org/abs/2406.11852v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Release of Pre-Trained Models for the Japanese Language", "abstract": "AI democratization aims to create a world in which the average person can\nutilize AI techniques. To achieve this goal, numerous research institutes have\nattempted to make their results accessible to the public. In particular, large\npre-trained models trained on large-scale data have shown unprecedented\npotential, and their release has had a significant impact. However, most of the\nreleased models specialize in the English language, and thus, AI\ndemocratization in non-English-speaking communities is lagging significantly.\nTo reduce this gap in AI access, we released Generative Pre-trained Transformer\n(GPT), Contrastive Language and Image Pre-training (CLIP), Stable Diffusion,\nand Hidden-unit Bidirectional Encoder Representations from Transformers\n(HuBERT) pre-trained in Japanese. By providing these models, users can freely\ninterface with AI that aligns with Japanese cultural values and ensures the\nidentity of Japanese culture, thus enhancing the democratization of AI.\nAdditionally, experiments showed that pre-trained models specialized for\nJapanese can efficiently achieve high performance in Japanese tasks.", "published": "2024-04-02 05:59:43", "link": "http://arxiv.org/abs/2404.01657v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Generative AI for Immersive Communication: The Next Frontier in\n  Internet-of-Senses Through 6G", "abstract": "Over the past two decades, the Internet-of-Things (IoT) has become a\ntransformative concept, and as we approach 2030, a new paradigm known as the\nInternet of Senses (IoS) is emerging. Unlike conventional Virtual Reality (VR),\nIoS seeks to provide multi-sensory experiences, acknowledging that in our\nphysical reality, our perception extends far beyond just sight and sound; it\nencompasses a range of senses. This article explores the existing technologies\ndriving immersive multi-sensory media, delving into their capabilities and\npotential applications. This exploration includes a comparative analysis\nbetween conventional immersive media streaming and a proposed use case that\nleverages semantic communication empowered by generative Artificial\nIntelligence (AI). The focal point of this analysis is the substantial\nreduction in bandwidth consumption by 99.93% in the proposed scheme. Through\nthis comparison, we aim to underscore the practical applications of generative\nAI for immersive media. Concurrently addressing major challenges in this field,\nsuch as temporal synchronization of multiple media, ensuring high throughput,\nminimizing the End-to-End (E2E) latency, and robustness to low bandwidth while\noutlining future trajectories.", "published": "2024-04-02 07:57:05", "link": "http://arxiv.org/abs/2404.01713v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.MM", "cs.NI"], "primary_category": "cs.CL"}
{"title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra\n  Large-Scale Code Generation and Optimization", "abstract": "Recent advancements in automatic code generation using large language model\n(LLM) agent have brought us closer to the future of automated software\ndevelopment. However, existing single-agent approaches face limitations in\ngenerating and improving large-scale, complex codebases due to constraints in\ncontext length. To tackle this challenge, we propose Self-Organized multi-Agent\nframework (SoA), a novel multi-agent framework that enables the scalable and\nefficient generation and optimization of large-scale code. In SoA,\nself-organized agents operate independently to generate and modify code\ncomponents while seamlessly collaborating to construct the overall codebase. A\nkey feature of our framework is the automatic multiplication of agents based on\nproblem complexity, allowing for dynamic scalability. This enables the overall\ncode volume to be increased indefinitely according to the number of agents,\nwhile the amount of code managed by each agent remains constant. We evaluate\nSoA on the HumanEval benchmark and demonstrate that, compared to a single-agent\nsystem, each agent in SoA handles significantly less code, yet the overall\ngenerated code is substantially greater. Moreover, SoA surpasses the powerful\nsingle-agent baseline by 5% in terms of Pass@1 accuracy.", "published": "2024-04-02 13:37:28", "link": "http://arxiv.org/abs/2404.02183v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.SE"}
{"title": "SMITIN: Self-Monitored Inference-Time INtervention for Generative Music\n  Transformers", "abstract": "We introduce Self-Monitored Inference-Time INtervention (SMITIN), an approach\nfor controlling an autoregressive generative music transformer using classifier\nprobes. These simple logistic regression probes are trained on the output of\neach attention head in the transformer using a small dataset of audio examples\nboth exhibiting and missing a specific musical trait (e.g., the\npresence/absence of drums, or real/synthetic music). We then steer the\nattention heads in the probe direction, ensuring the generative model output\ncaptures the desired musical trait. Additionally, we monitor the probe output\nto avoid adding an excessive amount of intervention into the autoregressive\ngeneration, which could lead to temporally incoherent music. We validate our\nresults objectively and subjectively for both audio continuation and\ntext-to-music applications, demonstrating the ability to add controls to large\ngenerative models for which retraining or even fine-tuning is impractical for\nmost musicians.\n  Audio samples of the proposed intervention approach are available on our demo\npage http://tinyurl.com/smitin .", "published": "2024-04-02 19:18:42", "link": "http://arxiv.org/abs/2404.02252v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Simulation for Sound Source Localization in Virtual Evironment", "abstract": "Non-line-of-sight localization in signal-deprived environments is a\nchallenging yet pertinent problem. Acoustic methods in such predominantly\nindoor scenarios encounter difficulty due to the reverberant nature. In this\nstudy, we aim to locate sound sources to specific locations within a virtual\nenvironment by leveraging physically grounded sound propagation simulations and\nmachine learning methods. This process attempts to overcome the issue of data\ninsufficiency to localize sound sources to their location of occurrence\nespecially in post-event localization. We achieve 0.786+/- 0.0136 F1-score\nusing an audio transformer spectrogram approach.", "published": "2024-04-02 03:18:28", "link": "http://arxiv.org/abs/2404.01611v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Voice EHR: Introducing Multimodal Audio Data for Health", "abstract": "Artificial intelligence (AI) models trained on audio data may have the\npotential to rapidly perform clinical tasks, enhancing medical decision-making\nand potentially improving outcomes through early detection. Existing\ntechnologies depend on limited datasets collected with expensive recording\nequipment in high-income countries, which challenges deployment in\nresource-constrained, high-volume settings where audio data may have a profound\nimpact on health equity. This report introduces a novel data type and a\ncorresponding collection system that captures health data through guided\nquestions using only a mobile/web application. The app facilitates the\ncollection of an audio electronic health record (Voice EHR) which may contain\ncomplex biomarkers of health from conventional voice/respiratory features,\nspeech patterns, and spoken language with semantic meaning and longitudinal\ncontext, potentially compensating for the typical limitations of unimodal\nclinical datasets. This report presents the application used for data\ncollection, initial experiments on data quality, and case studies which\ndemonstrate the potential of voice EHR to advance the scalability/diversity of\naudio AI.", "published": "2024-04-02 04:07:22", "link": "http://arxiv.org/abs/2404.01620v3", "categories": ["cs.SD", "cs.AI", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weakly-supervised Audio Separation via Bi-modal Semantic Similarity", "abstract": "Conditional sound separation in multi-source audio mixtures without having\naccess to single source sound data during training is a long standing\nchallenge. Existing mix-and-separate based methods suffer from significant\nperformance drop with multi-source training mixtures due to the lack of\nsupervision signal for single source separation cases during training. However,\nin the case of language-conditional audio separation, we do have access to\ncorresponding text descriptions for each audio mixture in our training data,\nwhich can be seen as (rough) representations of the audio samples in the\nlanguage modality. To this end, in this paper, we propose a generic bi-modal\nseparation framework which can enhance the existing unsupervised frameworks to\nseparate single-source signals in a target modality (i.e., audio) using the\neasily separable corresponding signals in the conditioning modality (i.e.,\nlanguage), without having access to single-source samples in the target\nmodality during training. We empirically show that this is well within reach if\nwe have access to a pretrained joint embedding model between the two modalities\n(i.e., CLAP). Furthermore, we propose to incorporate our framework into two\nfundamental scenarios to enhance separation performance. First, we show that\nour proposed methodology significantly improves the performance of purely\nunsupervised baselines by reducing the distribution shift between training and\ntest samples. In particular, we show that our framework can achieve 71% boost\nin terms of Signal-to-Distortion Ratio (SDR) over the baseline, reaching 97.5%\nof the supervised learning performance. Second, we show that we can further\nimprove the performance of the supervised learning itself by 17% if we augment\nit by our proposed weakly-supervised framework, that enables a powerful\nsemi-supervised framework for audio separation.", "published": "2024-04-02 08:59:58", "link": "http://arxiv.org/abs/2404.01740v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "T-VSL: Text-Guided Visual Sound Source Localization in Mixtures", "abstract": "Visual sound source localization poses a significant challenge in identifying\nthe semantic region of each sounding source within a video. Existing\nself-supervised and weakly supervised source localization methods struggle to\naccurately distinguish the semantic regions of each sounding object,\nparticularly in multi-source mixtures. These methods often rely on audio-visual\ncorrespondence as guidance, which can lead to substantial performance drops in\ncomplex multi-source localization scenarios. The lack of access to individual\nsource sounds in multi-source mixtures during training exacerbates the\ndifficulty of learning effective audio-visual correspondence for localization.\nTo address this limitation, in this paper, we propose incorporating the text\nmodality as an intermediate feature guide using tri-modal joint embedding\nmodels (e.g., AudioCLIP) to disentangle the semantic audio-visual source\ncorrespondence in multi-source mixtures. Our framework, dubbed T-VSL, begins by\npredicting the class of sounding entities in mixtures. Subsequently, the\ntextual representation of each sounding source is employed as guidance to\ndisentangle fine-grained audio-visual source correspondence from multi-source\nmixtures, leveraging the tri-modal AudioCLIP embedding. This approach enables\nour framework to handle a flexible number of sources and exhibits promising\nzero-shot transferability to unseen classes during test time. Extensive\nexperiments conducted on the MUSIC, VGGSound, and VGGSound-Instruments datasets\ndemonstrate significant performance improvements over state-of-the-art methods.\nCode is released at https://github.com/enyac-group/T-VSL/tree/main", "published": "2024-04-02 09:07:05", "link": "http://arxiv.org/abs/2404.01751v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Multi-Lingual Speaker Verification in Clinical Trials", "abstract": "Due to the substantial number of clinicians, patients, and data collection\nenvironments involved in clinical trials, gathering data of superior quality\nposes a significant challenge. In clinical trials, patients are assessed based\non their speech data to detect and monitor cognitive and mental health\ndisorders. We propose using these speech recordings to verify the identities of\nenrolled patients and identify and exclude the individuals who try to enroll\nmultiple times in the same trial. Since clinical studies are often conducted\nacross different countries, creating a system that can perform speaker\nverification in diverse languages without additional development effort is\nimperative. We evaluate pre-trained TitaNet, ECAPA-TDNN, and SpeakerNet models\nby enrolling and testing with speech-impaired patients speaking English,\nGerman, Danish, Spanish, and Arabic languages. Our results demonstrate that\ntested models can effectively generalize to clinical speakers, with less than\n2.7% EER for European Languages and 8.26% EER for Arabic. This represents a\nsignificant step in developing more versatile and efficient speaker\nverification systems for cognitive and mental health clinical trials that can\nbe used across a wide range of languages and dialects, substantially reducing\nthe effort required to develop speaker verification systems for multiple\nlanguages. We also evaluate how speech tasks and number of speakers involved in\nthe trial influence the performance and show that the type of speech tasks\nimpacts the model performance.", "published": "2024-04-02 14:19:30", "link": "http://arxiv.org/abs/2404.01981v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "SPMamba: State-space model is all you need in speech separation", "abstract": "Existing CNN-based speech separation models face local receptive field\nlimitations and cannot effectively capture long time dependencies. Although\nLSTM and Transformer-based speech separation models can avoid this problem,\ntheir high complexity makes them face the challenge of computational resources\nand inference efficiency when dealing with long audio. To address this\nchallenge, we introduce an innovative speech separation method called SPMamba.\nThis model builds upon the robust TF-GridNet architecture, replacing its\ntraditional BLSTM modules with bidirectional Mamba modules. These modules\neffectively model the spatiotemporal relationships between the time and\nfrequency dimensions, allowing SPMamba to capture long-range dependencies with\nlinear computational complexity. Specifically, the bidirectional processing\nwithin the Mamba modules enables the model to utilize both past and future\ncontextual information, thereby enhancing separation performance. Extensive\nexperiments conducted on public datasets, including WSJ0-2Mix, WHAM!, and\nLibri2Mix, as well as the newly constructed Echo2Mix dataset, demonstrated that\nSPMamba significantly outperformed existing state-of-the-art models, achieving\nsuperior results while also reducing computational complexity. These findings\nhighlighted the effectiveness of SPMamba in tackling the intricate challenges\nof speech separation in complex environments.", "published": "2024-04-02 16:04:31", "link": "http://arxiv.org/abs/2404.02063v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
