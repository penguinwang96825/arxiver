{"title": "Automatic Construction of Enterprise Knowledge Base", "abstract": "In this paper, we present an automatic knowledge base construction system\nfrom large scale enterprise documents with minimal efforts of human\nintervention. In the design and deployment of such a knowledge mining system\nfor enterprise, we faced several challenges including data distributional\nshift, performance evaluation, compliance requirements and other practical\nissues. We leveraged state-of-the-art deep learning models to extract\ninformation (named entities and definitions) at per document level, then\nfurther applied classical machine learning techniques to process global\nstatistical information to improve the knowledge base. Experimental results are\nreported on actual enterprise documents. This system is currently serving as\npart of a Microsoft 365 service.", "published": "2021-06-29 04:29:02", "link": "http://arxiv.org/abs/2106.15085v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple and Efficient Probabilistic Language model for Code-Mixed Text", "abstract": "The conventional natural language processing approaches are not accustomed to\nthe social media text due to colloquial discourse and non-homogeneous\ncharacteristics. Significantly, the language identification in a multilingual\ndocument is ascertained to be a preceding subtask in several information\nextraction applications such as information retrieval, named entity\nrecognition, relation extraction, etc. The problem is often more challenging in\ncode-mixed documents wherein foreign languages words are drawn into base\nlanguage while framing the text. The word embeddings are powerful language\nmodeling tools for representation of text documents useful in obtaining\nsimilarity between words or documents. We present a simple probabilistic\napproach for building efficient word embedding for code-mixed text and\nexemplifying it over language identification of Hindi-English short test\nmessages scrapped from Twitter. We examine its efficacy for the classification\ntask using bidirectional LSTMs and SVMs and observe its improved scores over\nvarious existing code-mixed embeddings", "published": "2021-06-29 05:37:57", "link": "http://arxiv.org/abs/2106.15102v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sexism in the Judiciary", "abstract": "We analyze 6.7 million case law documents to determine the presence of gender\nbias within our judicial system. We find that current bias detectino methods in\nNLP are insufficient to determine gender bias in our case law database and\npropose an alternative approach. We show that existing algorithms' inconsistent\nresults are consequences of prior research's definition of biases themselves.\nBias detection algorithms rely on groups of words to represent bias (e.g.,\n'salary,' 'job,' and 'boss' to represent employment as a potentially biased\ntheme against women in text). However, the methods to build these groups of\nwords have several weaknesses, primarily that the word lists are based on the\nresearchers' own intuitions. We suggest two new methods of automating the\ncreation of word lists to represent biases. We find that our methods outperform\ncurrent NLP bias detection methods. Our research improves the capabilities of\nNLP technology to detect bias and highlights gender biases present in\ninfluential case law. In order test our NLP bias detection method's\nperformance, we regress our results of bias in case law against U.S census data\nof women's participation in the workforce in the last 100 years.", "published": "2021-06-29 05:38:53", "link": "http://arxiv.org/abs/2106.15103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Lexicons for Hindi-English Multilingual Text Processing", "abstract": "Language Identification in textual documents is the process of automatically\ndetecting the language contained in a document based on its content. The\npresent Language Identification techniques presume that a document contains\ntext in one of the fixed set of languages, however, this presumption is\nincorrect when dealing with multilingual document which includes content in\nmore than one possible language. Due to the unavailability of large standard\ncorpora for Hindi-English mixed lingual language processing tasks we propose\nthe language lexicons, a novel kind of lexical database that supports several\nmultilingual language processing tasks. These lexicons are built by learning\nclassifiers over transliterated Hindi and English vocabulary. The designed\nlexicons possess richer quantitative characteristic than its primary source of\ncollection which is revealed using the visualization techniques.", "published": "2021-06-29 05:42:54", "link": "http://arxiv.org/abs/2106.15105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Time-Aware Language Models as Temporal Knowledge Bases", "abstract": "Many facts come with an expiration date, from the name of the President to\nthe basketball team Lebron James plays for. But language models (LMs) are\ntrained on snapshots of data collected at a specific moment in time, and this\ncan limit their utility, especially in the closed-book setting where the\npretraining corpus must contain the facts the model should memorize. We\nintroduce a diagnostic dataset aimed at probing LMs for factual knowledge that\nchanges over time and highlight problems with LMs at either end of the spectrum\n-- those trained on specific slices of temporal data, as well as those trained\non a wide range of temporal data. To mitigate these problems, we propose a\nsimple technique for jointly modeling text with its timestamp. This improves\nmemorization of seen facts from the training time period, as well as\ncalibration on predictions about unseen facts from future time periods. We also\nshow that models trained with temporal context can be efficiently \"refreshed\"\nas new data arrives, without the need for retraining from scratch.", "published": "2021-06-29 06:18:57", "link": "http://arxiv.org/abs/2106.15110v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TWAG: A Topic-Guided Wikipedia Abstract Generator", "abstract": "Wikipedia abstract generation aims to distill a Wikipedia abstract from web\nsources and has met significant success by adopting multi-document\nsummarization techniques. However, previous works generally view the abstract\nas plain text, ignoring the fact that it is a description of a certain entity\nand can be decomposed into different topics. In this paper, we propose a\ntwo-stage model TWAG that guides the abstract generation with topical\ninformation. First, we detect the topic of each input paragraph with a\nclassifier trained on existing Wikipedia articles to divide input documents\ninto different topics. Then, we predict the topic distribution of each abstract\nsentence, and decode the sentence from topic-aware representations with a\nPointer-Generator network. We evaluate our model on the WikiCatSum dataset, and\nthe results show that \\modelnames outperforms various existing baselines and is\ncapable of generating comprehensive abstracts. Our code and dataset can be\naccessed at \\url{https://github.com/THU-KEG/TWAG}", "published": "2021-06-29 07:42:08", "link": "http://arxiv.org/abs/2106.15135v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic-to-Essay Generation with Comprehensive Knowledge Enhancement", "abstract": "Generating high-quality and diverse essays with a set of topics is a\nchallenging task in natural language generation. Since several given topics\nonly provide limited source information, utilizing various topic-related\nknowledge is essential for improving essay generation performance. However,\nprevious works cannot sufficiently use that knowledge to facilitate the\ngeneration procedure. This paper aims to improve essay generation by extracting\ninformation from both internal and external knowledge. Thus, a topic-to-essay\ngeneration model with comprehensive knowledge enhancement, named TEGKE, is\nproposed. For internal knowledge enhancement, both topics and related essays\nare fed to a teacher network as source information. Then, informative features\nwould be obtained from the teacher network and transferred to a student network\nwhich only takes topics as input but provides comparable information compared\nwith the teacher network. For external knowledge enhancement, a topic knowledge\ngraph encoder is proposed. Unlike the previous works only using the nearest\nneighbors of topics in the commonsense base, our topic knowledge graph encoder\ncould exploit more structural and semantic information of the commonsense\nknowledge graph to facilitate essay generation. Moreover, the adversarial\ntraining based on the Wasserstein distance is proposed to improve generation\nquality. Experimental results demonstrate that TEGKE could achieve\nstate-of-the-art performance on both automatic and human evaluation.", "published": "2021-06-29 08:01:42", "link": "http://arxiv.org/abs/2106.15142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Miscellaneous Other-Class Words for Few-shot Named Entity\n  Recognition", "abstract": "Few-shot Named Entity Recognition (NER) exploits only a handful of\nannotations to identify and classify named entity mentions. Prototypical\nnetwork shows superior performance on few-shot NER. However, existing\nprototypical methods fail to differentiate rich semantics in other-class words,\nwhich will aggravate overfitting under few shot scenario. To address the issue,\nwe propose a novel model, Mining Undefined Classes from Other-class (MUCO),\nthat can automatically induce different undefined classes from the other class\nto improve few-shot NER. With these extra-labeled undefined classes, our method\nwill improve the discriminative ability of NER classifier and enhance the\nunderstanding of predefined classes with stand-by semantic knowledge.\nExperimental results demonstrate that our model outperforms five\nstate-of-the-art models in both 1-shot and 5-shots settings on four NER\nbenchmarks. We will release the code upon acceptance. The source code is\nreleased on https: //github.com/shuaiwa16/OtherClassNER.git.", "published": "2021-06-29 08:28:42", "link": "http://arxiv.org/abs/2106.15167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scientific Credibility of Machine Translation Research: A\n  Meta-Evaluation of 769 Papers", "abstract": "This paper presents the first large-scale meta-evaluation of machine\ntranslation (MT). We annotated MT evaluations conducted in 769 research papers\npublished from 2010 to 2020. Our study shows that practices for automatic MT\nevaluation have dramatically changed during the past decade and follow\nconcerning trends. An increasing number of MT evaluations exclusively rely on\ndifferences between BLEU scores to draw conclusions, without performing any\nkind of statistical significance testing nor human evaluation, while at least\n108 metrics claiming to be better than BLEU have been proposed. MT evaluations\nin recent papers tend to copy and compare automatic metric scores from previous\nwork to claim the superiority of a method or an algorithm without confirming\nneither exactly the same training, validating, and testing data have been used\nnor the metric scores are comparable. Furthermore, tools for reporting\nstandardized metric scores are still far from being widely adopted by the MT\ncommunity. After showing how the accumulation of these pitfalls leads to\ndubious evaluation, we propose a guideline to encourage better automatic MT\nevaluation along with a simple meta-evaluation scoring method to assess its\ncredibility.", "published": "2021-06-29 09:30:17", "link": "http://arxiv.org/abs/2106.15195v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Arabic Medical Dataset for Diseases Classification", "abstract": "The Arabic language suffers from a great shortage of datasets suitable for\ntraining deep learning models, and the existing ones include general\nnon-specialized classifications. In this work, we introduce a new Arab medical\ndataset, which includes two thousand medical documents collected from several\nArabic medical websites, in addition to the Arab Medical Encyclopedia. The\ndataset was built for the task of classifying texts and includes 10 classes\n(Blood, Bone, Cardiovascular, Ear, Endocrine, Eye, Gastrointestinal, Immune,\nLiver and Nephrological) diseases. Experiments on the dataset were performed by\nfine-tuning three pre-trained models: BERT from Google, Arabert that based on\nBERT with large Arabic corpus, and AraBioNER that based on Arabert with Arabic\nmedical corpus.", "published": "2021-06-29 10:42:53", "link": "http://arxiv.org/abs/2106.15236v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation based meta-learning for few-shot spoken intent\n  recognition", "abstract": "Spoken intent detection has become a popular approach to interface with\nvarious smart devices with ease. However, such systems are limited to the\npreset list of intents-terms or commands, which restricts the quick\ncustomization of personal devices to new intents. This paper presents a\nfew-shot spoken intent classification approach with task-agnostic\nrepresentations via meta-learning paradigm. Specifically, we leverage the\npopular representation-based meta-learning learning to build a task-agnostic\nrepresentation of utterances, that then use a linear classifier for prediction.\nWe evaluate three such approaches on our novel experimental protocol developed\non two popular spoken intent classification datasets: Google Commands and the\nFluent Speech Commands dataset. For a 5-shot (1-shot) classification of novel\nclasses, the proposed framework provides an average classification accuracy of\n88.6% (76.3%) on the Google Commands dataset, and 78.5% (64.2%) on the Fluent\nSpeech Commands dataset. The performance is comparable to traditionally\nsupervised classification models with abundant training samples.", "published": "2021-06-29 10:46:35", "link": "http://arxiv.org/abs/2106.15238v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Take It Literally: An Edit-Invariant Sequence Loss for Text\n  Generation", "abstract": "Neural text generation models are typically trained by maximizing\nlog-likelihood with the sequence cross entropy (CE) loss, which encourages an\nexact token-by-token match between a target sequence with a generated sequence.\nSuch training objective is sub-optimal when the target sequence is not perfect,\ne.g., when the target sequence is corrupted with noises, or when only weak\nsequence supervision is available. To address the challenge, we propose a novel\nEdit-Invariant Sequence Loss (EISL), which computes the matching loss of a\ntarget n-gram with all n-grams in the generated sequence. EISL is designed to\nbe robust to various noises and edits in the target sequences. Moreover, the\nEISL computation is essentially an approximate convolution operation with\ntarget n-grams as kernels, which is easy to implement and efficient to compute\nwith existing libraries. To demonstrate the effectiveness of EISL, we conduct\nexperiments on a wide range of tasks, including machine translation with noisy\ntarget sequences, unsupervised text style transfer with only weak training\nsignals, and non-autoregressive generation with non-predefined generation\norder. Experimental results show our method significantly outperforms the\ncommon CE loss and other strong baselines on all the tasks. EISL has a simple\nAPI that can be used as a drop-in replacement of the CE loss:\nhttps://github.com/guangyliu/EISL.", "published": "2021-06-29 03:59:21", "link": "http://arxiv.org/abs/2106.15078v7", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation for Low-Resource Languages: A Survey", "abstract": "Neural Machine Translation (NMT) has seen a tremendous spurt of growth in\nless than ten years, and has already entered a mature phase. While considered\nas the most widely used solution for Machine Translation, its performance on\nlow-resource language pairs still remains sub-optimal compared to the\nhigh-resource counterparts, due to the unavailability of large parallel\ncorpora. Therefore, the implementation of NMT techniques for low-resource\nlanguage pairs has been receiving the spotlight in the recent NMT research\narena, thus leading to a substantial amount of research reported on this topic.\nThis paper presents a detailed survey of research advancements in low-resource\nlanguage NMT (LRL-NMT), along with a quantitative analysis aimed at identifying\nthe most popular solutions. Based on our findings from reviewing previous work,\nthis survey paper provides a set of guidelines to select the possible NMT\ntechnique for a given LRL data setting. It also presents a holistic view of the\nLRL-NMT research landscape and provides a list of recommendations to further\nenhance the research efforts on LRL-NMT.", "published": "2021-06-29 06:31:58", "link": "http://arxiv.org/abs/2106.15115v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Digging Errors in NMT: Evaluating and Understanding Model Errors from\n  Partial Hypothesis Space", "abstract": "Solid evaluation of neural machine translation (NMT) is key to its\nunderstanding and improvement. Current evaluation of an NMT system is usually\nbuilt upon a heuristic decoding algorithm (e.g., beam search) and an evaluation\nmetric assessing similarity between the translation and golden reference.\nHowever, this system-level evaluation framework is limited by evaluating only\none best hypothesis and search errors brought by heuristic decoding algorithms.\nTo better understand NMT models, we propose a novel evaluation protocol, which\ndefines model errors with model's ranking capability over hypothesis space. To\ntackle the problem of exponentially large space, we propose two approximation\nmethods, top region evaluation along with an exact top-$k$ decoding algorithm,\nwhich finds top-ranked hypotheses in the whole hypothesis space, and Monte\nCarlo sampling evaluation, which simulates hypothesis space from a broader\nperspective. To quantify errors, we define our NMT model errors by measuring\ndistance between the hypothesis array ranked by the model and the ideally\nranked hypothesis array. After confirming the strong correlation with human\njudgment, we apply our evaluation to various NMT benchmarks and model\narchitectures. We show that the state-of-the-art Transformer models face\nserious ranking issues and only perform at the random chance level in the top\nregion. We further analyze model errors on architectures with different depths\nand widths, as well as different data-augmentation techniques, showing how\nthese factors affect model errors. Finally, we connect model errors with the\nsearch algorithms and provide interesting findings of beam search inductive\nbias and correlation with Minimum Bayes Risk (MBR) decoding.", "published": "2021-06-29 09:59:50", "link": "http://arxiv.org/abs/2106.15217v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Technique To Conversational Machine Reading", "abstract": "Conversational machine reading (CMR) tools have seen a rapid progress in the\nrecent past. The current existing tools rely on the supervised learning\ntechnique which require labeled dataset for their training. The supervised\ntechnique necessitates that for every new rule text, a manually labeled dataset\nmust be created. This is tedious and error prone. This paper introduces and\ndemonstrates how unsupervised learning technique can be applied in the\ndevelopment of CMR. Specifically, we demonstrate how unsupervised learning can\nbe used in rule extraction and entailment modules of CMR. Compared to the\ncurrent best CMR tool, our developed framework reports 3.3% improvement in\nmicro averaged accuracy and 1.4 % improvement in macro averaged accuracy.", "published": "2021-06-29 10:59:03", "link": "http://arxiv.org/abs/2106.15247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Topic Modeling Based Extractive Text Summarization", "abstract": "Text summarization is an approach for identifying important information\npresent within text documents. This computational technique aims to generate\nshorter versions of the source text, by including only the relevant and salient\ninformation present within the source text. In this paper, we propose a novel\nmethod to summarize a text document by clustering its contents based on latent\ntopics produced using topic modeling techniques and by generating extractive\nsummaries for each of the identified text clusters. All extractive\nsub-summaries are later combined to generate a summary for any given source\ndocument. We utilize the lesser used and challenging WikiHow dataset in our\napproach to text summarization. This dataset is unlike the commonly used news\ndatasets which are available for text summarization. The well-known news\ndatasets present their most important information in the first few lines of\ntheir source texts, which make their summarization a lesser challenging task\nwhen compared to summarizing the WikiHow dataset. Contrary to these news\ndatasets, the documents in the WikiHow dataset are written using a generalized\napproach and have lesser abstractedness and higher compression ratio, thus\nproposing a greater challenge to generate summaries. A lot of the current\nstate-of-the-art text summarization techniques tend to eliminate important\ninformation present in source documents in the favor of brevity. Our proposed\ntechnique aims to capture all the varied information present in source\ndocuments. Although the dataset proved challenging, after performing extensive\ntests within our experimental setup, we have discovered that our model produces\nencouraging ROUGE results and summaries when compared to the other published\nextractive and abstractive text summarization models.", "published": "2021-06-29 12:28:19", "link": "http://arxiv.org/abs/2106.15313v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On the Interaction of Belief Bias and Explanations", "abstract": "A myriad of explainability methods have been proposed in recent years, but\nthere is little consensus on how to evaluate them. While automatic metrics\nallow for quick benchmarking, it isn't clear how such metrics reflect human\ninteraction with explanations. Human evaluation is of paramount importance, but\nprevious protocols fail to account for belief biases affecting human\nperformance, which may lead to misleading conclusions. We provide an overview\nof belief bias, its role in human evaluation, and ideas for NLP practitioners\non how to account for it. For two experimental paradigms, we present a case\nstudy of gradient-based explainability introducing simple ways to account for\nhumans' prior beliefs: models of varying quality and adversarial examples. We\nshow that conclusions about the highest performing methods change when\nintroducing such controls, pointing to the importance of accounting for belief\nbias in evaluation.", "published": "2021-06-29 12:49:42", "link": "http://arxiv.org/abs/2106.15355v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Few-Shot Electronic Health Record Coding through Graph Contrastive\n  Learning", "abstract": "Electronic health record (EHR) coding is the task of assigning ICD codes to\neach EHR. Most previous studies either only focus on the frequent ICD codes or\ntreat rare and frequent ICD codes in the same way. These methods perform well\non frequent ICD codes but due to the extremely unbalanced distribution of ICD\ncodes, the performance on rare ones is far from satisfactory. We seek to\nimprove the performance for both frequent and rare ICD codes by using a\ncontrastive graph-based EHR coding framework, CoGraph, which re-casts EHR\ncoding as a few-shot learning task. First, we construct a heterogeneous EHR\nword-entity (HEWE) graph for each EHR, where the words and entities extracted\nfrom an EHR serve as nodes and the relations between them serve as edges. Then,\nCoGraph learns similarities and dissimilarities between HEWE graphs from\ndifferent ICD codes so that information can be transferred among them. In a\nfew-shot learning scenario, the model only has access to frequent ICD codes\nduring training, which might force it to encode features that are useful for\nfrequent ICD codes only. To mitigate this risk, CoGraph devises two graph\ncontrastive learning schemes, GSCL and GECL, that exploit the HEWE graph\nstructures so as to encode transferable features. GSCL utilizes the\nintra-correlation of different sub-graphs sampled from HEWE graphs while GECL\nexploits the inter-correlation among HEWE graphs at different clinical stages.\nExperiments on the MIMIC-III benchmark dataset show that CoGraph significantly\noutperforms state-of-the-art methods on EHR coding, not only on frequent ICD\ncodes, but also on rare codes, in terms of several evaluation indicators. On\nfrequent ICD codes, GSCL and GECL improve the classification accuracy and F1 by\n1.31% and 0.61%, respectively, and on rare ICD codes CoGraph has more obvious\nimprovements by 2.12% and 2.95%.", "published": "2021-06-29 14:53:17", "link": "http://arxiv.org/abs/2106.15467v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hate speech detection using static BERT embeddings", "abstract": "With increasing popularity of social media platforms hate speech is emerging\nas a major concern, where it expresses abusive speech that targets specific\ngroup characteristics, such as gender, religion or ethnicity to spread\nviolence. Earlier people use to verbally deliver hate speeches but now with the\nexpansion of technology, some people are deliberately using social media\nplatforms to spread hate by posting, sharing, commenting, etc. Whether it is\nChristchurch mosque shootings or hate crimes against Asians in west, it has\nbeen observed that the convicts are very much influenced from hate text present\nonline. Even though AI systems are in place to flag such text but one of the\nkey challenges is to reduce the false positive rate (marking non hate as hate),\nso that these systems can detect hate speech without undermining the freedom of\nexpression. In this paper, we use ETHOS hate speech detection dataset and\nanalyze the performance of hate speech detection classifier by replacing or\nintegrating the word embeddings (fastText (FT), GloVe (GV) or FT + GV) with\nstatic BERT embeddings (BE). With the extensive experimental trails it is\nobserved that the neural network performed better with static BE compared to\nusing FT, GV or FT + GV as word embeddings. In comparison to fine-tuned BERT,\none metric that significantly improved is specificity.", "published": "2021-06-29 16:17:10", "link": "http://arxiv.org/abs/2106.15537v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on\n  Spoken Language Understanding", "abstract": "Decomposable tasks are complex and comprise of a hierarchy of sub-tasks.\nSpoken intent prediction, for example, combines automatic speech recognition\nand natural language understanding. Existing benchmarks, however, typically\nhold out examples for only the surface-level sub-task. As a result, models with\nsimilar performance on these benchmarks may have unobserved performance\ndifferences on the other sub-tasks. To allow insightful comparisons between\ncompetitive end-to-end architectures, we propose a framework to construct\nrobust test sets using coordinate ascent over sub-task specific utility\nfunctions. Given a dataset for a decomposable task, our method optimally\ncreates a test set for each sub-task to individually assess sub-components of\nthe end-to-end model. Using spoken language understanding as a case study, we\ngenerate new splits for the Fluent Speech Commands and Snips SmartLights\ndatasets. Each split has two test sets: one with held-out utterances assessing\nnatural language understanding abilities, and one with held-out speakers to\ntest speech processing skills. Our splits identify performance gaps up to 10%\nbetween end-to-end systems that were within 1% of each other on the original\ntest sets. These performance gaps allow more realistic and actionable\ncomparisons between different architectures, driving future model development.\nWe release our splits and tools for the community.", "published": "2021-06-29 02:53:59", "link": "http://arxiv.org/abs/2106.15065v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech\n  Synthesis", "abstract": "Recent advances in neural multi-speaker text-to-speech (TTS) models have\nenabled the generation of reasonably good speech quality with a single model\nand made it possible to synthesize the speech of a speaker with limited\ntraining data. Fine-tuning to the target speaker data with the multi-speaker\nmodel can achieve better quality, however, there still exists a gap compared to\nthe real speech sample and the model depends on the speaker. In this work, we\npropose GANSpeech, which is a high-fidelity multi-speaker TTS model that adopts\nthe adversarial training method to a non-autoregressive multi-speaker TTS\nmodel. In addition, we propose simple but efficient automatic scaling methods\nfor feature matching loss used in adversarial training. In the subjective\nlistening tests, GANSpeech significantly outperformed the baseline\nmulti-speaker FastSpeech and FastSpeech2 models, and showed a better MOS score\nthan the speaker-specific fine-tuned FastSpeech2.", "published": "2021-06-29 08:15:30", "link": "http://arxiv.org/abs/2106.15153v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Leveraging Static Models for Link Prediction in Temporal Knowledge\n  Graphs", "abstract": "The inclusion of temporal scopes of facts in knowledge graph embedding (KGE)\npresents significant opportunities for improving the resulting embeddings, and\nconsequently for increased performance in downstream applications. Yet, little\nresearch effort has focussed on this area and much of the carried out research\nreports only marginally improved results compared to models trained without\ntemporal scopes (static models). Furthermore, rather than leveraging existing\nwork on static models, they introduce new models specific to temporal knowledge\ngraphs. We propose a novel perspective that takes advantage of the power of\nexisting static embedding models by focussing effort on manipulating the data\ninstead. Our method, SpliMe, draws inspiration from the field of signal\nprocessing and early work in graph embedding. We show that SpliMe competes with\nor outperforms the current state of the art in temporal KGE. Additionally, we\nuncover issues with the procedure currently used to assess the performance of\nstatic models on temporal graphs and introduce two ways to counteract them.", "published": "2021-06-29 10:15:17", "link": "http://arxiv.org/abs/2106.15223v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploring the Efficacy of Automatically Generated Counterfactuals for\n  Sentiment Analysis", "abstract": "While state-of-the-art NLP models have been achieving the excellent\nperformance of a wide range of tasks in recent years, important questions are\nbeing raised about their robustness and their underlying sensitivity to\nsystematic biases that may exist in their training and test data. Such issues\ncome to be manifest in performance problems when faced with out-of-distribution\ndata in the field. One recent solution has been to use counterfactually\naugmented datasets in order to reduce any reliance on spurious patterns that\nmay exist in the original data. Producing high-quality augmented data can be\ncostly and time-consuming as it usually needs to involve human feedback and\ncrowdsourcing efforts. In this work, we propose an alternative by describing\nand evaluating an approach to automatically generating counterfactual data for\ndata augmentation and explanation. A comprehensive evaluation on several\ndifferent datasets and using a variety of state-of-the-art benchmarks\ndemonstrate how our approach can achieve significant improvements in model\nperformance when compared to models training on the original data and even when\ncompared to models trained with the benefit of human-generated augmented data.", "published": "2021-06-29 10:27:01", "link": "http://arxiv.org/abs/2106.15231v3", "categories": ["cs.CL", "cs.AI", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Classification of Consumer Belief Statements From Social Media", "abstract": "Social media offer plenty of information to perform market research in order\nto meet the requirements of customers. One way how this research is conducted\nis that a domain expert gathers and categorizes user-generated content into a\ncomplex and fine-grained class structure. In many of such cases, little data\nmeets complex annotations. It is not yet fully understood how this can be\nleveraged successfully for classification. We examine the classification\naccuracy of expert labels when used with a) many fine-grained classes and b)\nfew abstract classes. For scenario b) we compare abstract class labels given by\nthe domain expert as baseline and by automatic hierarchical clustering. We\ncompare this to another baseline where the entire class structure is given by a\ncompletely unsupervised clustering approach. By doing so, this work can serve\nas an example of how complex expert annotations are potentially beneficial and\ncan be utilized in the most optimal way for opinion mining in highly specific\ndomains. By exploring across a range of techniques and experiments, we find\nthat automated class abstraction approaches in particular the unsupervised\napproach performs remarkably well against domain expert baseline on text\nclassification tasks. This has the potential to inspire opinion mining\napplications in order to support market researchers in practice and to inspire\nfine-grained automated content analysis on a large scale.", "published": "2021-06-29 15:25:33", "link": "http://arxiv.org/abs/2106.15498v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "SAT Based Analogy Evaluation Framework for Persian Word Embeddings", "abstract": "In recent years there has been a special interest in word embeddings as a new\napproach to convert words to vectors. It has been a focal point to understand\nhow much of the semantics of the the words has been transferred into embedding\nvectors. This is important as the embedding is going to be used as the basis\nfor downstream NLP applications and it will be costly to evaluate the\napplication end-to-end in order to identify quality of the used embedding\nmodel. Generally the word embeddings are evaluated through a number of tests,\nincluding analogy test. In this paper we propose a test framework for Persian\nembedding models. Persian is a low resource language and there is no rich\nsemantic benchmark to evaluate word embedding models for this language. In this\npaper we introduce an evaluation framework including a hand crafted Persian SAT\nbased analogy dataset, a colliquial test set (specific to Persian) and a\nbenchmark to study the impact of various parameters on the semantic evaluation\ntask.", "published": "2021-06-29 18:43:06", "link": "http://arxiv.org/abs/2106.15674v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Alzheimer's Dementia Recognition Using Acoustic, Lexical, Disfluency and\n  Speech Pause Features Robust to Noisy Inputs", "abstract": "We present two multimodal fusion-based deep learning models that consume ASR\ntranscribed speech and acoustic data simultaneously to classify whether a\nspeaker in a structured diagnostic task has Alzheimer's Disease and to what\ndegree, evaluating the ADReSSo challenge 2021 data. Our best model, a BiLSTM\nwith highway layers using words, word probabilities, disfluency features, pause\ninformation, and a variety of acoustic features, achieves an accuracy of 84%\nand RSME error prediction of 4.26 on MMSE cognitive scores. While predicting\ncognitive decline is more challenging, our models show improvement using the\nmultimodal approach and word probabilities, disfluency and pause information\nover word-only models. We show considerable gains for AD classification using\nmultimodal fusion and gating, which can effectively deal with noisy inputs from\nacoustic features and ASR hypotheses.", "published": "2021-06-29 19:24:29", "link": "http://arxiv.org/abs/2106.15684v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Survey on Neural Speech Synthesis", "abstract": "Text to speech (TTS), or speech synthesis, which aims to synthesize\nintelligible and natural speech given text, is a hot research topic in speech,\nlanguage, and machine learning communities and has broad applications in the\nindustry. As the development of deep learning and artificial intelligence,\nneural network-based TTS has significantly improved the quality of synthesized\nspeech in recent years. In this paper, we conduct a comprehensive survey on\nneural TTS, aiming to provide a good understanding of current research and\nfuture trends. We focus on the key components in neural TTS, including text\nanalysis, acoustic models and vocoders, and several advanced topics, including\nfast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.\nWe further summarize resources related to TTS (e.g., datasets, opensource\nimplementations) and discuss future research directions. This survey can serve\nboth academic researchers and industry practitioners working on TTS.", "published": "2021-06-29 16:50:51", "link": "http://arxiv.org/abs/2106.15561v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient Sequence Packing without Cross-contamination: Accelerating\n  Large Language Models without Impacting Performance", "abstract": "Effective training of today's large language models (LLMs) depends on large\nbatches and long sequences for throughput and accuracy. To handle\nvariable-length sequences on hardware accelerators, it is common practice to\nintroduce padding tokens, so that all sequences in a batch have the same\nlength. We show in this paper that the variation in sequence lengths in common\nNLP datasets is such that up to 50% of all tokens can be padding. In less\ncommon, but not extreme, cases (e.g. GLUE-cola with sequence length 128), the\nratio is up to 89%. Existing methods to address the resulting inefficiency are\ncomplicated by the need to avoid cross-contamination in self-attention, by a\nreduction in accuracy when sequence ordering information is lost, or by\ncustomized kernel implementations only valid for specific accelerators. This\npaper introduces a new formalization of sequence packing in the context of the\nwell-studied bin packing problem, and presents new algorithms based on this\nformulation which, for example, confer a 2x speedup for phase 2 pre-training in\nBERT. We show how existing models can be adapted to ensure mathematical\nequivalence between the original and packed models, meaning that packed models\ncan be trained with existing pre-training and fine-tuning practices.", "published": "2021-06-29 04:37:23", "link": "http://arxiv.org/abs/2107.02027v2", "categories": ["cs.CL", "cs.CC", "cs.IT", "cs.LG", "math.IT", "05-08", "I.2.7; G.2.1"], "primary_category": "cs.CL"}
{"title": "Hierarchical Context-Aware Transformers for Non-Autoregressive Text to\n  Speech", "abstract": "In this paper, we propose methods for improving the modeling performance of a\nTransformer-based non-autoregressive text-to-speech (TNA-TTS) model. Although\nthe text encoder and audio decoder handle different types and lengths of data\n(i.e., text and audio), the TNA-TTS models are not designed considering these\nvariations. Therefore, to improve the modeling performance of the TNA-TTS model\nwe propose a hierarchical Transformer structure-based text encoder and audio\ndecoder that are designed to accommodate the characteristics of each module.\nFor the text encoder, we constrain each self-attention layer so the encoder\nfocuses on a text sequence from the local to the global scope. Conversely, the\naudio decoder constrains its self-attention layers to focus in the reverse\ndirection, i.e., from global to local scope. Additionally, we further improve\nthe pitch modeling accuracy of the audio decoder by providing sentence and\nword-level pitch as conditions. Various objective and subjective evaluations\nverified that the proposed method outperformed the baseline TNA-TTS.", "published": "2021-06-29 08:05:11", "link": "http://arxiv.org/abs/2106.15144v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for\n  Pronunciation Enhancement", "abstract": "Recently, end-to-end Korean singing voice systems have been designed to\ngenerate realistic singing voices. However, these systems still suffer from a\nlack of robustness in terms of pronunciation accuracy. In this paper, we\npropose N-Singer, a non-autoregressive Korean singing voice system, to\nsynthesize accurate and pronounced Korean singing voices in parallel. N-Singer\nconsists of a Transformer-based mel-generator, a convolutional network-based\npostnet, and voicing-aware discriminators. It can contribute in the following\nways. First, for accurate pronunciation, N-Singer separately models linguistic\nand pitch information without other acoustic features. Second, to achieve\nimproved mel-spectrograms, N-Singer uses a combination of Transformer-based\nmodules and convolutional network-based modules. Third, in adversarial\ntraining, voicing-aware conditional discriminators are used to capture the\nharmonic features of voiced segments and noise components of unvoiced segments.\nThe experimental results prove that N-Singer can synthesize a natural singing\nvoice in parallel with a more accurate pronunciation than the baseline model.", "published": "2021-06-29 09:43:59", "link": "http://arxiv.org/abs/2106.15205v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards a generalized monaural and binaural auditory model for\n  psychoacoustics and speech intelligibility", "abstract": "Auditory perception involves cues in the monaural auditory pathways as well\nas binaural cues based on differences between the ears. So far auditory models\nhave often focused on either monaural or binaural experiments in isolation.\nAlthough binaural models typically build upon stages of (existing) monaural\nmodels, only a few attempts have been made to extend a monaural model by a\nbinaural stage using a unified decision stage for monaural and binaural cues.\nIn such approaches, a typical prototype of binaural processing has been the\nclassical equalization-cancelation mechanism, which either involves\nsignal-adaptive delays and provides a single channel output or can be\nimplemented with tapped delays providing a high-dimensional multichannel\noutput. This contribution extends the (monaural) generalized envelope power\nspectrum model by a non-adaptive binaural stage with only a few, fixed output\nchannels. The binaural stage resembles features of physiologically motivated\nhemispheric binaural processing, as simplified signal processing stages,\nyielding a 5-channel monaural and binaural matrix feature \"decoder\" (BMFD). The\nback end of the existing monaural model is applied to the 5-channel BMFD output\nand calculates short-time envelope power and power features. The model is\nevaluated and discussed for a baseline database of monaural and binaural\npsychoacoustic experiments from the literature.", "published": "2021-06-29 18:12:41", "link": "http://arxiv.org/abs/2106.15659v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FastPitchFormant: Source-filter based Decomposed Modeling for Speech\n  Synthesis", "abstract": "Methods for modeling and controlling prosody with acoustic features have been\nproposed for neural text-to-speech (TTS) models. Prosodic speech can be\ngenerated by conditioning acoustic features. However, synthesized speech with a\nlarge pitch-shift scale suffers from audio quality degradation, and speaker\ncharacteristics deformation. To address this problem, we propose a feed-forward\nTransformer based TTS model that is designed based on the source-filter theory.\nThis model, called FastPitchFormant, has a unique structure that handles text\nand acoustic features in parallel. With modeling each feature separately, the\ntendency that the model learns the relationship between two features can be\nmitigated.", "published": "2021-06-29 07:06:42", "link": "http://arxiv.org/abs/2106.15123v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Sounds of COVID-19: exploring realistic performance of audio-based\n  digital testing", "abstract": "Researchers have been battling with the question of how we can identify\nCoronavirus disease (COVID-19) cases efficiently, affordably and at scale.\nRecent work has shown how audio based approaches, which collect respiratory\naudio data (cough, breathing and voice) can be used for testing, however there\nis a lack of exploration of how biases and methodological decisions impact\nthese tools' performance in practice. In this paper, we explore the realistic\nperformance of audio-based digital testing of COVID-19. To investigate this, we\ncollected a large crowdsourced respiratory audio dataset through a mobile app,\nalongside recent COVID-19 test result and symptoms intended as a ground truth.\nWithin the collected dataset, we selected 5,240 samples from 2,478 participants\nand split them into different participant-independent sets for model\ndevelopment and validation. Among these, we controlled for potential\nconfounding factors (such as demographics and language). The unbiased model\ntakes features extracted from breathing, coughs, and voice signals as\npredictors and yields an AUC-ROC of 0.71 (95\\% CI: 0.65$-$0.77). We further\nexplore different unbalanced distributions to show how biases and participant\nsplits affect performance. Finally, we discuss how the realistic model\npresented could be integrated in clinical practice to realize continuous,\nubiquitous, sustainable and affordable testing at population scale.", "published": "2021-06-29 15:50:36", "link": "http://arxiv.org/abs/2106.15523v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Scale Spectrogram Modelling for Neural Text-to-Speech", "abstract": "We propose a novel Multi-Scale Spectrogram (MSS) modelling approach to\nsynthesise speech with an improved coarse and fine-grained prosody. We present\na generic multi-scale spectrogram prediction mechanism where the system first\npredicts coarser scale mel-spectrograms that capture the suprasegmental\ninformation in speech, and later uses these coarser scale mel-spectrograms to\npredict finer scale mel-spectrograms capturing fine-grained prosody.\n  We present details for two specific versions of MSS called Word-level MSS and\nSentence-level MSS where the scales in our system are motivated by the\nlinguistic units. The Word-level MSS models word, phoneme, and frame-level\nspectrograms while Sentence-level MSS models sentence-level spectrogram in\naddition.\n  Subjective evaluations show that Word-level MSS performs statistically\nsignificantly better compared to the baseline on two voices.", "published": "2021-06-29 18:01:34", "link": "http://arxiv.org/abs/2106.15649v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DCASE 2021 Task 3: Spectrotemporally-aligned Features for Polyphonic\n  Sound Event Localization and Detection", "abstract": "Sound event localization and detection consists of two subtasks which are\nsound event detection and direction-of-arrival estimation. While sound event\ndetection mainly relies on time-frequency patterns to distinguish different\nsound classes, direction-of-arrival estimation uses magnitude or phase\ndifferences between microphones to estimate source directions. Therefore, it is\noften difficult to jointly train these two subtasks simultaneously. We propose\na novel feature called spatial cue-augmented log-spectrogram (SALSA) with exact\ntime-frequency mapping between the signal power and the source\ndirection-of-arrival. The feature includes multichannel log-spectrograms\nstacked along with the estimated direct-to-reverberant ratio and a normalized\nversion of the principal eigenvector of the spatial covariance matrix at each\ntime-frequency bin on the spectrograms. Experimental results on the DCASE 2021\ndataset for sound event localization and detection with directional\ninterference showed that the deep learning-based models trained on this new\nfeature outperformed the DCASE challenge baseline by a large margin. We\ncombined several models with slightly different architectures that were trained\non the new feature to further improve the system performances for the DCASE\nsound event localization and detection challenge.", "published": "2021-06-29 09:18:30", "link": "http://arxiv.org/abs/2106.15190v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
