{"title": "Risk-Neutral Pricing Model of Uniswap Liquidity Providing Position: A Stopping Time Approach", "abstract": "In this paper, we introduce a novel pricing model for Uniswap V3, built upon\nstochastic processes and the Martingale Stopping Theorem. This model\ninnovatively frames the valuation of positions within Uniswap V3. We further\nconduct a numerical analysis and examine the sensitivities through Greek risk\nmeasures to elucidate the model's implications. The results underscore the\nmodel's significant academic contribution and its practical applicability for\nUniswap liquidity providers, particularly in assessing risk exposure and\nguiding hedging strategies.", "published": "2024-11-19 09:49:04", "link": "http://arxiv.org/abs/2411.12375v3", "categories": ["q-fin.PR", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "Germany's Tax Revenue and its Total Administrative Cost", "abstract": "Tax administrative cost reduction is an economically and socially desirable\ngoal for public policy. This article proposes total administrative cost as\npercentage of total tax revenue as a vivid measurand, also useful for\ncross-jurisdiction comparisons. Statistical data, surveys and a novel approach\ndemonstrate: Germany's 2021 tax administrative costs likely exceeded 20% of\ntotal tax revenue, indicating need for improvement of Germany's taxation system\n- and for the many jurisdictions with similar tax regimes. In addition, this\narticle outlines possible reasons for and implications of the seemingly high\ntax administrative burden as well as solutions.", "published": "2024-11-19 14:48:08", "link": "http://arxiv.org/abs/2411.12543v1", "categories": ["econ.GN", "q-fin.EC", "q-fin.ST", "stat.AP"], "primary_category": "econ.GN"}
{"title": "A Full-History Network Dataset for BTC Asset Decentralization Profiling", "abstract": "Since its advent in 2009, Bitcoin (BTC) has garnered increasing attention\nfrom both academia and industry. However, due to the massive transaction\nvolume, no systematic study has quantitatively measured the asset\ndecentralization degree specifically from a network perspective.\n  In this paper, by conducting a thorough analysis of the BTC transaction\nnetwork, we first address the significant gap in the availability of\nfull-history BTC graph and network property dataset, which spans over 15 years\nfrom the genesis block (1st March, 2009) to the 845651-th block (29, May 2024).\nWe then present the first systematic investigation to profile BTC's asset\ndecentralization and design several decentralization degrees for\nquantification. Through extensive experiments, we emphasize the significant\nrole of network properties and our network-based decentralization degree in\nenhancing Bitcoin analysis. Our findings demonstrate the importance of our\ncomprehensive dataset and analysis in advancing research on Bitcoin's\ntransaction dynamics and decentralization, providing valuable insights into the\nnetwork's structure and its implications.", "published": "2024-11-19 10:55:29", "link": "http://arxiv.org/abs/2411.13603v1", "categories": ["q-fin.ST", "cs.SI"], "primary_category": "q-fin.ST"}
{"title": "Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment", "abstract": "Large Language Models (LLMs) have achieved remarkable success recently,\ndisplaying exceptional capabilities in creating understandable and organized\ntext. These LLMs have been utilized in diverse fields, such as clinical\nresearch, where domain-specific models like Med-Palm have achieved human-level\nperformance. Recently, researchers have employed advanced prompt engineering to\nenhance the general reasoning ability of LLMs. Despite the remarkable success\nof zero-shot Chain-of-Thoughts (CoT) in solving general reasoning tasks, the\npotential of these methods still remains paid limited attention in the\nfinancial reasoning task.To address this issue, we explore multiple prompt\nstrategies and incorporated semantic news information to improve LLMs'\nperformance on financial reasoning tasks.To the best of our knowledge, we are\nthe first to explore this important issue by applying ChatGPT to the gold\ninvestment.In this work, our aim is to investigate the financial reasoning\ncapabilities of LLMs and their capacity to generate logical and persuasive\ninvestment opinions. We will use ChatGPT, one of the most powerful LLMs\nrecently, and prompt engineering to achieve this goal. Our research will focus\non understanding the ability of LLMs in sophisticated analysis and reasoning\nwithin the context of investment decision-making. Our study finds that ChatGPT\nwith CoT prompt can provide more explainable predictions and overcome\nbehavioral biases, which is crucial in finance-related tasks and can achieve\nhigher investment returns.", "published": "2024-11-19 07:45:58", "link": "http://arxiv.org/abs/2411.13599v2", "categories": ["q-fin.ST", "cs.AI"], "primary_category": "q-fin.ST"}
{"title": "JuniperLiu at CoMeDi Shared Task: Models as Annotators in Lexical\n  Semantics Disagreements", "abstract": "We present the results of our system for the CoMeDi Shared Task, which\npredicts majority votes (Subtask 1) and annotator disagreements (Subtask 2).\nOur approach combines model ensemble strategies with MLP-based and\nthreshold-based methods trained on pretrained language models. Treating\nindividual models as virtual annotators, we simulate the annotation process by\ndesigning aggregation measures that incorporate continuous relatedness scores\nand discrete classification labels to capture both majority and disagreement.\nAdditionally, we employ anisotropy removal techniques to enhance performance.\nExperimental results demonstrate the effectiveness of our methods, particularly\nfor Subtask 2. Notably, we find that standard deviation on continuous\nrelatedness scores among different model manipulations correlates with human\ndisagreement annotations compared to metrics on aggregated discrete labels. The\ncode will be published at https://github.com/RyanLiut/CoMeDi_Solution.", "published": "2024-11-19 00:50:06", "link": "http://arxiv.org/abs/2411.12147v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Combined Encoder and Transformer Approach for Coherent and\n  High-Quality Text Generation", "abstract": "This research introduces a novel text generation model that combines BERT's\nsemantic interpretation strengths with GPT-4's generative capabilities,\nestablishing a high standard in generating coherent, contextually accurate\nlanguage. Through the combined architecture, the model enhances semantic depth\nand maintains smooth, human-like text flow, overcoming limitations seen in\nprior models. Experimental benchmarks reveal that BERT-GPT-4 surpasses\ntraditional models, including GPT-3, T5, BART, Transformer-XL, and CTRL, in key\nmetrics like Perplexity and BLEU, showcasing its superior natural language\ngeneration performance. By fully utilizing contextual information, this hybrid\nmodel generates text that is not only logically coherent but also aligns\nclosely with human language patterns, providing an advanced solution for text\ngeneration tasks. This research highlights the potential of integrating\nsemantic understanding with advanced generative models, contributing new\ninsights for NLP, and setting a foundation for broader applications of\nlarge-scale generative architectures in areas such as automated writing,\nquestion-answer systems, and adaptive conversational agents.", "published": "2024-11-19 01:41:56", "link": "http://arxiv.org/abs/2411.12157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-resource Machine Translation: what for? who for? An observational\n  study on a dedicated Tetun language translation service", "abstract": "Low-resource machine translation (MT) presents a diversity of community needs\nand application challenges that remain poorly understood. To complement surveys\nand focus groups, which tend to rely on small samples of respondents, we\npropose an observational study on actual usage patterns of tetun$.$org, a\nspecialized MT service for the Tetun language, which is the lingua franca in\nTimor-Leste. Our analysis of 100,000 translation requests reveals patterns that\nchallenge assumptions based on existing corpora. We find that users, many of\nthem students on mobile devices, typically translate text from a high-resource\nlanguage into Tetun across diverse domains including science, healthcare, and\ndaily life. This contrasts sharply with available Tetun corpora, which are\ndominated by news articles covering government and social issues. Our results\nsuggest that MT systems for institutionalized minority languages like Tetun\nshould prioritize accuracy on domains relevant to educational contexts, in the\nhigh-resource to low-resource direction. More broadly, this study demonstrates\nhow observational analysis can inform low-resource language technology\ndevelopment, by grounding research in practical community needs.", "published": "2024-11-19 06:21:51", "link": "http://arxiv.org/abs/2411.12262v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUE-M: Contextual Understanding and Enhanced Search with Multimodal\n  Large Language Model", "abstract": "The integration of Retrieval-Augmented Generation (RAG) with Multimodal Large\nLanguage Models (MLLMs) has revolutionized information retrieval and expanded\nthe practical applications of AI. However, current systems struggle in\naccurately interpreting user intent, employing diverse retrieval strategies,\nand effectively filtering unintended or inappropriate responses, limiting their\neffectiveness. This paper introduces Contextual Understanding and Enhanced\nSearch with MLLM (CUE-M), a novel multimodal search framework that addresses\nthese challenges through a multi-stage pipeline comprising image context\nenrichment, intent refinement, contextual query generation, external API\nintegration, and relevance-based filtering. CUE-M incorporates a robust\nfiltering pipeline combining image-based, text-based, and multimodal\nclassifiers, dynamically adapting to instance- and category-specific concern\ndefined by organizational policies. Extensive experiments on real-word datasets\nand public benchmarks on knowledge-based VQA and safety demonstrated that CUE-M\noutperforms baselines and establishes new state-of-the-art results, advancing\nthe capabilities of multimodal retrieval systems.", "published": "2024-11-19 07:16:48", "link": "http://arxiv.org/abs/2411.12287v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Variation between Credible and Non-Credible News Across Topics", "abstract": "'Fake News' continues to undermine trust in modern journalism and politics.\nDespite continued efforts to study fake news, results have been conflicting.\nPrevious attempts to analyse and combat fake news have largely focused on\ndistinguishing fake news from truth, or differentiating between its various\nsub-types (such as propaganda, satire, misinformation, etc.) This paper\nconducts a linguistic and stylistic analysis of fake news, focusing on\nvariation between various news topics. It builds on related work identifying\nfeatures from discourse and linguistics in deception detection by analysing\nfive distinct news topics: Economy, Entertainment, Health, Science, and Sports.\nThe results emphasize that linguistic features vary between credible and\ndeceptive news in each domain and highlight the importance of adapting\nclassification tasks to accommodate variety-based stylistic and linguistic\ndifferences in order to achieve better real-world performance.", "published": "2024-11-19 12:29:30", "link": "http://arxiv.org/abs/2411.12458v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NMT-Obfuscator Attack: Ignore a sentence in translation with only one\n  word", "abstract": "Neural Machine Translation systems are used in diverse applications due to\ntheir impressive performance. However, recent studies have shown that these\nsystems are vulnerable to carefully crafted small perturbations to their\ninputs, known as adversarial attacks. In this paper, we propose a new type of\nadversarial attack against NMT models. In this attack, we find a word to be\nadded between two sentences such that the second sentence is ignored and not\ntranslated by the NMT model. The word added between the two sentences is such\nthat the whole adversarial text is natural in the source language. This type of\nattack can be harmful in practical scenarios since the attacker can hide\nmalicious information in the automatic translation made by the target NMT\nmodel. Our experiments show that different NMT models and translation tasks are\nvulnerable to this type of attack. Our attack can successfully force the NMT\nmodels to ignore the second part of the input in the translation for more than\n50% of all cases while being able to maintain low perplexity for the whole\ninput.", "published": "2024-11-19 12:55:22", "link": "http://arxiv.org/abs/2411.12473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Eradicating Social Biases in Sentiment Analysis using Semantic Blinding\n  and Semantic Propagation Graph Neural Networks", "abstract": "This paper introduces the Semantic Propagation Graph Neural Network (SProp\nGNN), a machine learning sentiment analysis (SA) architecture that relies\nexclusively on syntactic structures and word-level emotional cues to predict\nemotions in text. By semantically blinding the model to information about\nspecific words, it is robust to social biases such as political or gender bias\nthat have been plaguing previous machine learning-based SA systems. The SProp\nGNN shows performance superior to lexicon-based alternatives such as VADER\n(Valence Aware Dictionary and Sentiment Reasoner) and EmoAtlas on two different\nprediction tasks, and across two languages. Additionally, it approaches the\naccuracy of transformer-based models while significantly reducing bias in\nemotion prediction tasks. By offering improved explainability and reducing\nbias, the SProp GNN bridges the methodological gap between interpretable\nlexicon approaches and powerful, yet often opaque, deep learning models,\noffering a robust tool for fair and effective emotion analysis in understanding\nhuman behavior through text.", "published": "2024-11-19 13:23:53", "link": "http://arxiv.org/abs/2411.12493v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text\n  Vectorization Techniques. Defying BERT?", "abstract": "The rapid spread of misinformation, particularly through online platforms,\nunderscores the urgent need for reliable detection systems. This study explores\nthe utilization of machine learning and natural language processing,\nspecifically Support Vector Machines (SVM) and BERT, to detect news that are\nfake. We employ three distinct text vectorization methods for SVM: Term\nFrequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW)\nevaluating their effectiveness in distinguishing between genuine and fake news.\nAdditionally, we compare these methods against the transformer large language\nmodel, BERT. Our comprehensive approach includes detailed preprocessing steps,\nrigorous model implementation, and thorough evaluation to determine the most\neffective techniques. The results demonstrate that while BERT achieves superior\naccuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear\nkernel and BoW vectorization also performs exceptionally well, achieving 99.81%\naccuracy and an F1-score of 0.9980. These findings highlight that, despite\nBERT's superior performance, SVM models with BoW and TF-IDF vectorization\nmethods come remarkably close, offering highly competitive performance with the\nadvantage of lower computational requirements.", "published": "2024-11-19 18:15:46", "link": "http://arxiv.org/abs/2411.12703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling laws for nonlinear dynamical models of articulatory control", "abstract": "Dynamical theories of speech use computational models of articulatory control\nto generate quantitative predictions and advance understanding of speech\ndynamics. The addition of a nonlinear restoring force to task dynamic models is\na significant improvement over linear models, but nonlinearity introduces\nchallenges with parameterization and interpretability. We illustrate these\nproblems through numerical simulations and introduce solutions in the form of\nscaling laws. We apply the scaling laws to a cubic model and show how they\nfacilitate interpretable simulations of articulatory dynamics, and can be\ntheoretically interpreted as imposing physical and cognitive constraints on\nmodels of speech movement dynamics.", "published": "2024-11-19 18:38:01", "link": "http://arxiv.org/abs/2411.12720v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AzSLD: Azerbaijani Sign Language Dataset for Fingerspelling, Word, and\n  Sentence Translation with Baseline Software", "abstract": "Sign language processing technology development relies on extensive and\nreliable datasets, instructions, and ethical guidelines. We present a\ncomprehensive Azerbaijani Sign Language Dataset (AzSLD) collected from diverse\nsign language users and linguistic parameters to facilitate advancements in\nsign recognition and translation systems and support the local sign language\ncommunity. The dataset was created within the framework of a vision-based AzSL\ntranslation project. This study introduces the dataset as a summary of the\nfingerspelling alphabet and sentence- and word-level sign language datasets.\nThe dataset was collected from signers of different ages, genders, and signing\nstyles, with videos recorded from two camera angles to capture each sign in\nfull detail. This approach ensures robust training and evaluation of gesture\nrecognition models. AzSLD contains 30,000 videos, each carefully annotated with\naccurate sign labels and corresponding linguistic translations. The dataset is\naccompanied by technical documentation and source code to facilitate its use in\ntraining and testing. This dataset offers a valuable resource of labeled data\nfor researchers and developers working on sign language recognition,\ntranslation, or synthesis. Ethical guidelines were strictly followed throughout\nthe project, with all participants providing informed consent for collecting,\npublishing, and using the data.", "published": "2024-11-19 21:15:47", "link": "http://arxiv.org/abs/2411.12865v2", "categories": ["cs.CL", "I.4.0"], "primary_category": "cs.CL"}
{"title": "HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning\n  with Hard Negatives", "abstract": "Unsupervised sentence representation learning remains a critical challenge in\nmodern natural language processing (NLP) research. Recently, contrastive\nlearning techniques have achieved significant success in addressing this issue\nby effectively capturing textual semantics. Many such approaches prioritize the\noptimization using negative samples. In fields such as computer vision, hard\nnegative samples (samples that are close to the decision boundary and thus more\ndifficult to distinguish) have been shown to enhance representation learning.\nHowever, adapting hard negatives to contrastive sentence learning is complex\ndue to the intricate syntactic and semantic details of text. To address this\nproblem, we propose HNCSE, a novel contrastive learning framework that extends\nthe leading SimCSE approach. The hallmark of HNCSE is its innovative use of\nhard negative samples to enhance the learning of both positive and negative\nsamples, thereby achieving a deeper semantic understanding. Empirical tests on\nsemantic textual similarity and transfer task datasets validate the superiority\nof HNCSE.", "published": "2024-11-19 01:26:20", "link": "http://arxiv.org/abs/2411.12156v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BoolQuestions: Does Dense Retrieval Understand Boolean Logic in\n  Language?", "abstract": "Dense retrieval, which aims to encode the semantic information of arbitrary\ntext into dense vector representations or embeddings, has emerged as an\neffective and efficient paradigm for text retrieval, consequently becoming an\nessential component in various natural language processing systems. These\nsystems typically focus on optimizing the embedding space by attending to the\nrelevance of text pairs, while overlooking the Boolean logic inherent in\nlanguage, which may not be captured by current training objectives. In this\nwork, we first investigate whether current retrieval systems can comprehend the\nBoolean logic implied in language. To answer this question, we formulate the\ntask of Boolean Dense Retrieval and collect a benchmark dataset, BoolQuestions,\nwhich covers complex queries containing basic Boolean logic and corresponding\nannotated passages. Through extensive experimental results on the proposed task\nand benchmark dataset, we draw the conclusion that current dense retrieval\nsystems do not fully understand Boolean logic in language, and there is a long\nway to go to improve our dense retrieval systems. Furthermore, to promote\nfurther research on enhancing the understanding of Boolean logic for language\nmodels, we explore Boolean operation on decomposed query and propose a\ncontrastive continual training method that serves as a strong baseline for the\nresearch community.", "published": "2024-11-19 05:19:53", "link": "http://arxiv.org/abs/2411.12235v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Evaluating Tokenizer Performance of Large Language Models Across\n  Official Indian Languages", "abstract": "Large Language Models (LLMs) based on transformer architectures have\nrevolutionized a variety of domains, with tokenization playing a pivotal role\nin their pre-processing and fine-tuning stages. In multilingual models,\nparticularly those tailored for Indic languages, effective tokenization is\ncrucial for optimizing performance. This paper presents a comprehensive\nevaluation of tokenizers used by 12 LLMs across all 22 official languages of\nIndia, with a focus on comparing the efficiency of their tokenization\nprocesses. We employed the Normalized Sequence Length (NSL) as a key metric in\nour analysis. Our findings reveal that the SUTRA tokenizer outperforms all\nother models, including several Indic-specific models, excelling in 14\nlanguages. Notable insights include the SUTRA tokenizer's superior handling of\nIndic languages, GPT-4o's advancement over its predecessor GPT-4 in processing\nIndian languages, and the limited performance of Project Indus in certain\nlanguages. This study underscores the critical importance of developing\ntargeted tokenization strategies for multilingual and Indic-centric models,\nlaying the groundwork for future improvements in tokenizer design to enhance\nlinguistic coverage and model efficiency.", "published": "2024-11-19 05:37:17", "link": "http://arxiv.org/abs/2411.12240v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Review on Generative AI Models for Synthetic Medical Text, Time\n  Series, and Longitudinal Data", "abstract": "This paper presents the results of a novel scoping review on the practical\nmodels for generating three different types of synthetic health records (SHRs):\nmedical text, time series, and longitudinal data. The innovative aspects of the\nreview, which incorporate study objectives, data modality, and research\nmethodology of the reviewed studies, uncover the importance and the scope of\nthe topic for the digital medicine context. In total, 52 publications met the\neligibility criteria for generating medical time series (22), longitudinal data\n(17), and medical text (13). Privacy preservation was found to be the main\nresearch objective of the studied papers, along with class imbalance, data\nscarcity, and data imputation as the other objectives. The adversarial\nnetwork-based, probabilistic, and large language models exhibited superiority\nfor generating synthetic longitudinal data, time series, and medical texts,\nrespectively. Finding a reliable performance measure to quantify SHR\nre-identification risk is the major research gap of the topic.", "published": "2024-11-19 06:53:54", "link": "http://arxiv.org/abs/2411.12274v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RedPajama: an Open Dataset for Training Large Language Models", "abstract": "Large language models are increasingly becoming a cornerstone technology in\nartificial intelligence, the sciences, and society as a whole, yet the optimal\nstrategies for dataset composition and filtering remain largely elusive. Many\nof the top-performing models lack transparency in their dataset curation and\nmodel development processes, posing an obstacle to the development of fully\nopen language models. In this paper, we identify three core data-related\nchallenges that must be addressed to advance open-source language models. These\ninclude (1) transparency in model development, including the data curation\nprocess, (2) access to large quantities of high-quality data, and (3)\navailability of artifacts and metadata for dataset curation and analysis. To\naddress these challenges, we release RedPajama-V1, an open reproduction of the\nLLaMA training dataset. In addition, we release RedPajama-V2, a massive\nweb-only dataset consisting of raw, unfiltered text data together with quality\nsignals and metadata. Together, the RedPajama datasets comprise over 100\ntrillion tokens spanning multiple domains and with their quality signals\nfacilitate the filtering of data, aiming to inspire the development of numerous\nnew datasets. To date, these datasets have already been used in the training of\nstrong language models used in production, such as Snowflake Arctic,\nSalesforce's XGen and AI2's OLMo. To provide insight into the quality of\nRedPajama, we present a series of analyses and ablation studies with\ndecoder-only language models with up to 1.6B parameters. Our findings\ndemonstrate how quality signals for web data can be effectively leveraged to\ncurate high-quality subsets of the dataset, underscoring the potential of\nRedPajama to advance the development of transparent and high-performing\nlanguage models at scale.", "published": "2024-11-19 09:35:28", "link": "http://arxiv.org/abs/2411.12372v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do LLMs Understand Ambiguity in Text? A Case Study in Open-world\n  Question Answering", "abstract": "Ambiguity in natural language poses significant challenges to Large Language\nModels (LLMs) used for open-domain question answering. LLMs often struggle with\nthe inherent uncertainties of human communication, leading to\nmisinterpretations, miscommunications, hallucinations, and biased responses.\nThis significantly weakens their ability to be used for tasks like\nfact-checking, question answering, feature extraction, and sentiment analysis.\nUsing open-domain question answering as a test case, we compare off-the-shelf\nand few-shot LLM performance, focusing on measuring the impact of explicit\ndisambiguation strategies. We demonstrate how simple, training-free,\ntoken-level disambiguation methods may be effectively used to improve LLM\nperformance for ambiguous question answering tasks. We empirically show our\nfindings and discuss best practices and broader impacts regarding ambiguity in\nLLMs.", "published": "2024-11-19 10:27:26", "link": "http://arxiv.org/abs/2411.12395v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neon: News Entity-Interaction Extraction for Enhanced Question Answering", "abstract": "Capturing fresh information in near real-time and using it to augment\nexisting large language models (LLMs) is essential to generate up-to-date,\ngrounded, and reliable output. This problem becomes particularly challenging\nwhen LLMs are used for informational tasks in rapidly evolving fields, such as\nWeb search related to recent or unfolding events involving entities, where\ngenerating temporally relevant responses requires access to up-to-the-hour news\nsources. However, the information modeled by the parametric memory of LLMs is\noften outdated, and Web results from prototypical retrieval systems may fail to\ncapture the latest relevant information and struggle to handle conflicting\nreports in evolving news. To address this challenge, we present the NEON\nframework, designed to extract emerging entity interactions -- such as events\nor activities -- as described in news articles. NEON constructs an\nentity-centric timestamped knowledge graph that captures such interactions,\nthereby facilitating enhanced QA capabilities related to news events. Our\nframework innovates by integrating open Information Extraction (openIE) style\ntuples into LLMs to enable in-context retrieval-augmented generation. This\nintegration demonstrates substantial improvements in QA performance when\ntackling temporal, entity-centric search queries. Through NEON, LLMs can\ndeliver more accurate, reliable, and up-to-date responses.", "published": "2024-11-19 12:17:43", "link": "http://arxiv.org/abs/2411.12449v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Exploring Iterative Controllable Summarization with Large Language\n  Models", "abstract": "Large language models (LLMs) have demonstrated remarkable performance in\nabstractive summarization tasks. However, their ability to precisely control\nsummary attributes (e.g., length or topic) remains underexplored, limiting\ntheir adaptability to specific user preferences. In this paper, we\nsystematically explore the controllability of LLMs. To this end, we revisit\nsummary attribute measurements and introduce iterative evaluation metrics,\nfailure rate and average iteration count to precisely evaluate controllability\nof LLMs, rather than merely assessing errors. Our findings show that LLMs\nstruggle more with numerical attributes than with linguistic attributes. To\naddress this challenge, we propose a guide-to-explain framework (GTE) for\ncontrollable summarization. Our GTE framework enables the model to identify\nmisaligned attributes in the initial draft and guides it in self-explaining\nerrors in the previous output. By allowing the model to reflect on its\nmisalignment, GTE generates well-adjusted summaries that satisfy the desired\nattributes with robust effectiveness, requiring surprisingly fewer iterations\nthan other iterative approaches.", "published": "2024-11-19 12:36:02", "link": "http://arxiv.org/abs/2411.12460v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Regular-pattern-sensitive CRFs for Distant Label Interactions", "abstract": "Linear-chain conditional random fields (CRFs) are a common model component\nfor sequence labeling tasks when modeling the interactions between different\nlabels is important. However, the Markov assumption limits linear-chain CRFs to\nonly directly modeling interactions between adjacent labels. Weighted\nfinite-state transducers (FSTs) are a related approach which can be made to\nmodel distant label-label interactions, but exact label inference is\nintractable for these models in the general case, and the task of selecting an\nappropriate automaton structure for the desired interaction types poses a\npractical challenge. In this work, we present regular-pattern-sensitive CRFs\n(RPCRFs), a method of enriching standard linear-chain CRFs with the ability to\nlearn long-distance label interactions which occur in user-specified patterns.\nThis approach allows users to write regular-expression label patterns concisely\nspecifying which types of interactions the model should take into account,\nallowing the model to learn from data whether and in which contexts these\npatterns occur. The result can be interpreted alternatively as a CRF augmented\nwith additional, non-local potentials, or as a finite-state transducer whose\nstructure is defined by a set of easily-interpretable patterns. Critically,\nunlike the general case for FSTs (and for non-chain CRFs), exact training and\ninference are tractable for many pattern sets. In this work, we detail how a\nRPCRF can be automatically constructed from a set of user-specified patterns,\nand demonstrate the model's effectiveness on synthetic data, showing how\ndifferent types of patterns can capture different nonlocal dependency\nstructures in label sequences.", "published": "2024-11-19 13:08:03", "link": "http://arxiv.org/abs/2411.12484v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Procedural Knowledge in Pretraining Drives Reasoning in Large Language\n  Models", "abstract": "The capabilities and limitations of Large Language Models have been sketched\nout in great detail in recent years, providing an intriguing yet conflicting\npicture. On the one hand, LLMs demonstrate a general ability to solve problems.\nOn the other hand, they show surprising reasoning gaps when compared to humans,\ncasting doubt on the robustness of their generalisation strategies. The sheer\nvolume of data used in the design of LLMs has precluded us from applying the\nmethod traditionally used to measure generalisation: train-test set separation.\nTo overcome this, we study what kind of generalisation strategies LLMs employ\nwhen performing reasoning tasks by investigating the pretraining data they rely\non. For two models of different sizes (7B and 35B) and 2.5B of their\npretraining tokens, we identify what documents influence the model outputs for\nthree simple mathematical reasoning tasks and contrast this to the data that\nare influential for answering factual questions. We find that, while the models\nrely on mostly distinct sets of data for each factual question, a document\noften has a similar influence across different reasoning questions within the\nsame task, indicating the presence of procedural knowledge. We further find\nthat the answers to factual questions often show up in the most influential\ndata. However, for reasoning questions the answers usually do not show up as\nhighly influential, nor do the answers to the intermediate reasoning steps.\nWhen we characterise the top ranked documents for the reasoning questions\nqualitatively, we confirm that the influential documents often contain\nprocedural knowledge, like demonstrating how to obtain a solution using\nformulae or code. Our findings indicate that the approach to reasoning the\nmodels use is unlike retrieval, and more like a generalisable strategy that\nsynthesises procedural knowledge from documents doing a similar form of\nreasoning.", "published": "2024-11-19 15:47:12", "link": "http://arxiv.org/abs/2411.12580v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Whisper Finetuning on Nepali Language", "abstract": "Despite the growing advancements in Automatic Speech Recognition (ASR)\nmodels, the development of robust models for underrepresented languages, such\nas Nepali, remains a challenge. This research focuses on making an exhaustive\nand generalized dataset followed by fine-tuning OpenAI's Whisper models of\ndifferent sizes to improve transcription (speech-to-text) accuracy for the\nNepali language. We leverage publicly available ASR datasets and self-recorded\ncustom datasets with a diverse range of accents, dialects, and speaking styles\nfurther enriched through augmentation. Our experimental results demonstrate\nthat fine-tuning Whisper models on our curated custom dataset substantially\nreduces the Word Error Rate (WER) across all model sizes attributed to larger\ndata variations in terms of speaker's age, gender, and sentiment, acoustic\nenvironment, dialect, denser audio segments (15-30 seconds) that are more\ncompatible with Whisper's input, and manual curation of audios and\ntranscriptions. Notably, our approach outperforms Whisper's baseline models\ntrained on Fleur's dataset, achieving WER reductions of up to 36.2% on the\nsmall and 23.8% on medium models. Furthermore, we show that data augmentation\nplays a significant role in enhancing model robustness. Our approach underlines\nthe importance of dataset quality, variation, and augmentation in the\nadaptation of state-of-the-art models to underrepresented languages for\ndeveloping accurate ASR systems.", "published": "2024-11-19 15:55:56", "link": "http://arxiv.org/abs/2411.12587v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Virtual Reality and AI Tutoring for Language Learning: A Case\n  Study of a Virtual Campus Environment with OpenAI GPT Integration with Unity\n  3D", "abstract": "This paper presents a new approach to multiple language learning, with Hindi\nthe language to be learnt in our case, by using the integration of virtual\nreality environments and AI enabled tutoring systems using OpenAIs GPT api\ncalls. We have developed a scenario which has a virtual campus environment\nusing Unity which focuses on a detailed representation of our universitys\nbuildings 11th floor, where most of the cultural and technological activities\ntake place. Within this virtual environment that we have created, we have an AI\ntutor powered by OpenAI's GPT model which was called using an api which moves\naround with the user. This provided language learning support in Hindi, as GPT\nis able to take care of language translation. Our approach mainly involves\nutilising speech to text, text to text conversion and text to speech\ncapabilities to facilitate real time interaction between users and the AI tutor\nin the presence of internet. This research demonstrates the use of combining VR\ntechnology with AI tutoring for immersive language learning experiences and\nprovides interaction.", "published": "2024-11-19 16:26:19", "link": "http://arxiv.org/abs/2411.12619v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Enhanced Sign Language Translation between American Sign Language (ASL)\n  and Indian Sign Language (ISL) Using LLMs", "abstract": "We have come up with a research that hopes to provide a bridge between the\nusers of American Sign Language and the users of spoken language and Indian\nSign Language (ISL). The research enabled us to create a novel framework that\nwe have developed for Learner Systems. Leveraging art of Large models to create\nkey features including: - Real-time translation between these two sign\nlanguages in an efficient manner. Making LLM's capability available for\nseamless translations to ISL. Here is the full study showing its implementation\nin this paper. The core of the system is a sophisticated pipeline that begins\nwith reclassification and recognition of ASL gestures based on a strong Random\nForest Classifier. By recognizing the ASL, it is translated into text which can\nbe more easily processed. Highly evolved natural language NLP (Natural Language\nProcessing) techniques come in handy as they play a role in our LLM integration\nwhere you then use LLMs to be able to convert the ASL text to ISL which\nprovides you with the intent of sentence or phrase. The final step is to\nsynthesize the translated text back into ISL gestures, creating an end-to-end\ntranslation experience using RIFE-Net. This framework is tasked with key\nchallenges such as automatically dealing with gesture variability and\novercoming the linguistic differences between ASL and ISL. By automating the\ntranslation process, we hope to vastly improve accessibility for sign language\nusers. No longer will the communication gap between ASL and ISL create\nbarriers; this totally cool innovation aims to bring our communities closer\ntogether. And we believe, with full confidence in our framework, that we're\nable to apply the same principles across a wide variety of sign language\ndialects.", "published": "2024-11-19 17:45:12", "link": "http://arxiv.org/abs/2411.12685v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular,\n  Nervous System, and Digestive Disorders Using Advanced LLMs", "abstract": "In this research, we explored the improvement in terms of multi-class disease\nclassification via pre-trained language models over Medical-Abstracts-TC-Corpus\nthat spans five medical conditions. We excluded non-cancer conditions and\nexamined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and\nBERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained\non medical data, demonstrated superior performance in medical text\nclassification (97% accuracy). Surprisingly, XLNet followed closely (96%\naccuracy), demonstrating its generalizability across domains even though it was\nnot pre-trained on medical data. LastBERT, a custom model based on the lighter\nversion of BERT, also proved competitive with 87.10% accuracy (just under\nBERT's 89.33%). Our findings confirm the importance of specialized models such\nas BioBERT and also support impressions around more general solutions like\nXLNet and well-tuned transformer architectures with fewer parameters (in this\ncase, LastBERT) in medical domain tasks.", "published": "2024-11-19 18:27:25", "link": "http://arxiv.org/abs/2411.12712v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Probing the Capacity of Language Model Agents to Operationalize\n  Disparate Experiential Context Despite Distraction", "abstract": "Large language model (LLM) agents show promise in an increasing number of\ndomains. In many proposed applications, it is expected that the agent reasons\nover accumulated experience presented in an input prompt. We propose the OEDD\n(Operationalize Experience Despite Distraction) corpus, a\nhuman-annotator-validated body of scenarios with pre-scripted agent histories\nwhere the agent must make a decision based on disparate experiential\ninformation in the presence of a distractor. We evaluate three state-of-the-art\nLLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal\nchain-of-thought prompting strategy and observe that when (1) the input context\ncontains over 1,615 tokens of historical interactions, (2) a crucially\ndecision-informing premise is the rightful conclusion over two disparate\nenvironment premises, and (3) a trivial, but distracting red herring fact\nfollows, all LLMs perform worse than random choice at selecting the better of\ntwo actions. Our code and test corpus are publicly available at:\nhttps://github.com/sonnygeorge/OEDD .", "published": "2024-11-19 19:33:16", "link": "http://arxiv.org/abs/2411.12828v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Selective Attention: Enhancing Transformer through Principled Context\n  Control", "abstract": "The attention mechanism within the transformer architecture enables the model\nto weigh and combine tokens based on their relevance to the query. While\nself-attention has enjoyed major success, it notably treats all queries $q$ in\nthe same way by applying the mapping $V^\\top\\text{softmax}(Kq)$, where $V,K$\nare the value and key embeddings respectively. In this work, we argue that this\nuniform treatment hinders the ability to control contextual sparsity and\nrelevance. As a solution, we introduce the $\\textit{Selective Self-Attention}$\n(SSA) layer that augments the softmax nonlinearity with a principled\ntemperature scaling strategy. By controlling temperature, SSA adapts the\ncontextual sparsity of the attention map to the query embedding and its\nposition in the context window. Through theory and experiments, we demonstrate\nthat this alleviates attention dilution, aids the optimization process, and\nenhances the model's ability to control softmax spikiness of individual\nqueries. We also incorporate temperature scaling for value embeddings and show\nthat it boosts the model's ability to suppress irrelevant/noisy tokens.\nNotably, SSA is a lightweight method which introduces less than 0.5% new\nparameters through a weight-sharing strategy and can be fine-tuned on existing\nLLMs. Extensive empirical evaluations demonstrate that SSA-equipped models\nachieve a noticeable and consistent accuracy improvement on language modeling\nbenchmarks.", "published": "2024-11-19 22:17:18", "link": "http://arxiv.org/abs/2411.12892v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via\n  Reinforcement Learning", "abstract": "Large language models (LLMs) have demonstrated impressive success in a wide\nrange of natural language processing (NLP) tasks due to their extensive general\nknowledge of the world. Recent works discovered that the performance of LLMs is\nheavily dependent on the input prompt. However, prompt engineering is usually\ndone manually in a trial-and-error fashion, which can be labor-intensive and\nchallenging in order to find the optimal prompts. To address these problems and\nunleash the utmost potential of LLMs, we propose a novel LLMs-agnostic\nframework for prompt optimization, namely GRL-Prompt, which aims to\nautomatically construct optimal prompts via reinforcement learning (RL) in an\nend-to-end manner. To provide structured action/state representation for\noptimizing prompts, we construct a knowledge graph (KG) that better encodes the\ncorrelation between the user query and candidate in-context examples.\nFurthermore, a policy network is formulated to generate the optimal action by\nselecting a set of in-context examples in a rewardable order to construct the\nprompt. Additionally, the embedding-based reward shaping is utilized to\nstabilize the RL training process. The experimental results show that\nGRL-Prompt outperforms recent state-of-the-art methods, achieving an average\nincrease of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in\nBLEU.", "published": "2024-11-19 10:52:25", "link": "http://arxiv.org/abs/2411.14479v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat", "abstract": "Deciding which large language model (LLM) to use is a complex challenge.\nPairwise ranking has emerged as a new method for evaluating human preferences\nfor LLMs. This approach entails humans evaluating pairs of model outputs based\non a predefined criterion. By collecting these comparisons, a ranking can be\nconstructed using methods such as Elo. However, applying these algorithms as\nconstructed in the context of LLM evaluation introduces several challenges. In\nthis paper, we explore the effectiveness of ranking systems for head-to-head\ncomparisons of LLMs. We formally define a set of fundamental principles for\neffective ranking and conduct a series of extensive evaluations on the\nrobustness of several ranking algorithms in the context of LLMs. Our analysis\nuncovers key insights into the factors that affect ranking accuracy and\nefficiency, offering guidelines for selecting the most appropriate methods\nbased on specific evaluation contexts and resource constraints.", "published": "2024-11-19 20:16:26", "link": "http://arxiv.org/abs/2411.14483v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Computational Method for Measuring \"Open Codes\" in Qualitative\n  Analysis", "abstract": "Qualitative analysis is critical to understanding human datasets in many\nsocial science disciplines. Open coding is an inductive qualitative process\nthat identifies and interprets \"open codes\" from datasets. Yet, meeting\nmethodological expectations (such as \"as exhaustive as possible\") can be\nchallenging. While many machine learning (ML)/generative AI (GAI) studies have\nattempted to support open coding, few have systematically measured or evaluated\nGAI outcomes, increasing potential bias risks. Building on Grounded Theory and\nThematic Analysis theories, we present a computational method to measure and\nidentify potential biases from \"open codes\" systematically. Instead of\noperationalizing human expert results as the \"ground truth,\" our method is\nbuilt upon a team-based approach between human and machine coders. We\nexperiment with two HCI datasets to establish this method's reliability by 1)\ncomparing it with human analysis, and 2) analyzing its output stability. We\npresent evidence-based suggestions and example workflows for ML/GAI to support\nopen coding.", "published": "2024-11-19 00:44:56", "link": "http://arxiv.org/abs/2411.12142v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Just KIDDIN: Knowledge Infusion and Distillation for Detection of\n  INdecent Memes", "abstract": "Toxicity identification in online multimodal environments remains a\nchallenging task due to the complexity of contextual connections across\nmodalities (e.g., textual and visual). In this paper, we propose a novel\nframework that integrates Knowledge Distillation (KD) from Large Visual\nLanguage Models (LVLMs) and knowledge infusion to enhance the performance of\ntoxicity detection in hateful memes. Our approach extracts sub-knowledge graphs\nfrom ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused\nwithin a compact VLM framework. The relational context between toxic phrases in\ncaptions and memes, as well as visual concepts in memes enhance the model's\nreasoning capabilities. Experimental results from our study on two hate speech\nbenchmark datasets demonstrate superior performance over the state-of-the-art\nbaselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,\nrespectively. Given the contextual complexity of the toxicity detection task,\nour approach showcases the significance of learning from both explicit (i.e.\nKG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a\nhybrid neurosymbolic approach. This is crucial for real-world applications\nwhere accurate and scalable recognition of toxic content is critical for\ncreating safer online environments.", "published": "2024-11-19 02:39:28", "link": "http://arxiv.org/abs/2411.12174v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Predicting User Intents and Musical Attributes from Music Discovery\n  Conversations", "abstract": "Intent classification is a text understanding task that identifies user needs\nfrom input text queries. While intent classification has been extensively\nstudied in various domains, it has not received much attention in the music\ndomain. In this paper, we investigate intent classification models for music\ndiscovery conversation, focusing on pre-trained language models. Rather than\nonly predicting functional needs: intent classification, we also include a task\nfor classifying musical needs: musical attribute classification. Additionally,\nwe propose a method of concatenating previous chat history with just\nsingle-turn user queries in the input text, allowing the model to understand\nthe overall conversation context better. Our proposed model significantly\nimproves the F1 score for both user intent and musical attribute\nclassification, and surpasses the zero-shot and few-shot performance of the\npretrained Llama 3 model.", "published": "2024-11-19 05:58:22", "link": "http://arxiv.org/abs/2411.12254v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Building Trust: Foundations of Security, Safety and Transparency in AI", "abstract": "This paper explores the rapidly evolving ecosystem of publicly available AI\nmodels, and their potential implications on the security and safety landscape.\nAs AI models become increasingly prevalent, understanding their potential risks\nand vulnerabilities is crucial. We review the current security and safety\nscenarios while highlighting challenges such as tracking issues, remediation,\nand the apparent absence of AI model lifecycle and ownership processes.\nComprehensive strategies to enhance security and safety for both model\ndevelopers and end-users are proposed. This paper aims to provide some of the\nfoundational pieces for more standardized security, safety, and transparency in\nthe development and operation of AI models and the larger open ecosystems and\ncommunities forming around them.", "published": "2024-11-19 06:55:57", "link": "http://arxiv.org/abs/2411.12275v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Balancing Accuracy and Efficiency in Multi-Turn Intent Classification\n  for LLM-Powered Dialog Systems in Production", "abstract": "Accurate multi-turn intent classification is essential for advancing\nconversational AI systems. However, challenges such as the scarcity of\ncomprehensive datasets and the complexity of contextual dependencies across\ndialogue turns hinder progress. This paper presents two novel approaches\nleveraging Large Language Models (LLMs) to enhance scalability and reduce\nlatency in production dialogue systems. First, we introduce Symbol Tuning,\nwhich simplifies intent labels to reduce task complexity and improve\nperformance in multi-turn dialogues. Second, we propose C-LARA\n(Consistency-aware, Linguistics Adaptive Retrieval Augmentation), a framework\nthat employs LLMs for data augmentation and pseudo-labeling to generate\nsynthetic multi-turn dialogues. These enriched datasets are used to fine-tune a\nsmall, efficient model suitable for deployment. Experiments conducted on\nmultilingual dialogue datasets demonstrate significant improvements in\nclassification accuracy and resource efficiency. Our methods enhance multi-turn\nintent classification accuracy by 5.09%, reduce annotation costs by 40%, and\nenable scalable deployment in low-resource multilingual industrial systems,\nhighlighting their practicality and impact.", "published": "2024-11-19 07:48:35", "link": "http://arxiv.org/abs/2411.12307v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Layered Architecture for Developing and Enhancing Capabilities in\n  Large Language Model-based Software Systems", "abstract": "Significant efforts has been made to expand the use of Large Language Models\n(LLMs) beyond basic language tasks. While the generalizability and versatility\nof LLMs have enabled widespread adoption, evolving demands in application\ndevelopment often exceed their native capabilities. Meeting these demands may\ninvolve a diverse set of methods, such as enhancing creativity through either\ninference temperature adjustments or creativity-provoking prompts. Selecting\nthe right approach is critical, as different methods lead to trade-offs in\nengineering complexity, scalability, and operational costs. This paper\nintroduces a layered architecture that organizes LLM software system\ndevelopment into distinct layers, each characterized by specific attributes. By\naligning capabilities with these layers, the framework encourages the\nsystematic implementation of capabilities in effective and efficient ways that\nultimately supports desired functionalities and qualities. Through practical\ncase studies, we illustrate the utility of the framework. This work offers\ndevelopers actionable insights for selecting suitable technologies in LLM-based\nsoftware system development, promoting robustness and scalability.", "published": "2024-11-19 09:18:20", "link": "http://arxiv.org/abs/2411.12357v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Evaluating the Prompt Steerability of Large Language Models", "abstract": "Building pluralistic AI requires designing models that are able to be shaped\nto represent a wide range of value systems and cultures. Achieving this\nrequires first being able to evaluate the degree to which a given model is\ncapable of reflecting various personas. To this end, we propose a benchmark for\nevaluating the steerability of model personas as a function of prompting. Our\ndesign is based on a formal definition of prompt steerability, which analyzes\nthe degree to which a model's joint behavioral distribution can be shifted from\nits baseline. By defining steerability indices and inspecting how these indices\nchange as a function of steering effort, we can estimate the steerability of a\nmodel across various persona dimensions and directions. Our benchmark reveals\nthat the steerability of many current models is limited -- due to both a skew\nin their baseline behavior and an asymmetry in their steerability across many\npersona dimensions. We release an implementation of our benchmark at\nhttps://github.com/IBM/prompt-steering.", "published": "2024-11-19 10:41:54", "link": "http://arxiv.org/abs/2411.12405v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Analysing Explanation-Related Interactions in Collaborative\n  Perception-Cognition-Communication-Action", "abstract": "Effective communication is essential in collaborative tasks, so AI-equipped\nrobots working alongside humans need to be able to explain their behaviour in\norder to cooperate effectively and earn trust. We analyse and classify\ncommunications among human participants collaborating to complete a simulated\nemergency response task. The analysis identifies messages that relate to\nvarious kinds of interactive explanations identified in the explainable AI\nliterature. This allows us to understand what type of explanations humans\nexpect from their teammates in such settings, and thus where AI-equipped robots\nmost need explanation capabilities. We find that most explanation-related\nmessages seek clarification in the decisions or actions taken. We also confirm\nthat messages have an impact on the performance of our simulated task.", "published": "2024-11-19 13:07:04", "link": "http://arxiv.org/abs/2411.12483v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues", "abstract": "Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and\nDeltaNet have emerged as efficient alternatives to Transformers for long\nsequences. However, both Transformers and LRNNs struggle to perform\nstate-tracking, which may impair performance in tasks such as code evaluation.\nIn one forward pass, current architectures are unable to solve even parity, the\nsimplest state-tracking task, which non-linear RNNs can handle effectively.\nRecently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like\nMamba to solve parity stems from restricting the value range of their diagonal\nstate-transition matrices to $[0, 1]$ and that incorporating negative values\ncan resolve this issue. We extend this result to non-diagonal LRNNs such as\nDeltaNet. We prove that finite precision LRNNs with state-transition matrices\nhaving only positive eigenvalues cannot solve parity, while non-triangular\nmatrices are needed to count modulo $3$. Notably, we also prove that LRNNs can\nlearn any regular language when their state-transition matrices are products of\nidentity minus vector outer product matrices, each with eigenvalues in the\nrange $[-1, 1]$. Our experiments confirm that extending the eigenvalue range of\nMamba and DeltaNet to include negative values not only enables them to solve\nparity but consistently improves their performance on state-tracking tasks. We\nalso show that state-tracking enabled LRNNs can be pretrained stably and\nefficiently at scale (1.3B parameters), achieving competitive performance on\nlanguage modeling and showing promise on code and math tasks.", "published": "2024-11-19 14:35:38", "link": "http://arxiv.org/abs/2411.12537v5", "categories": ["cs.LG", "cs.CL", "cs.FL"], "primary_category": "cs.LG"}
{"title": "Predicting Customer Satisfaction by Replicating the Survey Response\n  Distribution", "abstract": "For many call centers, customer satisfaction (CSAT) is a key performance\nindicator (KPI). However, only a fraction of customers take the CSAT survey\nafter the call, leading to a biased and inaccurate average CSAT value, and\nmissed opportunities for coaching, follow-up, and rectification. Therefore,\ncall centers can benefit from a model predicting customer satisfaction on calls\nwhere the customer did not complete the survey. Given that CSAT is a closely\nmonitored KPI, it is critical to minimize any bias in the average predicted\nCSAT (pCSAT). In this paper, we introduce a method such that predicted CSAT\n(pCSAT) scores accurately replicate the distribution of survey CSAT responses\nfor every call center with sufficient data in a live production environment.\nThe method can be applied to many multiclass classification problems to improve\nthe class balance and minimize its changes upon model updates.", "published": "2024-11-19 14:39:29", "link": "http://arxiv.org/abs/2411.12539v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models for Combinatorial Optimization of Design Structure\n  Matrix", "abstract": "Combinatorial optimization (CO) is essential for improving efficiency and\nperformance in engineering applications. As complexity increases with larger\nproblem sizes and more intricate dependencies, identifying the optimal solution\nbecome challenging. When it comes to real-world engineering problems,\nalgorithms based on pure mathematical reasoning are limited and incapable to\ncapture the contextual nuances necessary for optimization. This study explores\nthe potential of Large Language Models (LLMs) in solving engineering CO\nproblems by leveraging their reasoning power and contextual knowledge. We\npropose a novel LLM-based framework that integrates network topology and domain\nknowledge to optimize the sequencing of Design Structure Matrix (DSM)-a common\nCO problem. Our experiments on various DSM cases demonstrate that the proposed\nmethod achieves faster convergence and higher solution quality than benchmark\nmethods. Moreover, results show that incorporating contextual domain knowledge\nsignificantly improves performance despite the choice of LLMs. These findings\nhighlight the potential of LLMs in tackling complex real-world CO problems by\ncombining semantic and mathematical reasoning. This approach paves the way for\na new paradigm in in real-world combinatorial optimization.", "published": "2024-11-19 15:39:51", "link": "http://arxiv.org/abs/2411.12571v1", "categories": ["cs.CE", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "primary_category": "cs.CE"}
{"title": "DLBacktrace: A Model Agnostic Explainability for any Deep Learning\n  Models", "abstract": "The rapid growth of AI has led to more complex deep learning models, often\noperating as opaque \"black boxes\" with limited transparency in their\ndecision-making. This lack of interpretability poses challenges, especially in\nhigh-stakes applications where understanding model output is crucial. This work\nhighlights the importance of interpretability in fostering trust,\naccountability, and responsible deployment. To address these challenges, we\nintroduce DLBacktrace, a novel, model-agnostic technique designed to provide\nclear insights into deep learning model decisions across a wide range of\ndomains and architectures, including MLPs, CNNs, and Transformer-based LLM\nmodels. We present a comprehensive overview of DLBacktrace and benchmark its\nperformance against established interpretability methods such as SHAP, LIME,\nand GradCAM. Our results demonstrate that DLBacktrace effectively enhances\nunderstanding of model behavior across diverse tasks. DLBacktrace is compatible\nwith models developed in both PyTorch and TensorFlow, supporting architectures\nsuch as BERT, ResNet, U-Net, and custom DNNs for tabular data. The library is\nopen-sourced and available at https://github.com/AryaXAI/DLBacktrace .", "published": "2024-11-19 16:54:30", "link": "http://arxiv.org/abs/2411.12643v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Neurosymbolic Graph Enrichment for Grounded World Models", "abstract": "The development of artificial intelligence systems capable of understanding\nand reasoning about complex real-world scenarios is a significant challenge. In\nthis work we present a novel approach to enhance and exploit LLM reactive\ncapability to address complex problems and interpret deeply contextual\nreal-world meaning. We introduce a method and a tool for creating a multimodal,\nknowledge-augmented formal representation of meaning that combines the\nstrengths of large language models with structured semantic representations.\nOur method begins with an image input, utilizing state-of-the-art large\nlanguage models to generate a natural language description. This description is\nthen transformed into an Abstract Meaning Representation (AMR) graph, which is\nformalized and enriched with logical design patterns, and layered semantics\nderived from linguistic and factual knowledge bases. The resulting graph is\nthen fed back into the LLM to be extended with implicit knowledge activated by\ncomplex heuristic learning, including semantic implicatures, moral values,\nembodied cognition, and metaphorical representations. By bridging the gap\nbetween unstructured language models and formal semantic structures, our method\nopens new avenues for tackling intricate problems in natural language\nunderstanding and reasoning.", "published": "2024-11-19 17:23:55", "link": "http://arxiv.org/abs/2411.12671v1", "categories": ["cs.AI", "cs.CL", "cs.ET"], "primary_category": "cs.AI"}
{"title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech\n  Evaluation", "abstract": "Despite rapid advancements in TTS models, a consistent and robust human\nevaluation framework is still lacking. For example, MOS tests fail to\ndifferentiate between similar models, and CMOS's pairwise comparisons are\ntime-intensive. The MUSHRA test is a promising alternative for evaluating\nmultiple TTS systems simultaneously, but in this work we show that its reliance\non matching human reference speech unduly penalises the scores of modern TTS\nsystems that can exceed human speech quality. More specifically, we conduct a\ncomprehensive assessment of the MUSHRA test, focusing on its sensitivity to\nfactors such as rater variability, listener fatigue, and reference bias. Based\non our extensive evaluation involving 492 human listeners across Hindi and\nTamil we identify two primary shortcomings: (i) reference-matching bias, where\nraters are unduly influenced by the human reference, and (ii) judgement\nambiguity, arising from a lack of clear fine-grained guidelines. To address\nthese issues, we propose two refined variants of the MUSHRA test. The first\nvariant enables fairer ratings for synthesized samples that surpass human\nreference quality. The second variant reduces ambiguity, as indicated by the\nrelatively lower variance across raters. By combining these approaches, we\nachieve both more reliable and more fine-grained assessments. We also release\nMANGO, a massive dataset of 246,000 human ratings, the first-of-its-kind\ncollection for Indian languages, aiding in analyzing human preferences and\ndeveloping automatic metrics for evaluating TTS systems.", "published": "2024-11-19 18:37:45", "link": "http://arxiv.org/abs/2411.12719v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Information Theory of Meaningful Communication", "abstract": "In Shannon's seminal paper, entropy of printed English, treated as a\nstationary stochastic process, was estimated to be roughly 1 bit per character.\nHowever, considered as a means of communication, language differs considerably\nfrom its printed form: (i) the units of information are not characters or even\nwords but clauses, i.e. shortest meaningful parts of speech; and (ii) what is\ntransmitted is principally the meaning of what is being said or written, while\nthe precise phrasing that was used to communicate the meaning is typically\nignored. In this study, we show that one can leverage recently developed large\nlanguage models to quantify information communicated in meaningful narratives\nin terms of bits of meaning per clause.", "published": "2024-11-19 18:51:23", "link": "http://arxiv.org/abs/2411.12728v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Revisiting Fake News Detection: Towards Temporality-aware Evaluation by\n  Leveraging Engagement Earliness", "abstract": "Social graph-based fake news detection aims to identify news articles\ncontaining false information by utilizing social contexts, e.g., user\ninformation, tweets and comments. However, conventional methods are evaluated\nunder less realistic scenarios, where the model has access to future knowledge\non article-related and context-related data during training. In this work, we\nnewly formalize a more realistic evaluation scheme that mimics real-world\nscenarios, where the data is temporality-aware and the detection model can only\nbe trained on data collected up to a certain point in time. We show that the\ndiscriminative capabilities of conventional methods decrease sharply under this\nnew setting, and further propose DAWN, a method more applicable to such\nscenarios. Our empirical findings indicate that later engagements (e.g.,\nconsuming or reposting news) contribute more to noisy edges that link real\nnews-fake news pairs in the social graph. Motivated by this, we utilize feature\nrepresentations of engagement earliness to guide an edge weight estimator to\nsuppress the weights of such noisy edges, thereby enhancing the detection\nperformance of DAWN. Through extensive experiments, we demonstrate that DAWN\noutperforms existing fake news detection methods under real-world environments.\nThe source code is available at https://github.com/LeeJunmo/DAWN.", "published": "2024-11-19 05:08:00", "link": "http://arxiv.org/abs/2411.12775v1", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Human-Robot Dialogue Annotation for Multi-Modal Common Ground", "abstract": "In this paper, we describe the development of symbolic representations\nannotated on human-robot dialogue data to make dimensions of meaning accessible\nto autonomous systems participating in collaborative, natural language\ndialogue, and to enable common ground with human partners. A particular\nchallenge for establishing common ground arises in remote dialogue (occurring\nin disaster relief or search-and-rescue tasks), where a human and robot are\nengaged in a joint navigation and exploration task of an unfamiliar\nenvironment, but where the robot cannot immediately share high quality visual\ninformation due to limited communication constraints. Engaging in a dialogue\nprovides an effective way to communicate, while on-demand or lower-quality\nvisual information can be supplemented for establishing common ground. Within\nthis paradigm, we capture propositional semantics and the illocutionary force\nof a single utterance within the dialogue through our Dialogue-AMR annotation,\nan augmentation of Abstract Meaning Representation. We then capture patterns in\nhow different utterances within and across speaker floors relate to one another\nin our development of a multi-floor Dialogue Structure annotation schema.\nFinally, we begin to annotate and analyze the ways in which the visual\nmodalities provide contextual information to the dialogue for overcoming\ndisparities in the collaborators' understanding of the environment. We conclude\nby discussing the use-cases, architectures, and systems we have implemented\nfrom our annotations that enable physical robots to autonomously engage with\nhumans in bi-directional dialogue and navigation.", "published": "2024-11-19 19:33:54", "link": "http://arxiv.org/abs/2411.12829v1", "categories": ["cs.HC", "cs.CL", "cs.RO", "I.2.7; I.2.9; I.2.10; H.5.2; J.7"], "primary_category": "cs.HC"}
{"title": "Reward Modeling with Ordinal Feedback: Wisdom of the Crowd", "abstract": "Learning a reward model (RM) from human preferences has been an important\ncomponent in aligning large language models (LLMs). The canonical setup of\nlearning RMs from pairwise preference data is rooted in the classic\nBradley-Terry (BT) model that accepts binary feedback, i.e., the label being\neither Response 1 is better than Response 2, or the opposite. Such a setup\ninevitably discards potentially useful samples (such as \"tied\" between the two\nresponses) and loses more fine-grained information (such as \"slightly better\").\nIn this paper, we propose a framework for learning RMs under ordinal feedback\nwhich generalizes the case of binary preference feedback to any arbitrary\ngranularity. Specifically, we first identify a marginal unbiasedness condition,\nwhich generalizes the assumption of the BT model in the existing binary\nfeedback setting. The condition validates itself via the sociological concept\nof the wisdom of the crowd. Under the condition, we develop a natural\nprobability model for pairwise preference data under ordinal feedback and\nanalyze its properties. We prove the statistical benefits of ordinal feedback\nin terms of reducing the Rademacher complexity compared to the case of binary\nfeedback. The proposed learning objective and the theory also extend to hinge\nloss and direct policy optimization (DPO). In particular, the theoretical\nanalysis may be of independent interest when applying to a seemingly unrelated\nproblem of knowledge distillation to interpret the bias-variance trade-off\ntherein. The framework also sheds light on writing guidance for human\nannotators. Our numerical experiments validate that fine-grained feedback leads\nto better reward learning for both in-distribution and out-of-distribution\nsettings. Further experiments show that incorporating a certain proportion of\nsamples with tied preference boosts RM learning.", "published": "2024-11-19 20:17:04", "link": "http://arxiv.org/abs/2411.12843v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SCOUT: A Situated and Multi-Modal Human-Robot Dialogue Corpus", "abstract": "We introduce the Situated Corpus Of Understanding Transactions (SCOUT), a\nmulti-modal collection of human-robot dialogue in the task domain of\ncollaborative exploration. The corpus was constructed from multiple\nWizard-of-Oz experiments where human participants gave verbal instructions to a\nremotely-located robot to move and gather information about its surroundings.\nSCOUT contains 89,056 utterances and 310,095 words from 278 dialogues averaging\n320 utterances per dialogue. The dialogues are aligned with the multi-modal\ndata streams available during the experiments: 5,785 images and 30 maps. The\ncorpus has been annotated with Abstract Meaning Representation and Dialogue-AMR\nto identify the speaker's intent and meaning within an utterance, and with\nTransactional Units and Relations to track relationships between utterances to\nreveal patterns of the Dialogue Structure. We describe how the corpus and its\nannotations have been used to develop autonomous human-robot systems and enable\nresearch in open questions of how humans speak to robots. We release this\ncorpus to accelerate progress in autonomous, situated, human-robot dialogue,\nespecially in the context of navigation tasks where details about the\nenvironment need to be discovered.", "published": "2024-11-19 20:18:55", "link": "http://arxiv.org/abs/2411.12844v1", "categories": ["cs.HC", "cs.CL", "cs.RO", "I.2.7; I.2.9; I.2.10; H.5.2; J.7"], "primary_category": "cs.HC"}
{"title": "ProSec: Fortifying Code LLMs with Proactive Security Alignment", "abstract": "Recent advances in code-specific large language models (LLMs) have greatly\nenhanced code generation and refinement capabilities. However, the safety of\ncode LLMs remains under-explored, posing potential risks as insecure code\ngenerated by these models may introduce vulnerabilities into real-world\nsystems. Previous work proposes to collect security-focused instruction-tuning\ndataset from real-world vulnerabilities. It is constrained by the data sparsity\nof vulnerable code, and has limited applicability in the iterative\npost-training workflows of modern LLMs. In this paper, we propose ProSec, a\nnovel proactive security alignment approach designed to align code LLMs with\nsecure coding practices. ProSec systematically exposes the vulnerabilities in a\ncode LLM by synthesizing error-inducing coding scenarios from Common Weakness\nEnumerations (CWEs), and generates fixes to vulnerable code snippets, allowing\nthe model to learn secure practices through advanced preference learning\nobjectives. The scenarios synthesized by ProSec triggers 25 times more\nvulnerable code than a normal instruction-tuning dataset, resulting in a\nsecurity-focused alignment dataset 7 times larger than the previous work.\nExperiments show that models trained with ProSec are 25.2% to 91.4% more secure\ncompared to previous work without degrading models' utility.", "published": "2024-11-19 22:00:01", "link": "http://arxiv.org/abs/2411.12882v2", "categories": ["cs.CR", "cs.CL", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Loss-to-Loss Prediction: Scaling Laws for All Datasets", "abstract": "While scaling laws provide a reliable methodology for predicting train loss\nacross compute scales for a single data distribution, less is known about how\nthese predictions should change as we change the distribution. In this paper,\nwe derive a strategy for predicting one loss from another and apply it to\npredict across different pre-training datasets and from pre-training data to\ndownstream task data. Our predictions extrapolate well even at 20x the largest\nFLOP budget used to fit the curves. More precisely, we find that there are\nsimple shifted power law relationships between (1) the train losses of two\nmodels trained on two separate datasets when the models are paired by training\ncompute (train-to-train), (2) the train loss and the test loss on any\ndownstream distribution for a single model (train-to-test), and (3) the test\nlosses of two models trained on two separate train datasets (test-to-test). The\nresults hold up for pre-training datasets that differ substantially (some are\nentirely code and others have no code at all) and across a variety of\ndownstream tasks. Finally, we find that in some settings these shifted power\nlaw relationships can yield more accurate predictions than extrapolating\nsingle-dataset scaling laws.", "published": "2024-11-19 23:23:16", "link": "http://arxiv.org/abs/2411.12925v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "RadPhi-3: Small Language Models for Radiology", "abstract": "LLM based copilot assistants are useful in everyday tasks. There is a\nproliferation in the exploration of AI assistant use cases to support radiology\nworkflows in a reliable manner. In this work, we present RadPhi-3, a Small\nLanguage Model instruction tuned from Phi-3-mini-4k-instruct with 3.8B\nparameters to assist with various tasks in radiology workflows. While\nimpression summary generation has been the primary task which has been explored\nin prior works w.r.t radiology reports of Chest X-rays, we also explore other\nuseful tasks like change summary generation comparing the current radiology\nreport and its prior report, section extraction from radiology reports, tagging\nthe reports with various pathologies and tubes, lines or devices present in\nthem etc. In-addition, instruction tuning RadPhi-3 involved learning from a\ncredible knowledge source used by radiologists, Radiopaedia.org. RadPhi-3 can\nbe used both to give reliable answers for radiology related queries as well as\nperform useful tasks related to radiology reports. RadPhi-3 achieves SOTA\nresults on the RaLEs radiology report generation benchmark.", "published": "2024-11-19 11:24:28", "link": "http://arxiv.org/abs/2411.13604v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "StreetviewLLM: Extracting Geographic Information Using a\n  Chain-of-Thought Multimodal Large Language Model", "abstract": "Geospatial predictions are crucial for diverse fields such as disaster\nmanagement, urban planning, and public health. Traditional machine learning\nmethods often face limitations when handling unstructured or multi-modal data\nlike street view imagery. To address these challenges, we propose\nStreetViewLLM, a novel framework that integrates a large language model with\nthe chain-of-thought reasoning and multimodal data sources. By combining street\nview imagery with geographic coordinates and textual data, StreetViewLLM\nimproves the precision and granularity of geospatial predictions. Using\nretrieval-augmented generation techniques, our approach enhances geographic\ninformation extraction, enabling a detailed analysis of urban environments. The\nmodel has been applied to seven global cities, including Hong Kong, Tokyo,\nSingapore, Los Angeles, New York, London, and Paris, demonstrating superior\nperformance in predicting urban indicators, including population density,\naccessibility to healthcare, normalized difference vegetation index, building\nheight, and impervious surface. The results show that StreetViewLLM\nconsistently outperforms baseline models, offering improved predictive accuracy\nand deeper insights into the built environment. This research opens new\nopportunities for integrating the large language model into urban analytics,\ndecision-making in urban planning, infrastructure management, and environmental\nmonitoring.", "published": "2024-11-19 05:15:19", "link": "http://arxiv.org/abs/2411.14476v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Guiding Word Equation Solving using Graph Neural Networks (Extended\n  Technical Report)", "abstract": "This paper proposes a Graph Neural Network-guided algorithm for solving word\nequations, based on the well-known Nielsen transformation for splitting\nequations. The algorithm iteratively rewrites the first terms of each side of\nan equation, giving rise to a tree-like search space. The choice of path at\neach split point of the tree significantly impacts solving time, motivating the\nuse of Graph Neural Networks (GNNs) for efficient split decision-making. Split\ndecisions are encoded as multi-classification tasks, and five graph\nrepresentations of word equations are introduced to encode their structural\ninformation for GNNs. The algorithm is implemented as a solver named DragonLi.\nExperiments are conducted on artificial and real-world benchmarks. The\nalgorithm performs particularly well on satisfiable problems. For single word\n\\mbox{equations}, DragonLi can solve significantly more problems than\nwell-established string solvers. For the conjunction of multiple word\nequations, DragonLi is competitive with state-of-the-art string solvers.", "published": "2024-11-19 14:15:34", "link": "http://arxiv.org/abs/2411.15194v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.LG"}
{"title": "Graph Neural Network-Based Entity Extraction and Relationship Reasoning\n  in Complex Knowledge Graphs", "abstract": "This study proposed a knowledge graph entity extraction and relationship\nreasoning algorithm based on a graph neural network, using a graph\nconvolutional network and graph attention network to model the complex\nstructure in the knowledge graph. By building an end-to-end joint model, this\npaper achieves efficient recognition and reasoning of entities and\nrelationships. In the experiment, this paper compared the model with a variety\nof deep learning algorithms and verified its superiority through indicators\nsuch as AUC, recall rate, precision rate, and F1 value. The experimental\nresults show that the model proposed in this paper performs well in all\nindicators, especially in complex knowledge graphs, it has stronger\ngeneralization ability and stability. This provides strong support for further\nresearch on knowledge graphs and also demonstrates the application potential of\ngraph neural networks in entity extraction and relationship reasoning.", "published": "2024-11-19 16:23:49", "link": "http://arxiv.org/abs/2411.15195v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Arabic-Nougat: Fine-Tuning Vision Transformers for Arabic OCR and\n  Markdown Extraction", "abstract": "We present Arabic-Nougat, a suite of OCR models for converting Arabic book\npages into structured Markdown text. Based on Meta's Nougat architecture,\nArabic-Nougat includes three specialized models: arabic-small-nougat,\narabic-base-nougat, and arabic-large-nougat. These models are fine-tuned on a\nsynthetic dataset, arabic-img2md, comprising 13.7k pairs of Arabic book pages\nand their Markdown representations. Key contributions include the\nAranizer-PBE-86k tokenizer, designed for efficient tokenization, and the use of\ntorch.bfloat16 precision with Flash Attention 2 for optimized training and\ninference. Our models achieve state-of-the-art performance, with\narabic-large-nougat delivering the highest Markdown Structure Accuracy and the\nlowest Character Error Rate. Additionally, we release a large-scale dataset\ncontaining 1.1 billion Arabic tokens extracted from over 8,500 books using our\nbest-performing model, providing a valuable resource for Arabic OCR research.\nAll models, datasets, and code are open-sourced and available at\nhttps://github.com/MohamedAliRashad/arabic-nougat.", "published": "2024-11-19 12:09:12", "link": "http://arxiv.org/abs/2411.17835v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Optimizing Airline Reservation Systems with Edge-Enabled Microservices:\n  A Framework for Real-Time Data Processing and Enhanced User Responsiveness", "abstract": "The growing complexity of the operations of airline reservations requires a\nsmart solution for the adoption of novel approaches to the development of\nquick, efficient, and adaptive reservation systems. This paper outlines in\ndetail a conceptual framework for the implementation of edge computing\nmicroservices in order to address the shortcomings of traditional centralized\narchitectures. Specifically, as edge computing allows for certain activities\nsuch as seat inventory checks, booking processes and even confirmation to be\ndone nearer to the user, thus lessening the overall response time and improving\nthe performance of the system. In addition, the framework value should include\nachieving the high performance of the system such as low latency, high\nthroughput and higher user experience. The major design components include\ndeployed distributed computing microservices orchestrated by Kubernetes,\nreal-time message processing system with Kafka and its elastic scaling. Other\noperational components include Prometheus and Grafana, which are used to\nmonitor and manage resources, ensuring that all operational processes are\noptimized. Although this research focuses on a design and theoretical scheming\nof the framework, its use is foreseen to be more advantageous in facilitating a\ntransform in the provision of services in the airline industry by improving\ncustomers' satisfaction, providing infrastructure which is cheap to install and\nefficiently supporting technology changes such as artificial intelligence and\ninternet of things embedded systems. This research addresses the increasing\ndemand for new technologies with modern well-distributed and real-time-centric\nsystems and also provides a basis for future case implementation and testing.\nAs such, the proposed architecture offers a market-ready, extensible solution\nto the problems posed by existing airline reservation systems .", "published": "2024-11-19 16:58:15", "link": "http://arxiv.org/abs/2411.12650v1", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.CL", "cs.DC"], "primary_category": "cs.SE"}
{"title": "Signformer is all you need: Towards Edge AI for Sign Language", "abstract": "Sign language translation, especially in gloss-free paradigm, is confronting\na dilemma of impracticality and unsustainability due to growing\nresource-intensive methodologies. Contemporary state-of-the-arts (SOTAs) have\nsignificantly hinged on pretrained sophiscated backbones such as Large Language\nModels (LLMs), embedding sources, or extensive datasets, inducing considerable\nparametric and computational inefficiency for sustainable use in real-world\nscenario. Despite their success, following this research direction undermines\nthe overarching mission of this domain to create substantial value to bridge\nhard-hearing and common populations. Committing to the prevailing trend of LLM\nand Natural Language Processing (NLP) studies, we pursue a profound essential\nchange in architecture to achieve ground-up improvements without external aid\nfrom pretrained models, prior knowledge transfer, or any NLP strategies\nconsidered not-from-scratch.\n  Introducing Signformer, a from-scratch Feather-Giant transforming the area\ntowards Edge AI that redefines extremities of performance and efficiency with\nLLM-competence and edgy-deployable compactness. In this paper, we present\nnature analysis of sign languages to inform our algorithmic design and deliver\na scalable transformer pipeline with convolution and attention novelty. We\nachieve new 2nd place on leaderboard with a parametric reduction of 467-1807x\nagainst the finests as of 2024 and outcompete almost every other methods in a\nlighter configuration of 0.57 million parameters.", "published": "2024-11-19 22:27:53", "link": "http://arxiv.org/abs/2411.12901v1", "categories": ["cs.CL", "cs.CV", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ACING: Actor-Critic for Instruction Learning in Black-Box Large Language\n  Models", "abstract": "The effectiveness of Large Language Models (LLMs) in solving tasks vastly\ndepends on the quality of the instructions, which often require fine-tuning\nthrough extensive human effort. This highlights the need for automated\ninstruction optimization; however, this optimization is particularly\nchallenging when dealing with black-box LLMs, where model parameters and\ngradients remain inaccessible. We propose ACING, a task-specific prompt\noptimization approach framed as a stateless continuous-action Reinforcement\nLearning (RL) problem, known as the continuum bandit setting. ACING leverages\nan actor-critic-based method to optimize prompts, learning from\nnon-differentiable reward signals. We validate ACING by optimizing prompts for\nChatGPT on 30 instruction-based tasks. ACING consistently outperforms baseline\nmethods, achieving a median score improvement of 10 percentage points.\nFurthermore, ACING not only recovers but also surpasses human-crafted expert\ninstructions, achieving up to a 39 percentage point improvement against human\nbenchmarks.", "published": "2024-11-19 18:58:03", "link": "http://arxiv.org/abs/2411.12736v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.CL"}
{"title": "Class-Incremental Learning for Sound Event Localization and Detection", "abstract": "This paper investigates the feasibility of class-incremental learning (CIL)\nfor Sound Event Localization and Detection (SELD) tasks. The method features an\nincremental learner that can learn new sound classes independently while\npreserving knowledge of old classes. The continual learning is achieved through\na mean square error-based distillation loss to minimize output discrepancies\nbetween subsequent learners. The experiments are conducted on the TAU-NIGENS\nSpatial Sound Events 2021 dataset, which includes 12 different sound classes\nand demonstrate the efficacy of proposed method. We begin by learning 8 classes\nand introduce the 4 new classes at next stage. After the incremental phase, the\nsystem is evaluated on the full set of learned classes. Results show that, for\nthis realistic dataset, our proposed method successfully maintains baseline\nperformance across all metrics.", "published": "2024-11-19 19:34:44", "link": "http://arxiv.org/abs/2411.12830v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Zero-Shot Crate Digging: DJ Tool Retrieval Using Speech Activity, Music\n  Structure And CLAP Embeddings", "abstract": "In genres like Hip-Hop, RnB, Reggae, Dancehall and just about every\nElectronic/Dance/Club style, DJ tools are a special set of audio files curated\nto heighten the DJ's musical performance and creative mixing choices. In this\nwork we demonstrate an approach to discovering DJ tools in personal music\ncollections. Leveraging open-source libraries for speech/music activity, music\nboundary analysis and a Contrastive Language-Audio Pretraining (CLAP) model for\nzero-shot audio classification, we demonstrate a novel system designed to\nretrieve (or rediscover) compelling DJ tools for use live or in the studio.", "published": "2024-11-19 03:57:00", "link": "http://arxiv.org/abs/2411.12209v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Neural Denoising Vocoder for Clean Waveform Generation from Noisy\n  Mel-Spectrogram based on Amplitude and Phase Predictions", "abstract": "This paper proposes a novel neural denoising vocoder that can generate clean\nspeech waveforms from noisy mel-spectrograms. The proposed neural denoising\nvocoder consists of two components, i.e., a spectrum predictor and a\nenhancement module. The spectrum predictor first predicts the noisy amplitude\nand phase spectra from the input noisy mel-spectrogram, and subsequently the\nenhancement module recovers the clean amplitude and phase spectrum from noisy\nones. Finally, clean speech waveforms are reconstructed through inverse\nshort-time Fourier transform (iSTFT). All operations are performed at the\nframe-level spectral domain, with the APNet vocoder and MP-SENet speech\nenhancement model used as the backbones for the two components, respectively.\nExperimental results demonstrate that our proposed neural denoising vocoder\nachieves state-of-the-art performance compared to existing neural vocoders on\nthe VoiceBank+DEMAND dataset. Additionally, despite the lack of phase\ninformation and partial amplitude information in the input mel-spectrogram, the\nproposed neural denoising vocoder still achieves comparable performance with\nthe serveral advanced speech enhancement methods.", "published": "2024-11-19 06:40:01", "link": "http://arxiv.org/abs/2411.12268v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DGSNA: prompt-based Dynamic Generative Scene-based Noise Addition method", "abstract": "To ensure the reliable operation of speech systems across diverse\nenvironments, noise addition methods have emerged as the prevailing solution.\nHowever, existing methods offer limited coverage of real-world noisy scenes and\ndepend on pre-existing scene-based information and noise. This paper presents\nprompt-based Dynamic Generative Scene-based Noise Addition (DGSNA), a novel\nnoise addition methodology that integrates Dynamic Generation of Scene-based\nInformation (DGSI) with Scene-based Noise Addition for Speech (SNAS). This\nintegration facilitates automated scene-based noise addition by transforming\nclean speech into various noise environments, thereby providing a more\ncomprehensive and realistic simulation of diverse noise conditions.\nExperimental results demonstrate that DGSNA significantly enhances the\nrobustness of speech recognition and keyword spotting models across various\nnoise conditions, achieving a relative improvement of up to 11.21%.\nFurthermore, DGSNA can be effectively integrated with other noise addition\nmethods to enhance performance. Our implementation and demonstrations are\navailable at https://dgsna.github.io.", "published": "2024-11-19 09:23:22", "link": "http://arxiv.org/abs/2411.12363v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Controllability and Editability for Pretrained Text-to-Music\n  Generation Models", "abstract": "The field of AI-assisted music creation has made significant strides, yet\nexisting systems often struggle to meet the demands of iterative and nuanced\nmusic production. These challenges include providing sufficient control over\nthe generated content and allowing for flexible, precise edits. This thesis\ntackles these issues by introducing a series of advancements that progressively\nbuild upon each other, enhancing the controllability and editability of\ntext-to-music generation models.\n  First, we introduce Loop Copilot, a system that tries to address the need for\niterative refinement in music creation. Loop Copilot leverages a large language\nmodel (LLM) to coordinate multiple specialised AI models, enabling users to\ngenerate and refine music interactively through a conversational interface.\nCentral to this system is the Global Attribute Table, which records and\nmaintains key musical attributes throughout the iterative process, ensuring\nthat modifications at any stage preserve the overall coherence of the music.\nWhile Loop Copilot excels in orchestrating the music creation process, it does\nnot directly address the need for detailed edits to the generated content.\n  To overcome this limitation, MusicMagus is presented as a further solution\nfor editing AI-generated music. MusicMagus introduces a zero-shot text-to-music\nediting approach that allows for the modification of specific musical\nattributes, such as genre, mood, and instrumentation, without the need for\nretraining. By manipulating the latent space within pre-trained diffusion\nmodels, MusicMagus ensures that these edits are stylistically coherent and that\nnon-targeted attributes remain unchanged. This system is particularly effective\nin maintaining the structural integrity of the music during edits, but it\nencounters challenges with more complex and real-world audio scenarios.\n  ...", "published": "2024-11-19 16:52:34", "link": "http://arxiv.org/abs/2411.12641v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Context-Based Numerical Format Prediction for a Text-To-Speech System", "abstract": "Many of the existing TTS systems cannot accurately synthesize text containing\na variety of numerical formats, resulting in reduced intelligibility of the\nsynthesized speech. This research aims to develop a numerical format classifier\nthat can classify six types of numeric contexts. Experiments were carried out\nusing the proposed context-based feature extraction technique, which is focused\non extracting keywords, punctuation marks, and symbols as the features of the\nnumbers. Support Vector Machine, K-Nearest Neighbors Linear Discriminant\nAnalysis, and Decision Tree were used as classifiers. We have used the 10-fold\ncross-validation technique to determine the classification accuracy in terms of\nrecall and precision. It can be found that the proposed solution is better than\nthe existing feature extraction technique with improvement to the\nclassification accuracy by 30% to 37%. The use of the number format\nclassification can increase the intelligibility of the TTS systems.", "published": "2024-11-19 05:06:43", "link": "http://arxiv.org/abs/2412.00028v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
