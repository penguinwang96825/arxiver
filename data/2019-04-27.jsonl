{"title": "Experiments in Cuneiform Language Identification", "abstract": "This paper presents methods to discriminate between languages and dialects\nwritten in Cuneiform script, one of the first writing systems in the world. We\nreport the results obtained by the PZ team in the Cuneiform Language\nIdentification (CLI) shared task organized within the scope of the VarDial\nEvaluation Campaign 2019. The task included two languages, Sumerian and\nAkkadian. The latter is divided into six dialects: Old Babylonian, Middle\nBabylonian peripheral, Standard Babylonian, Neo Babylonian, Late Babylonian,\nand Neo Assyrian. We approach the task using a meta-classifier trained on\nvarious SVM models and we show the effectiveness of the system for this task.\nOur submission achieved 0.738 F1 score in discriminating between the seven\nlanguages and dialects and it was ranked fourth in the competition among eight\nteams.", "published": "2019-04-27 01:51:55", "link": "http://arxiv.org/abs/1904.12087v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Several Experiments on Investigating Pretraining and Knowledge-Enhanced\n  Models for Natural Language Inference", "abstract": "Natural language inference (NLI) is among the most challenging tasks in\nnatural language understanding. Recent work on unsupervised pretraining that\nleverages unsupervised signals such as language-model and sentence prediction\nobjectives has shown to be very effective on a wide range of NLP problems. It\nwould still be desirable to further understand how it helps NLI; e.g., if it\nlearns artifacts in data annotation or instead learn true inference knowledge.\nIn addition, external knowledge that does not exist in the limited amount of\nNLI training data may be added to NLI models in two typical ways, e.g., from\nhuman-created resources or an unsupervised pretraining paradigm. We runs\nseveral experiments here to investigate whether they help NLI in the same way,\nand if not,how?", "published": "2019-04-27 04:24:07", "link": "http://arxiv.org/abs/1904.12104v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in\n  Monotonicity Reasoning", "abstract": "Large crowdsourced datasets are widely used for training and evaluating\nneural models on natural language inference (NLI). Despite these efforts,\nneural models have a hard time capturing logical inferences, including those\nlicensed by phrase replacements, so-called monotonicity reasoning. Since no\nlarge dataset has been developed for monotonicity reasoning, it is still\nunclear whether the main obstacle is the size of datasets or the model\narchitectures themselves. To investigate this issue, we introduce a new\ndataset, called HELP, for handling entailments with lexical and logical\nphenomena. We add it to training data for the state-of-the-art neural models\nand evaluate them on test sets for monotonicity phenomena. The results showed\nthat our data augmentation improved the overall accuracy. We also find that the\nimprovement is better on monotonicity inferences with lexical replacements than\non downward inferences with disjunction and modification. This suggests that\nsome types of inferences can be improved by our data augmentation while others\nare immune to it.", "published": "2019-04-27 15:15:14", "link": "http://arxiv.org/abs/1904.12166v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Recognizing Phrase Translation Processes: Experiments on\n  English-French", "abstract": "When translating phrases (words or group of words), human translators,\nconsciously or not, resort to different translation processes apart from the\nliteral translation, such as Idiom Equivalence, Generalization,\nParticularization, Semantic Modulation, etc. Translators and linguists (such as\nVinay and Darbelnet, Newmark, etc.) have proposed several typologies to\ncharacterize the different translation processes. However, to the best of our\nknowledge, there has not been effort to automatically classify these\nfine-grained translation processes. Recently, an English-French parallel corpus\nof TED Talks has been manually annotated with translation process categories,\nalong with established annotation guidelines. Based on these annotated\nexamples, we propose an automatic classification of translation processes at\nsubsentential level. Experimental results show that we can distinguish\nnon-literal translation from literal translation with an accuracy of 87.09%,\nand 55.20% for classifying among five non-literal translation processes. This\nwork demonstrates that it is possible to automatically classify translation\nprocesses. Even with a small amount of annotated examples, our experiments show\nthe directions that we can follow in future work. One of our long term\nobjectives is leveraging this automatic classification to better control\nparaphrase extraction from bilingual parallel corpora.", "published": "2019-04-27 21:14:21", "link": "http://arxiv.org/abs/1904.12213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Review-Driven Answer Generation for Product-Related Questions in\n  E-Commerce", "abstract": "The users often have many product-related questions before they make a\npurchase decision in E-commerce. However, it is often time-consuming to examine\neach user review to identify the desired information. In this paper, we propose\na novel review-driven framework for answer generation for product-related\nquestions in E-commerce, named RAGE. We develope RAGE on the basis of the\nmulti-layer convolutional architecture to facilitate speed-up of answer\ngeneration with the parallel computation. For each question, RAGE first\nextracts the relevant review snippets from the reviews of the corresponding\nproduct. Then, we devise a mechanism to identify the relevant information from\nthe noise-prone review snippets and incorporate this information to guide the\nanswer generation. The experiments on two real-world E-Commerce datasets show\nthat the proposed RAGE significantly outperforms the existing alternatives in\nproducing more accurate and informative answers in natural language. Moreover,\nRAGE takes much less time for both model training and answer generation than\nthe existing RNN based generation models.", "published": "2019-04-27 01:57:28", "link": "http://arxiv.org/abs/1905.01994v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Context Information to Enhance Simple Question Answering", "abstract": "With the rapid development of knowledge bases(KBs),question\nanswering(QA)based on KBs has become a hot research issue. In this paper,we\npropose two frameworks(i.e.,pipeline framework,an end-to-end framework)to focus\nanswering single-relation factoid question. In both of two frameworks,we study\nthe effect of context information on the quality of QA,such as the entity's\nnotable type,out-degree. In the end-to-end framework,we combine char-level\nencoding and self-attention mechanisms,using weight sharing and multi-task\nstrategies to enhance the accuracy of QA. Experimental results show that\ncontext information can get better results of simple QA whether it is the\npipeline framework or the end-to-end framework. In addition,we find that the\nend-to-end framework achieves results competitive with state-of-the-art\napproaches in terms of accuracy and take much shorter time than them.", "published": "2019-04-27 12:57:24", "link": "http://arxiv.org/abs/1905.01995v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Dataset Design Choices for Multi-hop Reasoning", "abstract": "Learning multi-hop reasoning has been a key challenge for reading\ncomprehension models, leading to the design of datasets that explicitly focus\non it. Ideally, a model should not be able to perform well on a multi-hop\nquestion answering task without doing multi-hop reasoning. In this paper, we\ninvestigate two recently proposed datasets, WikiHop and HotpotQA. First, we\nexplore sentence-factored models for these tasks; by design, these models\ncannot do multi-hop reasoning, but they are still able to solve a large number\nof examples in both datasets. Furthermore, we find spurious correlations in the\nunmasked version of WikiHop, which make it easy to achieve high performance\nconsidering only the questions and answers. Finally, we investigate one key\ndifference between these datasets, namely span-based vs. multiple-choice\nformulations of the QA task. Multiple-choice versions of both datasets can be\neasily gamed, and two models we examine only marginally exceed a baseline in\nthis setting. Overall, while these datasets are useful testbeds,\nhigh-performing models may not be learning as much multi-hop reasoning as\npreviously thought.", "published": "2019-04-27 04:36:57", "link": "http://arxiv.org/abs/1904.12106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sentiment Classification using N-gram IDF and Automated Machine Learning", "abstract": "We propose a sentiment classification method with a general machine learning\nframework. For feature representation, n-gram IDF is used to extract\nsoftware-engineering-related, dataset-specific, positive, neutral, and negative\nn-gram expressions. For classifiers, an automated machine learning tool is\nused. In the comparison using publicly available datasets, our method achieved\nthe highest F1 values in positive and negative sentences on all datasets.", "published": "2019-04-27 14:46:34", "link": "http://arxiv.org/abs/1904.12162v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Sound Event Detection with Sequentially Labelled Data Based on\n  Connectionist Temporal Classification and Unsupervised Clustering", "abstract": "Sound event detection (SED) methods typically rely on either strongly\nlabelled data or weakly labelled data. As an alternative, sequentially labelled\ndata (SLD) was proposed. In SLD, the events and the order of events in audio\nclips are known, without knowing the occurrence time of events. This paper\nproposes a connectionist temporal classification (CTC) based SED system that\nuses SLD instead of strongly labelled data, with a novel unsupervised\nclustering stage. Experiments on 41 classes of sound events show that the\nproposed two-stage method trained on SLD achieves performance comparable to the\nprevious state-of-the-art SED system trained on strongly labelled data, and is\nfar better than another state-of-the-art SED system trained on weakly labelled\ndata, which indicates the effectiveness of the proposed two-stage method\ntrained on SLD without any onset/offset time of sound events.", "published": "2019-04-27 03:54:24", "link": "http://arxiv.org/abs/1904.12102v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Analysis of Acoustic Events and Scenes Based on Multitask Learning", "abstract": "Acoustic event detection and scene classification are major research tasks in\nenvironmental sound analysis, and many methods based on neural networks have\nbeen proposed. Conventional methods have addressed these tasks separately;\nhowever, acoustic events and scenes are closely related to each other. For\nexample, in the acoustic scene `office', the acoustic events `mouse clicking'\nand `keyboard typing' are likely to occur. In this paper, we propose multitask\nlearning for joint analysis of acoustic events and scenes, which shares the\nparts of the networks holding information on acoustic events and scenes in\ncommon. By integrating the two networks, we expect that information on acoustic\nscenes will improve the performance of acoustic event detection. Experimental\nresults obtained using TUT Sound Events 2016/2017 and TUT Acoustic Scenes 2016\ndatasets indicate that the proposed method improves the performance of acoustic\nevent detection by 10.66 percentage points in terms of the F-score, compared\nwith a conventional method based on a convolutional recurrent neural network.", "published": "2019-04-27 11:22:18", "link": "http://arxiv.org/abs/1904.12146v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural source-filter waveform models for statistical parametric speech\n  synthesis", "abstract": "Neural waveform models such as WaveNet have demonstrated better performance\nthan conventional vocoders for statistical parametric speech synthesis. As an\nautoregressive (AR) model, WaveNet is limited by a slow sequential waveform\ngeneration process. Some new models that use the inverse-autoregressive flow\n(IAF) can generate a whole waveform in a one-shot manner. However, these\nIAF-based models require sequential transformation during training, which\nseverely slows down the training speed. Other models such as Parallel WaveNet\nand ClariNet bring together the benefits of AR and IAF-based models and train\nan IAF model by transferring the knowledge from a pre-trained AR teacher to an\nIAF student without any sequential transformation. However, both models require\nadditional training criteria, and their implementation is prohibitively\ncomplicated.\n  We propose a framework for neural source-filter (NSF) waveform modeling\nwithout AR nor IAF-based approaches. This framework requires only three\ncomponents for waveform generation: a source module that generates a sine-based\nsignal as excitation, a non-AR dilated-convolution-based filter module that\ntransforms the excitation into a waveform, and a conditional module that\npre-processes the acoustic features for the source and filer modules. This\nframework minimizes spectral-amplitude distances for model training, which can\nbe efficiently implemented by using short-time Fourier transform routines.\nUnder this framework, we designed three NSF models and compared them with\nWaveNet. It was demonstrated that the NSF models generated waveforms at least\n100 times faster than WaveNet, and the quality of the synthetic speech from the\nbest NSF model was better than or equally good as that from WaveNet.", "published": "2019-04-27 02:08:20", "link": "http://arxiv.org/abs/1904.12088v2", "categories": ["eess.AS", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Towards Automation of Creativity: A Machine Intelligence Approach", "abstract": "This paper demonstrates emergence of computational creativity in the field of\nmusic. Different aspects of creativity such as producer, process, product and\npress are studied and formulated. Different notions of computational creativity\nsuch as novelty, quality and typicality of compositions as products are studied\nand evaluated. We formulate an algorithmic perception on human creativity and\npropose a prototype that is capable of demonstrating human-level creativity. We\nthen validate the proposed prototype by applying various creativity benchmarks\nwith the results obtained and compare the proposed prototype with the other\nexisting computational creative systems.", "published": "2019-04-27 18:54:51", "link": "http://arxiv.org/abs/1904.12194v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
