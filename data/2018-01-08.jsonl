{"title": "Analyzing Roles of Classifiers and Code-Mixed factors for Sentiment\n  Identification", "abstract": "Multilingual speakers often switch between languages to express themselves on\nsocial communication platforms. Sometimes, the original script of the language\nis preserved, while using a common script for all the languages is quite\npopular as well due to convenience. On such occasions, multiple languages are\nbeing mixed with different rules of grammar, using the same script which makes\nit a challenging task for natural language processing even in case of accurate\nsentiment identification. In this paper, we report results of various\nexperiments carried out on movie reviews dataset having this code-mixing\nproperty of two languages, English and Bengali, both typed in Roman script. We\nhave tested various machine learning algorithms trained only on English\nfeatures on our code-mixed data and have achieved the maximum accuracy of\n59.00% using Naive Bayes (NB) model. We have also tested various models trained\non code-mixed data, as well as English features and the highest accuracy of\n72.50% was obtained by a Support Vector Machine (SVM) model. Finally, we have\nanalyzed the misclassified snippets and have discussed the challenges needed to\nbe resolved for better accuracy.", "published": "2018-01-08 17:43:12", "link": "http://arxiv.org/abs/1801.02581v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evorus: A Crowd-powered Conversational Assistant Built to Automate\n  Itself Over Time", "abstract": "Crowd-powered conversational assistants have been shown to be more robust\nthan automated systems, but do so at the cost of higher response latency and\nmonetary costs. A promising direction is to combine the two approaches for high\nquality, low latency, and low cost solutions. In this paper, we introduce\nEvorus, a crowd-powered conversational assistant built to automate itself over\ntime by (i) allowing new chatbots to be easily integrated to automate more\nscenarios, (ii) reusing prior crowd answers, and (iii) learning to\nautomatically approve response candidates. Our 5-month-long deployment with 80\nparticipants and 281 conversations shows that Evorus can automate itself\nwithout compromising conversation quality. Crowd-AI architectures have long\nbeen proposed as a way to reduce cost and latency for crowd-powered systems;\nEvorus demonstrates how automation can be introduced successfully in a deployed\nsystem. Its architecture allows future researchers to make further innovation\non the underlying automated components in the context of a deployed open domain\ndialog system.", "published": "2018-01-08 20:07:35", "link": "http://arxiv.org/abs/1801.02668v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.m"], "primary_category": "cs.HC"}
{"title": "DCASE 2017 Task 1: Acoustic Scene Classification Using Shift-Invariant\n  Kernels and Random Features", "abstract": "Acoustic scene recordings are represented by different types of handcrafted\nor Neural Network-derived features. These features, typically of thousands of\ndimensions, are classified in state of the art approaches using kernel\nmachines, such as the Support Vector Machines (SVM). However, the complexity of\ntraining these methods increases with the dimensionality of these input\nfeatures and the size of the dataset. A solution is to map the input features\nto a randomized lower-dimensional feature space. The resulting random features\ncan approximate non-linear kernels with faster linear kernel computation. In\nthis work, we computed a set of 6,553 input features and used them to compute\nrandom features to approximate three types of kernels, Gaussian, Laplacian and\nCauchy. We compared their performance using an SVM in the context of the DCASE\nTask 1 - Acoustic Scene Classification. Experiments show that both, input and\nrandom features outperformed the DCASE baseline by an absolute 4%. Moreover,\nthe random features reduced the dimensionality of the input by more than three\ntimes with minimal loss of performance and by more than six times and still\noutperformed the baseline. Hence, random features could be employed by state of\nthe art approaches to compute low-storage features and perform faster kernel\ncomputations.", "published": "2018-01-08 21:12:49", "link": "http://arxiv.org/abs/1801.02690v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attacking Speaker Recognition With Deep Generative Models", "abstract": "In this paper we investigate the ability of generative adversarial networks\n(GANs) to synthesize spoofing attacks on modern speaker recognition systems. We\nfirst show that samples generated with SampleRNN and WaveNet are unable to fool\na CNN-based speaker recognition system. We propose a modification of the\nWasserstein GAN objective function to make use of data that is real but not\nfrom the class being learned. Our semi-supervised learning method is able to\nperform both targeted and untargeted attacks, raising questions related to\nsecurity in speaker authentication systems.", "published": "2018-01-08 11:17:56", "link": "http://arxiv.org/abs/1801.02384v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
