{"title": "CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral\n  Therapy-based Mental Health Question Answering", "abstract": "The recent advancements in artificial intelligence highlight the potential of\nlanguage models in psychological health support. While models trained on data\nfrom mental health service platform have achieved preliminary success,\nchallenges persist in areas such as data scarcity, quality, and ensuring a\nsolid foundation in psychological techniques. To address these challenges, this\nstudy introduces a novel approach to enhance the precision and efficacy of\npsychological support through large language models. Specifically, we design a\nspecific prompt derived from principles of Cognitive Behavioral Therapy (CBT)\nand have generated the CBT QA dataset, specifically for Chinese psychological\nhealth Q&A based on CBT structured intervention strategies. Unlike previous\nmethods, our dataset emphasizes professional and structured response. Utilizing\nthis dataset, we fine-tuned the large language model, giving birth to CBT-LLM,\nthe large-scale language model specifically designed for Cognitive Behavioral\nTherapy techniques. Empirical evaluations demonstrate that CBT-LLM excels in\ngenerating structured, professional, and highly relevant responses in\npsychological health support tasks, showcasing its practicality and quality.\nThe model is available on Hugging Face:\nhttps://huggingface.co/Hongbin37/CBT-LLM.", "published": "2024-03-24 04:34:34", "link": "http://arxiv.org/abs/2403.16008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monotonic Paraphrasing Improves Generalization of Language Model\n  Prompting", "abstract": "Performance of large language models (LLMs) may vary with different prompts\nor instructions of even the same task. One commonly recognized factor for this\nphenomenon is the model's familiarity with the given prompt or instruction,\nwhich is typically estimated by its perplexity. However, finding the prompt\nwith the lowest perplexity is challenging, given the enormous space of possible\nprompting phrases. In this paper, we propose monotonic paraphrasing (MonoPara),\nan end-to-end decoding strategy that paraphrases given prompts or instructions\ninto their lower perplexity counterparts based on an ensemble of a paraphrase\nLM for prompt (or instruction) rewriting, and a target LM (i.e. the prompt or\ninstruction executor) that constrains the generation for lower perplexity. The\nensemble decoding process can efficiently paraphrase the original prompt\nwithout altering its semantic meaning, while monotonically decreasing the\nperplexity of each generation as calculated by the target LM. We explore in\ndetail both greedy and search-based decoding as two alternative decoding\nschemes of MonoPara. Notably, MonoPara does not require any training and can\nmonotonically lower the perplexity of the paraphrased prompt or instruction,\nleading to improved performance of zero-shot LM prompting as evaluated on a\nwide selection of tasks. In addition, MonoPara is also shown to effectively\nimprove LMs' generalization on perturbed and unseen task instructions.", "published": "2024-03-24 06:49:07", "link": "http://arxiv.org/abs/2403.16038v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Argument Quality Assessment in the Age of Instruction-Following Large\n  Language Models", "abstract": "The computational treatment of arguments on controversial issues has been\nsubject to extensive NLP research, due to its envisioned impact on opinion\nformation, decision making, writing education, and the like. A critical task in\nany such application is the assessment of an argument's quality - but it is\nalso particularly challenging. In this position paper, we start from a brief\nsurvey of argument quality research, where we identify the diversity of quality\nnotions and the subjectiveness of their perception as the main hurdles towards\nsubstantial progress on argument quality assessment. We argue that the\ncapabilities of instruction-following large language models (LLMs) to leverage\nknowledge across contexts enable a much more reliable assessment. Rather than\njust fine-tuning LLMs towards leaderboard chasing on assessment tasks, they\nneed to be instructed systematically with argumentation theories and scenarios\nas well as with ways to solve argument-related problems. We discuss the\nreal-world opportunities and ethical issues emerging thereby.", "published": "2024-03-24 10:43:21", "link": "http://arxiv.org/abs/2403.16084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Lexical Ambiguity Detection and Word Sense Disambiguation", "abstract": "This paper explores techniques that focus on understanding and resolving\nambiguity in language within the field of natural language processing (NLP),\nhighlighting the complexity of linguistic phenomena such as polysemy and\nhomonymy and their implications for computational models. Focusing extensively\non Word Sense Disambiguation (WSD), it outlines diverse approaches ranging from\ndeep learning techniques to leveraging lexical resources and knowledge graphs\nlike WordNet. The paper introduces cutting-edge methodologies like word sense\nextension (WSE) and neuromyotonic approaches, enhancing disambiguation accuracy\nby predicting new word senses. It examines specific applications in biomedical\ndisambiguation and language specific optimisation and discusses the\nsignificance of cognitive metaphors in discourse analysis. The research\nidentifies persistent challenges in the field, such as the scarcity of sense\nannotated corpora and the complexity of informal clinical texts. It concludes\nby suggesting future directions, including using large language models, visual\nWSD, and multilingual WSD systems, emphasising the ongoing evolution in\naddressing lexical complexities in NLP. This thinking perspective highlights\nthe advancement in this field to enable computers to understand language more\naccurately.", "published": "2024-03-24 12:58:48", "link": "http://arxiv.org/abs/2403.16129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Little Leak Will Sink a Great Ship: Survey of Transparency for Large\n  Language Models from Start to Finish", "abstract": "Large Language Models (LLMs) are trained on massive web-crawled corpora. This\nposes risks of leakage, including personal information, copyrighted texts, and\nbenchmark datasets. Such leakage leads to undermining human trust in AI due to\npotential unauthorized generation of content or overestimation of performance.\nWe establish the following three criteria concerning the leakage issues: (1)\nleakage rate: the proportion of leaked data in training data, (2) output rate:\nthe ease of generating leaked data, and (3) detection rate: the detection\nperformance of leaked versus non-leaked data. Despite the leakage rate being\nthe origin of data leakage issues, it is not understood how it affects the\noutput rate and detection rate. In this paper, we conduct an experimental\nsurvey to elucidate the relationship between the leakage rate and both the\noutput rate and detection rate for personal information, copyrighted texts, and\nbenchmark data. Additionally, we propose a self-detection approach that uses\nfew-shot learning in which LLMs detect whether instances are present or absent\nin their training data, in contrast to previous methods that do not employ\nexplicit learning. To explore the ease of generating leaked information, we\ncreate a dataset of prompts designed to elicit personal information,\ncopyrighted text, and benchmarks from LLMs. Our experiments reveal that LLMs\nproduce leaked information in most cases despite less such data in their\ntraining set. This indicates even small amounts of leaked data can greatly\naffect outputs. Our self-detection method showed superior performance compared\nto existing detection methods.", "published": "2024-03-24 13:21:58", "link": "http://arxiv.org/abs/2403.16139v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Korean Bio-Medical Corpus (KBMC) for Medical Named Entity Recognition", "abstract": "Named Entity Recognition (NER) plays a pivotal role in medical Natural\nLanguage Processing (NLP). Yet, there has not been an open-source medical NER\ndataset specifically for the Korean language. To address this, we utilized\nChatGPT to assist in constructing the KBMC (Korean Bio-Medical Corpus), which\nwe are now presenting to the public. With the KBMC dataset, we noticed an\nimpressive 20% increase in medical NER performance compared to models trained\non general Korean NER datasets. This research underscores the significant\nbenefits and importance of using specialized tools and datasets, like ChatGPT,\nto enhance language processing in specialized fields such as healthcare.", "published": "2024-03-24 13:51:05", "link": "http://arxiv.org/abs/2403.16158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language\n  Models", "abstract": "Parameter-efficient fine-tuning (PEFT) is widely studied for its\neffectiveness and efficiency in the era of large language models. Low-rank\nadaptation (LoRA) has demonstrated commendable performance as a popular and\nrepresentative method. However, it is implemented with a fixed intrinsic rank\nthat might not be the ideal setting for the downstream tasks. Recognizing the\nneed for more flexible downstream task adaptation, we extend the methodology of\nLoRA to an innovative approach we call allocating low-rank adaptation (ALoRA)\nthat enables dynamic adjustments to the intrinsic rank during the adaptation\nprocess. First, we propose a novel method, AB-LoRA, that can effectively\nestimate the importance score of each LoRA rank. Second, guided by AB-LoRA, we\ngradually prune abundant and negatively impacting LoRA ranks and allocate the\npruned LoRA budgets to important Transformer modules needing higher ranks. We\nhave conducted experiments on various tasks, and the experimental results\ndemonstrate that our ALoRA method can outperform the recent baselines with\ncomparable tunable parameters.", "published": "2024-03-24 15:09:55", "link": "http://arxiv.org/abs/2403.16187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Offer an Alternative to the Traditional Approach\n  of Topic Modelling", "abstract": "Topic modelling, as a well-established unsupervised technique, has found\nextensive use in automatically detecting significant topics within a corpus of\ndocuments. However, classic topic modelling approaches (e.g., LDA) have certain\ndrawbacks, such as the lack of semantic understanding and the presence of\noverlapping topics. In this work, we investigate the untapped potential of\nlarge language models (LLMs) as an alternative for uncovering the underlying\ntopics within extensive text corpora. To this end, we introduce a framework\nthat prompts LLMs to generate topics from a given set of documents and\nestablish evaluation protocols to assess the clustering efficacy of LLMs. Our\nfindings indicate that LLMs with appropriate prompts can stand out as a viable\nalternative, capable of generating relevant topic titles and adhering to human\nguidelines to refine and merge topics. Through in-depth experiments and\nevaluation, we summarise the advantages and constraints of employing LLMs in\ntopic extraction.", "published": "2024-03-24 17:39:51", "link": "http://arxiv.org/abs/2403.16248v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved\n  Phrase Graphs", "abstract": "We study the patent phrase similarity inference task, which measures the\nsemantic similarity between two patent phrases. As patent documents employ\nlegal and highly technical language, existing semantic textual similarity\nmethods that use localized contextual information do not perform satisfactorily\nin inferring patent phrase similarity. To address this, we introduce a\ngraph-augmented approach to amplify the global contextual information of the\npatent phrases. For each patent phrase, we construct a phrase graph that links\nto its focal patents and a list of patents that are either cited by or cite\nthese focal patents. The augmented phrase embedding is then derived from\ncombining its localized contextual embedding with its global embedding within\nthe phrase graph. We further propose a self-supervised learning objective that\ncapitalizes on the retrieved topology to refine both the contextualized\nembedding and the graph parameters in an end-to-end manner. Experimental\nresults from a unique patent phrase similarity dataset demonstrate that our\napproach significantly enhances the representation of patent phrases, resulting\nin marked improvements in similarity inference in a self-supervised fashion.\nSubstantial improvements are also observed in the supervised setting,\nunderscoring the potential benefits of leveraging retrieved phrase graph\naugmentation.", "published": "2024-03-24 18:59:38", "link": "http://arxiv.org/abs/2403.16265v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LexDrafter: Terminology Drafting for Legislative Documents using\n  Retrieval Augmented Generation", "abstract": "With the increase in legislative documents at the EU, the number of new terms\nand their definitions is increasing as well. As per the Joint Practical Guide\nof the European Parliament, the Council and the Commission, terms used in legal\ndocuments shall be consistent, and identical concepts shall be expressed\nwithout departing from their meaning in ordinary, legal, or technical language.\nThus, while drafting a new legislative document, having a framework that\nprovides insights about existing definitions and helps define new terms based\non a document's context will support such harmonized legal definitions across\ndifferent regulations and thus avoid ambiguities. In this paper, we present\nLexDrafter, a framework that assists in drafting Definitions articles for\nlegislative documents using retrieval augmented generation (RAG) and existing\nterm definitions present in different legislative documents. For this,\ndefinition elements are built by extracting definitions from existing\ndocuments. Using definition elements and RAG, a Definitions article can be\nsuggested on demand for a legislative document that is being drafted. We\ndemonstrate and evaluate the functionality of LexDrafter using a collection of\nEU documents from the energy domain. The code for LexDrafter framework is\navailable at https://github.com/achouhan93/LexDrafter.", "published": "2024-03-24 21:02:35", "link": "http://arxiv.org/abs/2403.16295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval", "abstract": "The burgeoning integration of 3D medical imaging into healthcare has led to a\nsubstantial increase in the workload of medical professionals. To assist\nclinicians in their diagnostic processes and alleviate their workload, the\ndevelopment of a robust system for retrieving similar case studies presents a\nviable solution. While the concept holds great promise, the field of 3D medical\ntext-image retrieval is currently limited by the absence of robust evaluation\nbenchmarks and curated datasets. To remedy this, our study presents a\ngroundbreaking dataset, {BIMCV-R}, which includes an extensive collection of\n8,069 3D CT volumes, encompassing over 2 million slices, paired with their\nrespective radiological reports. Expanding upon the foundational work of our\ndataset, we craft a retrieval strategy, MedFinder. This approach employs a\ndual-stream network architecture, harnessing the potential of large language\nmodels to advance the field of medical image retrieval beyond existing\ntext-image retrieval solutions. It marks our preliminary step towards\ndeveloping a system capable of facilitating text-to-image, image-to-text, and\nkeyword-based retrieval tasks. Our project is available at\n\\url{https://huggingface.co/datasets/cyd0806/BIMCV-R}.", "published": "2024-03-24 03:10:07", "link": "http://arxiv.org/abs/2403.15992v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Qibo: A Large Language Model for Traditional Chinese Medicine", "abstract": "Large Language Models (LLMs) has made significant progress in a number of\nprofessional fields, including medicine, law, and finance. However, in\ntraditional Chinese medicine (TCM), there are challenges such as the essential\ndifferences between theory and modern medicine, the lack of specialized corpus\nresources, and the fact that relying only on supervised fine-tuning may lead to\noverconfident predictions. To address these challenges, we propose a two-stage\ntraining approach that combines continuous pre-training and supervised\nfine-tuning. A notable contribution of our study is the processing of a 2GB\ncorpus dedicated to TCM, constructing pre-training and instruction fine-tuning\ndatasets for TCM, respectively. In addition, we have developed Qibo-Benchmark,\na tool that evaluates the performance of LLM in the TCM on multiple dimensions,\nincluding subjective, objective, and three TCM NLP tasks. The medical LLM\ntrained with our pipeline, named $\\textbf{Qibo}$, exhibits significant\nperformance boosts. Compared to the baselines, the average subjective win rate\nis 63%, the average objective accuracy improved by 23% to 58%, and the Rouge-L\nscores for the three TCM NLP tasks are 0.72, 0.61, and 0.55. Finally, we\npropose a pipline to apply Qibo to TCM consultation and demonstrate the model\nperformance through the case study.", "published": "2024-03-24 07:48:05", "link": "http://arxiv.org/abs/2403.16056v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-Label Dataset of French Fake News: Human and Machine Insights", "abstract": "We present a corpus of 100 documents, OBSINFOX, selected from 17 sources of\nFrench press considered unreliable by expert agencies, annotated using 11\nlabels by 8 annotators. By collecting more labels than usual, by more\nannotators than is typically done, we can identify features that humans\nconsider as characteristic of fake news, and compare them to the predictions of\nautomated classifiers. We present a topic and genre analysis using Gate Cloud,\nindicative of the prevalence of satire-like text in the corpus. We then use the\nsubjectivity analyzer VAGO, and a neural version of it, to clarify the link\nbetween ascriptions of the label Subjective and ascriptions of the label Fake\nNews. The annotated dataset is available online at the following url:\nhttps://github.com/obs-info/obsinfox\n  Keywords: Fake News, Multi-Labels, Subjectivity, Vagueness, Detail, Opinion,\nExaggeration, French Press", "published": "2024-03-24 11:29:55", "link": "http://arxiv.org/abs/2403.16099v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WangchanLion and WangchanX MRC Eval", "abstract": "This technical report describes the development of WangchanLion, an\ninstruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in\nthe Thai language. Our model is based on SEA-LION and a collection of\ninstruction following datasets. To promote open research and reproducibility,\nwe publicly release all training data, code, and the final model weights under\nthe Apache-2 license. To assess the contextual understanding capability, we\nconducted extensive experimental studies using two Thai MRC datasets, XQuAD and\nIapp_wiki_qa_squad. Experimental results demonstrate the model's ability to\ncomprehend the context and produce an answer faithful to the reference one in\n0-shot and 1-shot settings. In addition, our evaluation goes beyond the\ntraditional MRC. We propose a new evaluation scheme assessing the answer's\ncorrectness, helpfulness, conciseness, and contextuality. Our code is available\npublicly at https://github.com/vistec-AI/WangchanLion.", "published": "2024-03-24 12:49:30", "link": "http://arxiv.org/abs/2403.16127v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Happens to a Dataset Transformed by a Projection-based Concept\n  Removal Method?", "abstract": "We investigate the behavior of methods that use linear projections to remove\ninformation about a concept from a language representation, and we consider the\nquestion of what happens to a dataset transformed by such a method. A\ntheoretical analysis and experiments on real-world and synthetic data show that\nthese methods inject strong statistical dependencies into the transformed\ndatasets. After applying such a method, the representation space is highly\nstructured: in the transformed space, an instance tends to be located near\ninstances of the opposite label. As a consequence, the original labeling can in\nsome cases be reconstructed by applying an anti-clustering method.", "published": "2024-03-24 13:28:27", "link": "http://arxiv.org/abs/2403.16142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ESREAL: Exploiting Semantic Reconstruction to Mitigate Hallucinations in\n  Vision-Language Models", "abstract": "Hallucinations in vision-language models pose a significant challenge to\ntheir reliability, particularly in the generation of long captions. Current\nmethods fall short of accurately identifying and mitigating these\nhallucinations. To address this issue, we introduce ESREAL, a novel\nunsupervised learning framework designed to suppress the generation of\nhallucinations through accurate localization and penalization of hallucinated\ntokens. Initially, ESREAL creates a reconstructed image based on the generated\ncaption and aligns its corresponding regions with those of the original image.\nThis semantic reconstruction aids in identifying both the presence and type of\ntoken-level hallucinations within the generated caption. Subsequently, ESREAL\ncomputes token-level hallucination scores by assessing the semantic similarity\nof aligned regions based on the type of hallucination. Finally, ESREAL employs\na proximal policy optimization algorithm, where it selectively penalizes\nhallucinated tokens according to their token-level hallucination scores. Our\nframework notably reduces hallucinations in LLaVA, InstructBLIP, and mPLUG-Owl2\nby 32.81%, 27.08%, and 7.46% on the CHAIR metric. This improvement is achieved\nsolely through signals derived from the image itself, without the need for any\nimage-text pairs.", "published": "2024-03-24 14:21:06", "link": "http://arxiv.org/abs/2403.16167v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Node Classification via Semantic-Structural Attention-Enhanced Graph\n  Convolutional Networks", "abstract": "Graph data, also known as complex network data, is omnipresent across various\ndomains and applications. Prior graph neural network models primarily focused\non extracting task-specific structural features through supervised learning\nobjectives, but they fell short in capturing the inherent semantic and\nstructural features of the entire graph. In this paper, we introduce the\nsemantic-structural attention-enhanced graph convolutional network (SSA-GCN),\nwhich not only models the graph structure but also extracts generalized\nunsupervised features to enhance vertex classification performance. The\nSSA-GCN's key contributions lie in three aspects: firstly, it derives semantic\ninformation through unsupervised feature extraction from a knowledge graph\nperspective; secondly, it obtains structural information through unsupervised\nfeature extraction from a complex network perspective; and finally, it\nintegrates these features through a cross-attention mechanism. By leveraging\nthese features, we augment the graph convolutional network, thereby enhancing\nthe model's generalization capabilities. Our experiments on the Cora and\nCiteSeer datasets demonstrate the performance improvements achieved by our\nproposed method. Furthermore, our approach also exhibits excellent accuracy\nunder privacy settings, making it a robust and effective solution for graph\ndata analysis.", "published": "2024-03-24 06:28:54", "link": "http://arxiv.org/abs/2403.16033v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "LLMs as Compiler for Arabic Programming Language", "abstract": "In this paper we introduce APL (Arabic Programming Language) that uses Large\nlanguage models (LLM) as semi-compiler to covert Arabic text code to python\ncode then run the code. Designing a full pipeline from the structure of the APL\ntext then a prompt (using prompt engineering) then running the prodcued python\ncode using PyRunner. This project has a three parts first python library, a\nplayground with simple interface and this research paper.", "published": "2024-03-24 10:57:08", "link": "http://arxiv.org/abs/2403.16087v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Subspace Defense: Discarding Adversarial Perturbations by Learning a\n  Subspace for Clean Signals", "abstract": "Deep neural networks (DNNs) are notoriously vulnerable to adversarial attacks\nthat place carefully crafted perturbations on normal examples to fool DNNs. To\nbetter understand such attacks, a characterization of the features carried by\nadversarial examples is needed. In this paper, we tackle this challenge by\ninspecting the subspaces of sample features through spectral analysis. We first\nempirically show that the features of either clean signals or adversarial\nperturbations are redundant and span in low-dimensional linear subspaces\nrespectively with minimal overlap, and the classical low-dimensional subspace\nprojection can suppress perturbation features out of the subspace of clean\nsignals. This makes it possible for DNNs to learn a subspace where only\nfeatures of clean signals exist while those of perturbations are discarded,\nwhich can facilitate the distinction of adversarial examples. To prevent the\nresidual perturbations that is inevitable in subspace learning, we propose an\nindependence criterion to disentangle clean signals from perturbations.\nExperimental results show that the proposed strategy enables the model to\ninherently suppress adversaries, which not only boosts model robustness but\nalso motivates new directions of effective adversarial defense.", "published": "2024-03-24 14:35:44", "link": "http://arxiv.org/abs/2403.16176v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "SQL-Encoder: Improving NL2SQL In-Context Learning Through a\n  Context-Aware Encoder", "abstract": "Detecting structural similarity between queries is essential for selecting\nexamples in in-context learning models. However, assessing structural\nsimilarity based solely on the natural language expressions of queries, without\nconsidering SQL queries, presents a significant challenge. This paper explores\nthe significance of this similarity metric and proposes a model for accurately\nestimating it. To achieve this, we leverage a dataset comprising 170k question\npairs, meticulously curated to train a similarity prediction model. Our\ncomprehensive evaluation demonstrates that the proposed model adeptly captures\nthe structural similarity between questions, as evidenced by improvements in\nKendall-Tau distance and precision@k metrics. Notably, our model outperforms\nstrong competitive embedding models from OpenAI and Cohere. Furthermore,\ncompared to these competitive models, our proposed encoder enhances the\ndownstream performance of NL2SQL models in 1-shot in-context learning scenarios\nby 1-2\\% for GPT-3.5-turbo, 4-8\\% for CodeLlama-7B, and 2-3\\% for\nCodeLlama-13B.", "published": "2024-03-24 15:57:24", "link": "http://arxiv.org/abs/2403.16204v1", "categories": ["cs.CL", "cs.DB", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Improving Sequence-to-Sequence Models for Abstractive Text Summarization\n  Using Meta Heuristic Approaches", "abstract": "As human society transitions into the information age, reduction in our\nattention span is a contingency, and people who spend time reading lengthy news\narticles are decreasing rapidly and the need for succinct information is higher\nthan ever before. Therefore, it is essential to provide a quick overview of\nimportant news by concisely summarizing the top news article and the most\nintuitive headline. When humans try to make summaries, they extract the\nessential information from the source and add useful phrases and grammatical\nannotations from the original extract. Humans have a unique ability to create\nabstractions. However, automatic summarization is a complicated problem to\nsolve. The use of sequence-to-sequence (seq2seq) models for neural abstractive\ntext summarization has been ascending as far as prevalence. Numerous innovative\nstrategies have been proposed to develop the current seq2seq models further,\npermitting them to handle different issues like saliency, familiarity, and\nhuman lucidness and create excellent synopses. In this article, we aimed toward\nenhancing the present architectures and models for abstractive text\nsummarization. The modifications have been aimed at fine-tuning\nhyper-parameters, attempting specific encoder-decoder combinations. We examined\nmany experiments on an extensively used CNN/DailyMail dataset to check the\neffectiveness of various models.", "published": "2024-03-24 17:39:36", "link": "http://arxiv.org/abs/2403.16247v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Large Language Models in Biomedical and Health Informatics: A Review\n  with Bibliometric Analysis", "abstract": "Large Language Models (LLMs) have rapidly become important tools in\nBiomedical and Health Informatics (BHI), enabling new ways to analyze data,\ntreat patients, and conduct research. This study aims to provide a\ncomprehensive overview of LLM applications in BHI, highlighting their\ntransformative potential and addressing the associated ethical and practical\nchallenges. We reviewed 1,698 research articles from January 2022 to December\n2023, categorizing them by research themes and diagnostic categories.\nAdditionally, we conducted network analysis to map scholarly collaborations and\nresearch dynamics. Our findings reveal a substantial increase in the potential\napplications of LLMs to a variety of BHI tasks, including clinical decision\nsupport, patient interaction, and medical document analysis. Notably, LLMs are\nexpected to be instrumental in enhancing the accuracy of diagnostic tools and\npatient care protocols. The network analysis highlights dense and dynamically\nevolving collaborations across institutions, underscoring the interdisciplinary\nnature of LLM research in BHI. A significant trend was the application of LLMs\nin managing specific disease categories such as mental health and neurological\ndisorders, demonstrating their potential to influence personalized medicine and\npublic health strategies. LLMs hold promising potential to further transform\nbiomedical research and healthcare delivery. While promising, the ethical\nimplications and challenges of model validation call for rigorous scrutiny to\noptimize their benefits in clinical settings. This survey serves as a resource\nfor stakeholders in healthcare, including researchers, clinicians, and\npolicymakers, to understand the current state and future potential of LLMs in\nBHI.", "published": "2024-03-24 21:29:39", "link": "http://arxiv.org/abs/2403.16303v4", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.DL"}
{"title": "An efficient domain-independent approach for supervised keyphrase\n  extraction and ranking", "abstract": "We present a supervised learning approach for automatic extraction of\nkeyphrases from single documents. Our solution uses simple to compute\nstatistical and positional features of candidate phrases and does not rely on\nany external knowledge base or on pre-trained language models or word\nembeddings. The ranking component of our proposed solution is a fairly\nlightweight ensemble model. Evaluation on benchmark datasets shows that our\napproach achieves significantly higher accuracy than several state-of-the-art\nbaseline models, including all deep learning-based unsupervised models compared\nwith, and is competitive with some supervised deep learning-based models too.\nDespite the supervised nature of our solution, the fact that does not rely on\nany corpus of \"golden\" keywords or any external knowledge corpus means that our\nsolution bears the advantages of unsupervised solutions to a fair extent.", "published": "2024-03-24 08:33:27", "link": "http://arxiv.org/abs/2404.07954v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "H.3.1; I.2.7"], "primary_category": "cs.IR"}
{"title": "Transformer-based Joint Modelling for Automatic Essay Scoring and\n  Off-Topic Detection", "abstract": "Automated Essay Scoring (AES) systems are widely popular in the market as\nthey constitute a cost-effective and time-effective option for grading systems.\nNevertheless, many studies have demonstrated that the AES system fails to\nassign lower grades to irrelevant responses. Thus, detecting the off-topic\nresponse in automated essay scoring is crucial in practical tasks where\ncandidates write unrelated text responses to the given task in the question. In\nthis paper, we are proposing an unsupervised technique that jointly scores\nessays and detects off-topic essays. The proposed Automated Open Essay Scoring\n(AOES) model uses a novel topic regularization module (TRM), which can be\nattached on top of a transformer model, and is trained using a proposed hybrid\nloss function. After training, the AOES model is further used to calculate the\nMahalanobis distance score for off-topic essay detection. Our proposed method\noutperforms the baseline we created and earlier conventional methods on two\nessay-scoring datasets in off-topic detection as well as on-topic scoring.\nExperimental evaluation results on different adversarial strategies also show\nhow the suggested method is robust for detecting possible human-level\nperturbations.", "published": "2024-03-24 21:44:14", "link": "http://arxiv.org/abs/2404.08655v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Target Speech Extraction with Pre-trained AV-HuBERT and Mask-And-Recover\n  Strategy", "abstract": "Audio-visual target speech extraction (AV-TSE) is one of the enabling\ntechnologies in robotics and many audio-visual applications. One of the\nchallenges of AV-TSE is how to effectively utilize audio-visual synchronization\ninformation in the process. AV-HuBERT can be a useful pre-trained model for\nlip-reading, which has not been adopted by AV-TSE. In this paper, we would like\nto explore the way to integrate a pre-trained AV-HuBERT into our AV-TSE system.\nWe have good reasons to expect an improved performance. To benefit from the\ninter and intra-modality correlations, we also propose a novel Mask-And-Recover\n(MAR) strategy for self-supervised learning. The experimental results on the\nVoxCeleb2 dataset show that our proposed model outperforms the baselines both\nin terms of subjective and objective metrics, suggesting that the pre-trained\nAV-HuBERT model provides more informative visual cues for target speech\nextraction. Furthermore, through a comparative study, we confirm that the\nproposed Mask-And-Recover strategy is significantly effective.", "published": "2024-03-24 09:42:05", "link": "http://arxiv.org/abs/2403.16078v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Theoretical Analysis of Quality of Conventional Beamforming for Phased\n  Microphone Arrays", "abstract": "A theoretical study is performed to analyze the directional response of\ndifferent types of microphone array designs. 1-D (linear) and 2-D (planar)\nmicrophone array types are considered, and the delay and sum beamforming and\nconventional beamforming techniques are employed to localize the sound source.\nA non-dimensional parameter, G, is characterized to simplify and standardize\nthe rejection performance of both 1-D and 2-D microphone arrays as a function\nof array geometry and sound source parameters. This parameter G is then used to\ndetermine an improved design of a 2-D microphone array for far-field sound\nlocalization. One such design, termed the Equi-area array is introduced and\nanalyzed in detail. The design is shown to have an advantageous rejection\nperformance compared to other conventionally used 2-D planar microphone arrays.", "published": "2024-03-24 10:18:04", "link": "http://arxiv.org/abs/2403.17376v1", "categories": ["cs.SD", "eess.AS", "76Q05 (Primary)"], "primary_category": "cs.SD"}
{"title": "Modeling Analog Dynamic Range Compressors using Deep Learning and\n  State-space Models", "abstract": "We describe a novel approach for developing realistic digital models of\ndynamic range compressors for digital audio production by analyzing their\nanalog prototypes. While realistic digital dynamic compressors are potentially\nuseful for many applications, the design process is challenging because the\ncompressors operate nonlinearly over long time scales. Our approach is based on\nthe structured state space sequence model (S4), as implementing the state-space\nmodel (SSM) has proven to be efficient at learning long-range dependencies and\nis promising for modeling dynamic range compressors. We present in this paper a\ndeep learning model with S4 layers to model the Teletronix LA-2A analog dynamic\nrange compressor. The model is causal, executes efficiently in real time, and\nachieves roughly the same quality as previous deep-learning models but with\nfewer parameters.", "published": "2024-03-24 23:50:15", "link": "http://arxiv.org/abs/2403.16331v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
