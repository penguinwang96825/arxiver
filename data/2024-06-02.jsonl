{"title": "LLMs Could Autonomously Learn Without External Supervision", "abstract": "In the quest for super-human performance, Large Language Models (LLMs) have\ntraditionally been tethered to human-annotated datasets and predefined training\nobjectives-a process that is both labor-intensive and inherently limited. This\npaper presents a transformative approach: Autonomous Learning for LLMs, a\nself-sufficient learning paradigm that frees models from the constraints of\nhuman supervision. This method endows LLMs with the ability to self-educate\nthrough direct interaction with text, akin to a human reading and comprehending\nliterature. Our approach eliminates the reliance on annotated data, fostering\nan Autonomous Learning environment where the model independently identifies and\nreinforces its knowledge gaps. Empirical results from our comprehensive\nexperiments, which utilized a diverse array of learning materials and were\nevaluated against standard public quizzes, reveal that Autonomous Learning\noutstrips the performance of both Pre-training and Supervised Fine-Tuning\n(SFT), as well as retrieval-augmented methods. These findings underscore the\npotential of Autonomous Learning to not only enhance the efficiency and\neffectiveness of LLM training but also to pave the way for the development of\nmore advanced, self-reliant AI systems.", "published": "2024-06-02 03:36:37", "link": "http://arxiv.org/abs/2406.00606v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Role-playing Prompt Framework: Generation and Evaluation", "abstract": "Large language models (LLMs) exhibit impressive proficiency in natural\nlanguage generation, understanding user instructions, and emulating human-like\nlanguage use, which has led to significant interest in their application to\nrole-playing scenarios. However, the manual collection of role-specific script\ndata and the evaluation of model performance are resource-intensive processes.\nThis paper introduces a prompt-based framework designed to leverage GPT's\ncapabilities for the generation of role-playing dialogue datasets and the\nevaluation of role-playing performance. To validate the effectiveness of the\nGPT-based generation and evaluation, we further incorporate the recall-oriented\nRouge-L metric, providing an additional quantitative measure of performance.", "published": "2024-06-02 06:09:56", "link": "http://arxiv.org/abs/2406.00627v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Presence or Absence: Are Unknown Word Usages in Dictionaries?", "abstract": "There has been a surge of interest in computational modeling of semantic\nchange. The foci of previous works are on detecting and interpreting word\nsenses gained over time; however, it remains unclear whether the gained senses\nare covered by dictionaries. In this work, we aim to fill this research gap by\ncomparing detected word senses with dictionary sense inventories in order to\nbridge between the communities of lexical semantic change detection and\nlexicography. We evaluate our system in the AXOLOTL-24 shared task for Finnish,\nRussian and German languages \\cite{fedorova-etal-2024-axolotl}. Our system is\nfully unsupervised. It leverages a graph-based clustering approach to predict\nmappings between unknown word usages and dictionary entries for Subtask 1, and\ngenerates dictionary-like definitions for those novel word usages through the\nstate-of-the-art Large Language Models such as GPT-4 and LLaMA-3 for Subtask 2.\nIn Subtask 1, our system outperforms the baseline system by a large margin, and\nit offers interpretability for the mapping results by distinguishing between\nmatched and unmatched (novel) word usages through our graph-based clustering\napproach. Our system ranks first in Finnish and German, and ranks second in\nRussian on the Subtask 2 test-phase leaderboard. These results show the\npotential of our system in managing dictionary entries, particularly for\nupdating dictionaries to include novel sense entries. Our code and data are\nmade publicly\navailable\\footnote{\\url{https://github.com/xiaohemaikoo/axolotl24-ABDN-NLP}}.", "published": "2024-06-02 07:57:45", "link": "http://arxiv.org/abs/2406.00656v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comprehensive Evaluation of Large Language Models for Topic Modeling", "abstract": "Recent work utilizes Large Language Models (LLMs) for topic modeling,\ngenerating comprehensible topic labels for given documents. However, their\nperformance has mainly been evaluated qualitatively, and there remains room for\nquantitative investigation of their capabilities. In this paper, we\nquantitatively evaluate LLMs from multiple perspectives: the quality of topics,\nthe impact of LLM-specific concerns, such as hallucination and shortcuts for\nlimited documents, and LLMs' controllability of topic categories via prompts.\nOur findings show that LLMs can identify coherent and diverse topics with few\nhallucinations but may take shortcuts by focusing only on parts of documents.\nWe also found that their controllability is limited.", "published": "2024-06-02 10:25:02", "link": "http://arxiv.org/abs/2406.00697v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Distributed Representations for Multi-Level Lexical\n  Semantics: A Research Proposal", "abstract": "Modern neural networks (NNs), trained on extensive raw sentence data,\nconstruct distributed representations by compressing individual words into\ndense, continuous, high-dimensional vectors. These representations are expected\nto capture multi-level lexical meaning. In this thesis, our objective is to\nexamine the efficacy of distributed representations from NNs in encoding\nlexical meaning. Initially, we identify and formalize three levels of lexical\nsemantics: \\textit{local}, \\textit{global}, and \\textit{mixed} levels. Then,\nfor each level, we evaluate language models by collecting or constructing\nmultilingual datasets, leveraging various language models, and employing\nlinguistic analysis theories. This thesis builds a bridge between computational\nmodels and lexical semantics, aiming to complement each other.", "published": "2024-06-02 14:08:51", "link": "http://arxiv.org/abs/2406.00751v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applying Intrinsic Debiasing on Downstream Tasks: Challenges and\n  Considerations for Machine Translation", "abstract": "Most works on gender bias focus on intrinsic bias -- removing traces of\ninformation about a protected group from the model's internal representation.\nHowever, these works are often disconnected from the impact of such debiasing\non downstream applications, which is the main motivation for debiasing in the\nfirst place. In this work, we systematically test how methods for intrinsic\ndebiasing affect neural machine translation models, by measuring the extrinsic\nbias of such systems under different design choices. We highlight three\nchallenges and mismatches between the debiasing techniques and their end-goal\nusage, including the choice of embeddings to debias, the mismatch between words\nand sub-word tokens debiasing, and the effect on different target languages. We\nfind that these considerations have a significant impact on downstream\nperformance and the success of debiasing.", "published": "2024-06-02 15:57:29", "link": "http://arxiv.org/abs/2406.00787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Power of Summary-Source Alignments", "abstract": "Multi-document summarization (MDS) is a challenging task, often decomposed to\nsubtasks of salience and redundancy detection, followed by text generation. In\nthis context, alignment of corresponding sentences between a reference summary\nand its source documents has been leveraged to generate training data for some\nof the component tasks. Yet, this enabling alignment step has usually been\napplied heuristically on the sentence level on a limited number of subtasks. In\nthis paper, we propose extending the summary-source alignment framework by (1)\napplying it at the more fine-grained proposition span level, (2) annotating\nalignment manually in a multi-document setup, and (3) revealing the great\npotential of summary-source alignments to yield several datasets for at least\nsix different tasks. Specifically, for each of the tasks, we release a manually\nannotated test set that was derived automatically from the alignment\nannotation. We also release development and train sets in the same way, but\nfrom automatically derived alignments. Using the datasets, each task is\ndemonstrated with baseline models and corresponding evaluation metrics to spur\nfuture research on this broad challenge.", "published": "2024-06-02 19:35:19", "link": "http://arxiv.org/abs/2406.00842v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongSkywork: A Training Recipe for Efficiently Extending Context Length\n  in Large Language Models", "abstract": "We introduce LongSkywork, a long-context Large Language Model (LLM) capable\nof processing up to 200,000 tokens. We provide a training recipe for\nefficiently extending context length of LLMs. We identify that the critical\nelement in enhancing long-context processing capability is to incorporate a\nlong-context SFT stage following the standard SFT stage. A mere 200 iterations\ncan convert the standard SFT model into a long-context model. To reduce the\neffort in collecting and annotating data for long-context language modeling, we\ndevelop two novel methods for creating synthetic data. These methods are\napplied during the continual pretraining phase as well as the Supervised\nFine-Tuning (SFT) phase, greatly enhancing the training efficiency of our\nlong-context LLMs. Our findings suggest that synthetic long-context SFT data\ncan surpass the performance of data curated by humans to some extent.\nLongSkywork achieves outstanding performance on a variety of long-context\nbenchmarks. In the Needle test, a benchmark for long-context information\nretrieval, our models achieved perfect accuracy across multiple context spans.\nMoreover, in realistic application scenarios, LongSkywork-13B demonstrates\nperformance on par with Claude2.1, the leading long-context model, underscoring\nthe effectiveness of our proposed methods.", "published": "2024-06-02 03:34:41", "link": "http://arxiv.org/abs/2406.00605v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A lexicon obtained and validated by a data-driven approach for organic\n  residues valorization in emerging and developing countries", "abstract": "The text mining method presented in this paper was used for annotation of\nterms related to biological transformation and valorization of organic residues\nin agriculture in low and middle-income country. Specialized lexicon was\nobtained through different steps: corpus and extraction of terms, annotation of\nextracted terms, selection of relevant terms.", "published": "2024-06-02 09:36:33", "link": "http://arxiv.org/abs/2406.00682v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Deciphering Oracle Bone Language with Diffusion Models", "abstract": "Originating from China's Shang Dynasty approximately 3,000 years ago, the\nOracle Bone Script (OBS) is a cornerstone in the annals of linguistic history,\npredating many established writing systems. Despite the discovery of thousands\nof inscriptions, a vast expanse of OBS remains undeciphered, casting a veil of\nmystery over this ancient language. The emergence of modern AI technologies\npresents a novel frontier for OBS decipherment, challenging traditional NLP\nmethods that rely heavily on large textual corpora, a luxury not afforded by\nhistorical languages. This paper introduces a novel approach by adopting image\ngeneration techniques, specifically through the development of Oracle Bone\nScript Decipher (OBSD). Utilizing a conditional diffusion-based strategy, OBSD\ngenerates vital clues for decipherment, charting a new course for AI-assisted\nanalysis of ancient languages. To validate its efficacy, extensive experiments\nwere conducted on an oracle bone script dataset, with quantitative results\ndemonstrating the effectiveness of OBSD. Code and decipherment results will be\nmade available at https://github.com/guanhaisu/OBSD.", "published": "2024-06-02 09:42:23", "link": "http://arxiv.org/abs/2406.00684v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Embodied World Model Based on LLM with Visual Information and\n  Prediction-Oriented Prompts", "abstract": "In recent years, as machine learning, particularly for vision and language\nunderstanding, has been improved, research in embedded AI has also evolved.\nVOYAGER is a well-known LLM-based embodied AI that enables autonomous\nexploration in the Minecraft world, but it has issues such as underutilization\nof visual data and insufficient functionality as a world model. In this\nresearch, the possibility of utilizing visual data and the function of LLM as a\nworld model were investigated with the aim of improving the performance of\nembodied AI. The experimental results revealed that LLM can extract necessary\ninformation from visual data, and the utilization of the information improves\nits performance as a world model. It was also suggested that devised prompts\ncould bring out the LLM's function as a world model.", "published": "2024-06-02 14:50:01", "link": "http://arxiv.org/abs/2406.00765v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Automatic Instruction Evolving for Large Language Models", "abstract": "Fine-tuning large pre-trained language models with Evol-Instruct has achieved\nencouraging results across a wide range of tasks. However, designing effective\nevolving methods for instruction evolution requires substantial human\nexpertise. This paper proposes Auto Evol-Instruct, an end-to-end framework that\nevolves instruction datasets using large language models without any human\neffort. The framework automatically analyzes and summarizes suitable\nevolutionary strategies for the given instruction data and iteratively improves\nthe evolving method based on issues exposed during the instruction evolution\nprocess. Our extensive experiments demonstrate that the best method optimized\nby Auto Evol-Instruct outperforms human-designed methods on various benchmarks,\nincluding MT-Bench, AlpacaEval, GSM8K, and HumanEval.", "published": "2024-06-02 15:09:00", "link": "http://arxiv.org/abs/2406.00770v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Developing an efficient corpus using Ensemble Data cleaning approach", "abstract": "Despite the observable benefit of Natural Language Processing (NLP) in\nprocessing a large amount of textual medical data within a limited time for\ninformation retrieval, a handful of research efforts have been devoted to\nuncovering novel data-cleaning methods. Data cleaning in NLP is at the centre\npoint for extracting validated information. Another observed limitation in the\nNLP domain is having limited medical corpora that provide answers to a given\nmedical question. Realising the limitations and challenges from two\nperspectives, this research aims to clean a medical dataset using ensemble\ntechniques and to develop a corpus. The corpora expect that it will answer the\nquestion based on the semantic relationship of corpus sequences. However, the\ndata cleaning method in this research suggests that the ensemble technique\nprovides the highest accuracy (94%) compared to the single process, which\nincludes vectorisation, exploratory data analysis, and feeding the vectorised\ndata. The second aim of having an adequate corpus was realised by extracting\nanswers from the dataset. This research is significant in machine learning,\nspecifically data cleaning and the medical sector, but it also underscores the\nimportance of NLP in the medical field, where accurate and timely information\nextraction can be a matter of life and death. It establishes text data\nprocessing using NLP as a powerful tool for extracting valuable information\nlike image data.", "published": "2024-06-02 16:03:31", "link": "http://arxiv.org/abs/2406.00789v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "BoNBoN Alignment for Large Language Models and the Sweetness of\n  Best-of-n Sampling", "abstract": "This paper concerns the problem of aligning samples from large language\nmodels to human preferences using best-of-$n$ sampling, where we draw $n$\nsamples, rank them, and return the best one. We consider two fundamental\nproblems. First: what is the relationship between best-of-$n$ and approaches to\nalignment that train LLMs to output samples with a high expected reward (e.g.,\nRLHF or DPO)? To answer this, we embed both the best-of-$n$ distribution and\nthe sampling distributions learned by alignment procedures in a common class of\ntiltings of the base LLM distribution. We then show that, within this class,\nbest-of-$n$ is essentially optimal in terms of the trade-off between win-rate\nagainst the base model vs KL distance from the base model. That is, best-of-$n$\nis the best choice of alignment distribution if the goal is to maximize win\nrate. However, best-of-$n$ requires drawing $n$ samples for each inference, a\nsubstantial cost. To avoid this, the second problem we consider is how to\nfine-tune a LLM to mimic the best-of-$n$ sampling distribution. We derive\nBoNBoN Alignment to achieve this by exploiting the special structure of the\nbest-of-$n$ distribution. Experiments show that BoNBoN alignment yields\nsubstantial improvements in producing a model that is preferred to the base\npolicy while minimally affecting off-target aspects.", "published": "2024-06-02 18:42:57", "link": "http://arxiv.org/abs/2406.00832v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FOCUS: Forging Originality through Contrastive Use in Self-Plagiarism\n  for Language Models", "abstract": "Pre-trained Language Models (PLMs) have shown impressive results in various\nNatural Language Generation (NLG) tasks, such as powering chatbots and\ngenerating stories. However, an ethical concern arises due to their potential\nto produce verbatim copies of paragraphs from their training data. This is\nproblematic as PLMs are trained on corpora constructed by human authors. As\nsuch, there is a pressing need for research to promote the generation of\noriginal content by these models. In this study, we introduce a unique\n\"self-plagiarism\" contrastive decoding strategy, aimed at boosting the\noriginality of text produced by PLMs. Our method entails modifying prompts in\nLLMs to develop an amateur model and a professional model. Specifically, the\namateur model is urged to plagiarize using three plagiarism templates we have\ndesigned, while the professional model maintains its standard language model\nstatus. This strategy employs prompts to stimulate the model's capacity to\nidentify non-original candidate token combinations and subsequently impose\npenalties. The application of this strategy is integrated prior to the model's\nfinal layer, ensuring smooth integration with most existing PLMs (T5, GPT,\nLLaMA) without necessitating further adjustments. Implementing our strategy, we\nobserve a significant decline in non-original sequences comprised of more than\nthree words in the academic AASC dataset and the story-based ROCStories\ndataset.", "published": "2024-06-02 19:17:00", "link": "http://arxiv.org/abs/2406.00839v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Formality Style Transfer in Persian", "abstract": "This study explores the formality style transfer in Persian, particularly\nrelevant in the face of the increasing prevalence of informal language on\ndigital platforms, which poses challenges for existing Natural Language\nProcessing (NLP) tools. The aim is to transform informal text into formal while\nretaining the original meaning, addressing both lexical and syntactic\ndifferences. We introduce a novel model, Fa-BERT2BERT, based on the Fa-BERT\narchitecture, incorporating consistency learning and gradient-based dynamic\nweighting. This approach improves the model's understanding of syntactic\nvariations, balancing loss components effectively during training. Our\nevaluation of Fa-BERT2BERT against existing methods employs new metrics\ndesigned to accurately measure syntactic and stylistic changes. Results\ndemonstrate our model's superior performance over traditional techniques across\nvarious metrics, including BLEU, BERT score, Rouge-l, and proposed metrics\nunderscoring its ability to adeptly navigate the complexities of Persian\nlanguage style transfer. This study significantly contributes to Persian\nlanguage processing by enhancing the accuracy and functionality of NLP models\nand thereby supports the development of more efficient and reliable NLP\napplications, capable of handling language style transformation effectively,\nthereby streamlining content moderation, enhancing data mining results, and\nfacilitating cross-cultural communication.", "published": "2024-06-02 20:57:27", "link": "http://arxiv.org/abs/2406.00867v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Show, Don't Tell: Aligning Language Models with Demonstrated Feedback", "abstract": "Language models are aligned to emulate the collective voice of many,\nresulting in outputs that align with no one in particular. Steering LLMs away\nfrom generic output is possible through supervised finetuning or RLHF, but\nrequires prohibitively large datasets for new ad-hoc tasks. We argue that it is\ninstead possible to align an LLM to a specific setting by leveraging a very\nsmall number ($<10$) of demonstrations as feedback. Our method, Demonstration\nITerated Task Optimization (DITTO), directly aligns language model outputs to a\nuser's demonstrated behaviors. Derived using ideas from online imitation\nlearning, DITTO cheaply generates online comparison data by treating users'\ndemonstrations as preferred over output from the LLM and its intermediate\ncheckpoints. We evaluate DITTO's ability to learn fine-grained style and task\nalignment across domains such as news articles, emails, and blog posts.\nAdditionally, we conduct a user study soliciting a range of demonstrations from\nparticipants ($N=16$). Across our benchmarks and user study, we find that\nwin-rates for DITTO outperform few-shot prompting, supervised fine-tuning, and\nother self-play methods by an average of 19% points. By using demonstrations as\nfeedback directly, DITTO offers a novel method for effective customization of\nLLMs.", "published": "2024-06-02 23:13:56", "link": "http://arxiv.org/abs/2406.00888v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Inverse Constitutional AI: Compressing Preferences into Principles", "abstract": "Feedback data plays an important role in fine-tuning and evaluating\nstate-of-the-art AI models. Often pairwise text preferences are used: given two\ntexts, human (or AI) annotators select the \"better\" one. Such feedback data is\nwidely used to align models to human preferences (e.g., reinforcement learning\nfrom human feedback), or to rank models according to human preferences (e.g.,\nChatbot Arena). Despite its wide-spread use, prior work has demonstrated that\nhuman-annotated pairwise text preference data often exhibits unintended biases.\nFor example, human annotators have been shown to prefer assertive over truthful\ntexts in certain contexts. Models trained or evaluated on this data may\nimplicitly encode these biases in a manner hard to identify. In this paper, we\nformulate the interpretation of existing pairwise text preference data as a\ncompression task: the Inverse Constitutional AI (ICAI) problem. In\nconstitutional AI, a set of principles (or constitution) is used to provide\nfeedback and fine-tune AI models. The ICAI problem inverts this process: given\na dataset of feedback, we aim to extract a constitution that best enables a\nlarge language model (LLM) to reconstruct the original annotations. We propose\na corresponding initial ICAI algorithm and validate its generated constitutions\nquantitatively based on reconstructed annotations. Generated constitutions have\nmany potential use-cases -- they may help identify undesirable biases, scale\nfeedback to unseen data or assist with adapting LLMs to individual user\npreferences. We demonstrate our approach on a variety of datasets: (a)\nsynthetic feedback datasets with known underlying principles; (b) the\nAlpacaEval dataset of cross-annotated human feedback; and (c) the crowdsourced\nChatbot Arena data set. We release the code for our algorithm and experiments\nat https://github.com/rdnfn/icai .", "published": "2024-06-02 11:54:50", "link": "http://arxiv.org/abs/2406.06560v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Brainstorming Brings Power to Large Language Models of Knowledge\n  Reasoning", "abstract": "Large Language Models (LLMs) have demonstrated amazing capabilities in\nlanguage generation, text comprehension, and knowledge reasoning. While a\nsingle powerful model can already handle multiple tasks, relying on a single\nperspective can lead to biased and unstable results. Recent studies have\nfurther improved the model's reasoning ability on a wide range of tasks by\nintroducing multi-model collaboration. However, models with different\ncapabilities may produce conflicting answers on the same problem, and how to\nreasonably obtain the correct answer from multiple candidate models has become\na challenging problem. In this paper, we propose the multi-model brainstorming\nbased on prompt. It incorporates different models into a group for\nbrainstorming, and after multiple rounds of reasoning elaboration and\nre-inference, a consensus answer is reached within the group. We conducted\nexperiments on three different types of datasets, and demonstrate that the\nbrainstorming can significantly improve the effectiveness in logical reasoning\nand fact extraction. Furthermore, we find that two small-parameter models can\nachieve accuracy approximating that of larger-parameter models through\nbrainstorming, which provides a new solution for distributed deployment of\nLLMs.", "published": "2024-06-02 14:47:14", "link": "http://arxiv.org/abs/2406.06561v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transforming Computer Security and Public Trust Through the Exploration\n  of Fine-Tuning Large Language Models", "abstract": "Large language models (LLMs) have revolutionized how we interact with\nmachines. However, this technological advancement has been paralleled by the\nemergence of \"Mallas,\" malicious services operating underground that exploit\nLLMs for nefarious purposes. Such services create malware, phishing attacks,\nand deceptive websites, escalating the cyber security threats landscape. This\npaper delves into the proliferation of Mallas by examining the use of various\npre-trained language models and their efficiency and vulnerabilities when\nmisused. Building on a dataset from the Common Vulnerabilities and Exposures\n(CVE) program, it explores fine-tuning methodologies to generate code and\nexplanatory text related to identified vulnerabilities. This research aims to\nshed light on the operational strategies and exploitation techniques of Mallas,\nleading to the development of more secure and trustworthy AI applications. The\npaper concludes by emphasizing the need for further research, enhanced\nsafeguards, and ethical guidelines to mitigate the risks associated with the\nmalicious application of LLMs.", "published": "2024-06-02 06:10:31", "link": "http://arxiv.org/abs/2406.00628v1", "categories": ["cs.CL", "cs.CR", "cs.CY", "cs.LG", "B.8.0; I.2.7; I.2.8; I.2.11; J.0; K.4.2; K.4.1"], "primary_category": "cs.CL"}
{"title": "Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback", "abstract": "In recent years, text-to-speech (TTS) technology has witnessed impressive\nadvancements, particularly with large-scale training datasets, showcasing\nhuman-level speech quality and impressive zero-shot capabilities on unseen\nspeakers. However, despite human subjective evaluations, such as the mean\nopinion score (MOS), remaining the gold standard for assessing the quality of\nsynthetic speech, even state-of-the-art TTS approaches have kept human feedback\nisolated from training that resulted in mismatched training objectives and\nevaluation metrics. In this work, we investigate a novel topic of integrating\nsubjective human evaluation into the TTS training loop. Inspired by the recent\nsuccess of reinforcement learning from human feedback, we propose a\ncomprehensive sampling-annotating-learning framework tailored to TTS\noptimization, namely uncertainty-aware optimization (UNO). Specifically, UNO\neliminates the need for a reward model or preference data by directly\nmaximizing the utility of speech generations while considering the uncertainty\nthat lies in the inherent variability in subjective human speech perception and\nevaluations. Experimental results of both subjective and objective evaluations\ndemonstrate that UNO considerably improves the zero-shot performance of TTS\nmodels in terms of MOS, word error rate, and speaker similarity. Additionally,\nwe present a remarkable ability of UNO that it can adapt to the desired\nspeaking style in emotional TTS seamlessly and flexibly.", "published": "2024-06-02 07:54:33", "link": "http://arxiv.org/abs/2406.00654v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluating Mathematical Reasoning of Large Language Models: A Focus on\n  Error Identification and Correction", "abstract": "The rapid advancement of Large Language Models (LLMs) in the realm of\nmathematical reasoning necessitates comprehensive evaluations to gauge progress\nand inspire future directions. Existing assessments predominantly focus on\nproblem-solving from the examinee perspective, overlooking a dual perspective\nof examiner regarding error identification and correction. From the examiner\nperspective, we define four evaluation tasks for error identification and\ncorrection along with a new dataset with annotated error types and steps. We\nalso design diverse prompts to thoroughly evaluate eleven representative LLMs.\nOur principal findings indicate that GPT-4 outperforms all models, while\nopen-source model LLaMA-2-7B demonstrates comparable abilities to closed-source\nmodels GPT-3.5 and Gemini Pro. Notably, calculation error proves the most\nchallenging error type. Moreover, prompting LLMs with the error types can\nimprove the average correction accuracy by 47.9\\%. These results reveal\npotential directions for developing the mathematical reasoning abilities of\nLLMs. Our code and dataset is available on https://github.com/LittleCirc1e/EIC.", "published": "2024-06-02 14:16:24", "link": "http://arxiv.org/abs/2406.00755v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Get my drift? Catching LLM Task Drift with Activation Deltas", "abstract": "LLMs are commonly used in retrieval-augmented applications to execute user\ninstructions based on data from external sources. For example, modern search\nengines use LLMs to answer queries based on relevant search results; email\nplugins summarize emails by processing their content through an LLM. However,\nthe potentially untrusted provenance of these data sources can lead to prompt\ninjection attacks, where the LLM is manipulated by natural language\ninstructions embedded in the external data, causing it to deviate from the\nuser's original instruction(s). We define this deviation as task drift. Task\ndrift is a significant concern as it allows attackers to exfiltrate data or\ninfluence the LLM's output for other users. We study LLM activations as a\nsolution to detect task drift, showing that activation deltas - the difference\nin activations before and after processing external data - are strongly\ncorrelated with this phenomenon. Through two probing methods, we demonstrate\nthat a simple linear classifier can detect drift with near-perfect ROC AUC on\nan out-of-distribution test set. We evaluate these methods by making minimal\nassumptions about how users' tasks, system prompts, and attacks can be phrased.\nWe observe that this approach generalizes surprisingly well to unseen task\ndomains, such as prompt injections, jailbreaks, and malicious instructions,\nwithout being trained on any of these attacks. Interestingly, the fact that\nthis solution does not require any modifications to the LLM (e.g.,\nfine-tuning), as well as its compatibility with existing meta-prompting\nsolutions, makes it cost-efficient and easy to deploy. To encourage further\nresearch on activation-based task inspection, decoding, and interpretability,\nwe release our large-scale TaskTracker toolkit, featuring a dataset of over\n500K instances, representations from six SoTA language models, and a suite of\ninspection tools.", "published": "2024-06-02 16:53:21", "link": "http://arxiv.org/abs/2406.00799v6", "categories": ["cs.CR", "cs.CL", "cs.CY"], "primary_category": "cs.CR"}
{"title": "Pretrained Hybrids with MAD Skills", "abstract": "While Transformers underpin modern large language models (LMs), there is a\ngrowing list of alternative architectures with new capabilities, promises, and\ntradeoffs. This makes choosing the right LM architecture challenging.\nRecently-proposed $\\textit{hybrid architectures}$ seek a best-of-all-worlds\napproach that reaps the benefits of all architectures. Hybrid design is\ndifficult for two reasons: it requires manual expert-driven search, and new\nhybrids must be trained from scratch. We propose $\\textbf{Manticore}$, a\nframework that addresses these challenges. Manticore $\\textit{automates the\ndesign of hybrid architectures}$ while reusing pretrained models to create\n$\\textit{pretrained}$ hybrids. Our approach augments ideas from differentiable\nNeural Architecture Search (NAS) by incorporating simple projectors that\ntranslate features between pretrained blocks from different architectures. We\nthen fine-tune hybrids that combine pretrained models from different\narchitecture families -- such as the GPT series and Mamba -- end-to-end. With\nManticore, we enable LM selection without training multiple models, the\nconstruction of pretrained hybrids from existing pretrained models, and the\nability to $\\textit{program}$ pretrained hybrids to have certain capabilities.\nManticore hybrids outperform existing manually-designed hybrids, achieve strong\nperformance on Long Range Arena (LRA) tasks, and can improve on pretrained\ntransformers and state space models.", "published": "2024-06-02 23:24:30", "link": "http://arxiv.org/abs/2406.00894v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Phonetic Error Analysis of Raw Waveform Acoustic Models with Parametric\n  and Non-Parametric CNNs", "abstract": "In this paper, we analyse the error patterns of the raw waveform acoustic\nmodels in TIMIT's phone recognition task. Our analysis goes beyond the\nconventional phone error rate (PER) metric. We categorise the phones into three\ngroups: {affricate, diphthong, fricative, nasal, plosive, semi-vowel, vowel,\nsilence}, {consonant, vowel+, silence}, and {voiced, unvoiced, silence} and,\ncompute the PER for each broad phonetic class in each category. We also\nconstruct a confusion matrix for each category using the substitution errors\nand compare the confusion patterns with those of the Filterbank and Wav2vec 2.0\nsystems. Our raw waveform acoustic models consists of parametric (Sinc2Net) or\nnon-parametric CNNs and Bidirectional LSTMs, achieving down to 13.7%/15.2% PERs\non TIMIT Dev/Test sets, outperforming reported PERs for raw waveform models in\nthe literature. We also investigate the impact of transfer learning from WSJ on\nthe phonetic error patterns and confusion matrices. It reduces the PER to\n11.8%/13.7% on the Dev/Test sets.", "published": "2024-06-02 23:39:15", "link": "http://arxiv.org/abs/2406.00898v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "YODAS: Youtube-Oriented Dataset for Audio and Speech", "abstract": "In this study, we introduce YODAS (YouTube-Oriented Dataset for Audio and\nSpeech), a large-scale, multilingual dataset comprising currently over 500k\nhours of speech data in more than 100 languages, sourced from both labeled and\nunlabeled YouTube speech datasets. The labeled subsets, including manual or\nautomatic subtitles, facilitate supervised model training. Conversely, the\nunlabeled subsets are apt for self-supervised learning applications. YODAS is\ndistinctive as the first publicly available dataset of its scale, and it is\ndistributed under a Creative Commons license. We introduce the collection\nmethodology utilized for YODAS, which contributes to the large-scale speech\ndataset construction. Subsequently, we provide a comprehensive analysis of\nspeech, text contained within the dataset. Finally, we describe the speech\nrecognition baselines over the top-15 languages.", "published": "2024-06-02 23:43:27", "link": "http://arxiv.org/abs/2406.00899v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Harnessing Business and Media Insights with Large Language Models", "abstract": "This paper introduces Fortune Analytics Language Model (FALM). FALM empowers\nusers with direct access to comprehensive business analysis, including market\ntrends, company performance metrics, and expert insights. Unlike generic LLMs,\nFALM leverages a curated knowledge base built from professional journalism,\nenabling it to deliver precise and in-depth answers to intricate business\nquestions. Users can further leverage natural language queries to directly\nvisualize financial data, generating insightful charts and graphs to understand\ntrends across diverse business sectors clearly. FALM fosters user trust and\nensures output accuracy through three novel methods: 1) Time-aware reasoning\nguarantees accurate event registration and prioritizes recent updates. 2)\nThematic trend analysis explicitly examines topic evolution over time,\nproviding insights into emerging business landscapes. 3) Content referencing\nand task decomposition enhance answer fidelity and data visualization accuracy.\nWe conduct both automated and human evaluations, demonstrating FALM's\nsignificant performance improvements over baseline methods while prioritizing\nresponsible AI practices. These benchmarks establish FALM as a cutting-edge LLM\nin the business and media domains, with exceptional accuracy and\ntrustworthiness.", "published": "2024-06-02 06:24:38", "link": "http://arxiv.org/abs/2406.06559v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Early Detection of Misinformation for Infodemic Management: A Domain\n  Adaptation Approach", "abstract": "An infodemic refers to an enormous amount of true information and\nmisinformation disseminated during a disease outbreak. Detecting misinformation\nat the early stage of an infodemic is key to manage it and reduce its harm to\npublic health. An early stage infodemic is characterized by a large volume of\nunlabeled information concerning a disease. As a result, conventional\nmisinformation detection methods are not suitable for this misinformation\ndetection task because they rely on labeled information in the infodemic domain\nto train their models. To address the limitation of conventional methods,\nstate-of-the-art methods learn their models using labeled information in other\ndomains to detect misinformation in the infodemic domain. The efficacy of these\nmethods depends on their ability to mitigate both covariate shift and concept\nshift between the infodemic domain and the domains from which they leverage\nlabeled information. These methods focus on mitigating covariate shift but\noverlook concept shift, rendering them less effective for the task. In\nresponse, we theoretically show the necessity of tackling both covariate shift\nand concept shift as well as how to operationalize each of them. Built on the\ntheoretical analysis, we develop a novel misinformation detection method that\naddresses both covariate shift and concept shift. Using two real-world\ndatasets, we conduct extensive empirical evaluations to demonstrate the\nsuperior performance of our method over state-of-the-art misinformation\ndetection methods as well as prevalent domain adaptation methods that can be\ntailored to solve the misinformation detection task.", "published": "2024-06-02 19:27:56", "link": "http://arxiv.org/abs/2406.10238v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Towards a copilot in BIM authoring tool using a large language\n  model-based agent for intelligent human-machine interaction", "abstract": "Facing increasingly complex BIM authoring software and the accompanying\nexpensive learning costs, designers often seek to interact with the software in\na more intelligent and lightweight manner. They aim to automate modeling\nworkflows, avoiding obstacles and difficulties caused by software usage,\nthereby focusing on the design process itself. To address this issue, we\nproposed an LLM-based autonomous agent framework that can function as a copilot\nin the BIM authoring tool, answering software usage questions, understanding\nthe user's design intentions from natural language, and autonomously executing\nmodeling tasks by invoking the appropriate tools. In a case study based on the\nBIM authoring software Vectorworks, we implemented a software prototype to\nintegrate the proposed framework seamlessly into the BIM authoring scenario. We\nevaluated the planning and reasoning capabilities of different LLMs within this\nframework when faced with complex instructions. Our work demonstrates the\nsignificant potential of LLM-based agents in design automation and intelligent\ninteraction.", "published": "2024-06-02 17:47:57", "link": "http://arxiv.org/abs/2406.16903v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "An Early Investigation into the Utility of Multimodal Large Language\n  Models in Medical Imaging", "abstract": "Recent developments in multimodal large language models (MLLMs) have spurred\nsignificant interest in their potential applications across various medical\nimaging domains. On the one hand, there is a temptation to use these generative\nmodels to synthesize realistic-looking medical image data, while on the other\nhand, the ability to identify synthetic image data in a pool of data is also\nsignificantly important. In this study, we explore the potential of the Gemini\n(\\textit{gemini-1.0-pro-vision-latest}) and GPT-4V (gpt-4-vision-preview)\nmodels for medical image analysis using two modalities of medical image data.\nUtilizing synthetic and real imaging data, both Gemini AI and GPT-4V are first\nused to classify real versus synthetic images, followed by an interpretation\nand analysis of the input images. Experimental results demonstrate that both\nGemini and GPT-4 could perform some interpretation of the input images. In this\nspecific experiment, Gemini was able to perform slightly better than the GPT-4V\non the classification task. In contrast, responses associated with GPT-4V were\nmostly generic in nature. Our early investigation presented in this work\nprovides insights into the potential of MLLMs to assist with the classification\nand interpretation of retinal fundoscopy and lung X-ray images. We also\nidentify key limitations associated with the early investigation study on MLLMs\nfor specialized tasks in medical image analysis.", "published": "2024-06-02 08:29:23", "link": "http://arxiv.org/abs/2406.00667v1", "categories": ["eess.IV", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Towards commands recommender system in BIM authoring tool using\n  transformers", "abstract": "The complexity of BIM software presents significant barriers to the\nwidespread adoption of BIM and model-based design within the Architecture,\nEngineering, and Construction (AEC) sector. End-users frequently express\nconcerns regarding the additional effort required to create a sufficiently\ndetailed BIM model when compared with conventional 2D drafting. This study\nexplores the potential of sequential recommendation systems to accelerate the\nBIM modeling process. By treating BIM software commands as recommendable items,\nwe introduce a novel end-to-end approach that predicts the next-best command\nbased on user historical interactions. Our framework extensively preprocesses\nreal-world, large-scale BIM log data, utilizes the transformer architectures\nfrom the latest large language models as the backbone network, and ultimately\nresults in a prototype that provides real-time command suggestions within the\nBIM authoring tool Vectorworks. Subsequent experiments validated that our\nproposed model outperforms the previous study, demonstrating the immense\npotential of the recommendation system in enhancing design efficiency.", "published": "2024-06-02 17:47:06", "link": "http://arxiv.org/abs/2406.10237v1", "categories": ["cs.IR", "cs.CE", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Intelligent Text-Conditioned Music Generation", "abstract": "CLIP (Contrastive Language-Image Pre-Training) is a multimodal neural network\ntrained on (text, image) pairs to predict the most relevant text caption given\nan image. It has been used extensively in image generation by connecting its\noutput with a generative model such as VQGAN, with the most notable example\nbeing OpenAI's DALLE-2. In this project, we apply a similar approach to bridge\nthe gap between natural language and music. Our model is split into two steps:\nfirst, we train a CLIP-like model on pairs of text and music over contrastive\nloss to align a piece of music with its most probable text caption. Then, we\ncombine the alignment model with a music decoder to generate music. To the best\nof our knowledge, this is the first attempt at text-conditioned deep music\ngeneration. Our experiments show that it is possible to train the text-music\nalignment model using contrastive loss and train a decoder to generate music\nfrom text prompts.", "published": "2024-06-02 06:08:41", "link": "http://arxiv.org/abs/2406.00626v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Enhanced Heart Sound Classification Using Mel Frequency Cepstral\n  Coefficients and Comparative Analysis of Single vs. Ensemble Classifier\n  Strategies", "abstract": "This paper explores the efficacy of Mel Frequency Cepstral Coefficients\n(MFCCs) in detecting abnormal heart sounds using two classification strategies:\na single classifier and an ensemble classifier approach. Heart sounds were\nfirst pre-processed to remove noise and then segmented into S1, systole, S2,\nand diastole intervals, with thirteen MFCCs estimated from each segment,\nyielding 52 MFCCs per beat. Finally, MFCCs were used for heart sound\nclassification. For that purpose, in the single classifier strategy, the MFCCs\nfrom nine consecutive beats were averaged to classify heart sounds by a single\nclassifier (either a support vector machine (SVM), the k nearest neighbors\n(kNN), or a decision tree (DT)). Conversely, the ensemble classifier strategy\nemployed nine classifiers (either nine SVMs, nine kNN classifiers, or nine DTs)\nto individually assess beats as normal or abnormal, with the overall\nclassification based on the majority vote. Both methods were tested on a\npublicly available phonocardiogram database. The heart sound classification\naccuracy was 91.95% for the SVM, 91.9% for the kNN, and 87.33% for the DT in\nthe single classifier strategy. Also, the accuracy was 93.59% for the SVM,\n91.84% for the kNN, and 92.22% for the DT in the ensemble classifier strategy.\nOverall, the results demonstrated that the ensemble classifier strategy\nimproved the accuracies of the DT and the SVM by 4.89% and 1.64%, establishing\nMFCCs as more effective than other features, including time, time-frequency,\nand statistical features, evaluated in similar studies.", "published": "2024-06-02 10:45:30", "link": "http://arxiv.org/abs/2406.00702v4", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Physics and geometry informed neural operator network with application\n  to acoustic scattering", "abstract": "In this paper, we introduce a physics and geometry informed neural operator\nnetwork with application to the forward simulation of acoustic scattering. The\ndevelopment of geometry informed deep learning models capable of learning a\nsolution operator for different computational domains is a problem of general\nimportance for a variety of engineering applications. To this end, we propose a\nphysics-informed deep operator network (DeepONet) capable of predicting the\nscattered pressure field for arbitrarily shaped scatterers using a geometric\nparameterization approach based on non-uniform rational B-splines (NURBS). This\napproach also results in parsimonious representations of non-trivial scatterer\ngeometries. In contrast to existing physics-based approaches that require model\nre-evaluation when changing the computational domains, our trained model is\ncapable of learning solution operator that can approximate\nphysically-consistent scattered pressure field in just a few seconds for\narbitrary rigid scatterer shapes; it follows that the computational time for\nforward simulations can improve (i.e. be reduced) by orders of magnitude in\ncomparison to the traditional forward solvers. In addition, this approach can\nevaluate the scattered pressure field without the need for labeled training\ndata. After presenting the theoretical approach, a comprehensive numerical\nstudy is also provided to illustrate the remarkable ability of this approach to\nsimulate the acoustic pressure fields resulting from arbitrary combinations of\narbitrary scatterer geometries. These results highlight the unique\ngeneralization capability of the proposed operator learning approach.", "published": "2024-06-02 03:41:52", "link": "http://arxiv.org/abs/2406.03407v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Robust Multi-Modal Speech In-Painting: A Sequence-to-Sequence Approach", "abstract": "The process of reconstructing missing parts of speech audio from context is\ncalled speech in-painting. Human perception of speech is inherently\nmulti-modal, involving both audio and visual (AV) cues. In this paper, we\nintroduce and study a sequence-to-sequence (seq2seq) speech in-painting model\nthat incorporates AV features. Our approach extends AV speech in-painting\ntechniques to scenarios where both audio and visual data may be jointly\ncorrupted. To achieve this, we employ a multi-modal training paradigm that\nboosts the robustness of our model across various conditions involving acoustic\nand visual distortions. This makes our distortion-aware model a plausible\nsolution for real-world challenging environments. We compare our method with\nexisting transformer-based and recurrent neural network-based models, which\nattempt to reconstruct missing speech gaps ranging from a few milliseconds to\nover a second. Our experimental results demonstrate that our novel seq2seq\narchitecture outperforms the state-of-the-art transformer solution by 38.8% in\nterms of enhancing speech quality and 7.14% in terms of improving speech\nintelligibility. We exploit a multi-task learning framework that simultaneously\nperforms lip-reading (transcribing video components to text) while\nreconstructing missing parts of the associated speech.", "published": "2024-06-02 23:51:43", "link": "http://arxiv.org/abs/2406.00901v1", "categories": ["cs.MM", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
