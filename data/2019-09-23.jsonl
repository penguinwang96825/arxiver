{"title": "Towards Best Experiment Design for Evaluating Dialogue System Output", "abstract": "To overcome the limitations of automated metrics (e.g. BLEU, METEOR) for\nevaluating dialogue systems, researchers typically use human judgments to\nprovide convergent evidence. While it has been demonstrated that human\njudgments can suffer from the inconsistency of ratings, extant research has\nalso found that the design of the evaluation task affects the consistency and\nquality of human judgments. We conduct a between-subjects study to understand\nthe impact of four experiment conditions on human ratings of dialogue system\noutput. In addition to discrete and continuous scale ratings, we also\nexperiment with a novel application of Best-Worst scaling to dialogue\nevaluation. Through our systematic study with 40 crowdsourced workers in each\ntask, we find that using continuous scales achieves more consistent ratings\nthan Likert scale or ranking-based experiment design. Additionally, we find\nthat factors such as time taken to complete the task and no prior experience of\nparticipating in similar studies of rating dialogue system output positively\nimpact consistency and agreement amongst raters", "published": "2019-09-23 01:45:55", "link": "http://arxiv.org/abs/1909.10122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency-Guided LSTM-CRF for Named Entity Recognition", "abstract": "Dependency tree structures capture long-distance and syntactic relationships\nbetween words in a sentence. The syntactic relations (e.g., nominal subject,\nobject) can potentially infer the existence of certain named entities. In\naddition, the performance of a named entity recognizer could benefit from the\nlong-distance dependencies between the words in dependency trees. In this work,\nwe propose a simple yet effective dependency-guided LSTM-CRF model to encode\nthe complete dependency trees and capture the above properties for the task of\nnamed entity recognition (NER). The data statistics show strong correlations\nbetween the entity types and dependency relations. We conduct extensive\nexperiments on several standard datasets and demonstrate the effectiveness of\nthe proposed model in improving NER and achieving state-of-the-art performance.\nOur analysis reveals that the significant improvements mainly result from the\ndependency relations and long-distance interactions provided by dependency\ntrees.", "published": "2019-09-23 04:21:35", "link": "http://arxiv.org/abs/1909.10148v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-Aware Aspect-Level Sentiment Classification with\n  Proximity-Weighted Convolution Network", "abstract": "It has been widely accepted that Long Short-Term Memory (LSTM) network,\ncoupled with attention mechanism and memory module, is useful for aspect-level\nsentiment classification. However, existing approaches largely rely on the\nmodelling of semantic relatedness of an aspect with its context words, while to\nsome extent ignore their syntactic dependencies within sentences. Consequently,\nthis may lead to an undesirable result that the aspect attends on contextual\nwords that are descriptive of other aspects. In this paper, we propose a\nproximity-weighted convolution network to offer an aspect-specific syntax-aware\nrepresentation of contexts. In particular, two ways of determining proximity\nweight are explored, namely position proximity and dependency proximity. The\nrepresentation is primarily abstracted by a bidirectional LSTM architecture and\nfurther enhanced by a proximity-weighted convolution. Experiments conducted on\nthe SemEval 2014 benchmark demonstrate the effectiveness of our proposed\napproach compared with a range of state-of-the-art models.", "published": "2019-09-23 05:56:13", "link": "http://arxiv.org/abs/1909.10171v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech Replay Detection with x-Vector Attack Embeddings and Spectral\n  Features", "abstract": "We present our system submission to the ASVspoof 2019 Challenge Physical\nAccess (PA) task. The objective for this challenge was to develop a\ncountermeasure that identifies speech audio as either bona fide or intercepted\nand replayed. The target prediction was a value indicating that a speech\nsegment was bona fide (positive values) or \"spoofed\" (negative values). Our\nsystem used convolutional neural networks (CNNs) and a representation of the\nspeech audio that combined x-vector attack embeddings with signal processing\nfeatures. The x-vector attack embeddings were created from mel-frequency\ncepstral coefficients (MFCCs) using a time-delay neural network (TDNN). These\nembeddings jointly modeled 27 different environments and 9 types of attacks\nfrom the labeled data. We also used sub-band spectral centroid magnitude\ncoefficients (SCMCs) as features. We included an additive Gaussian noise layer\nduring training as a way to augment the data to make our system more robust to\npreviously unseen attack examples. We report system performance using the\ntandem detection cost function (tDCF) and equal error rate (EER). Our approach\nperformed better that both of the challenge baselines. Our technique suggests\nthat our x-vector attack embeddings can help regularize the CNN predictions\neven when environments or attacks are more challenging.", "published": "2019-09-23 12:27:04", "link": "http://arxiv.org/abs/1909.10324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Consolidated System for Robust Multi-Document Entity Risk Extraction\n  and Taxonomy Augmentation", "abstract": "We introduce a hybrid human-automated system that provides scalable\nentity-risk relation extractions across large data sets. Given an\nexpert-defined keyword taxonomy, entities, and data sources, the system returns\ntext extractions based on bidirectional token distances between entities and\nkeywords and expands taxonomy coverage with word vector encodings. Our system\nrepresents a more simplified architecture compared to alerting focused systems\n- motivated by high coverage use cases in the risk mining space such as due\ndiligence activities and intelligence gathering. We provide an overview of the\nsystem and expert evaluations for a range of token distances. We demonstrate\nthat single and multi-sentence distance groups significantly outperform\nbaseline extractions with shorter, single sentences being preferred by\nanalysts. As the taxonomy expands, the amount of relevant information increases\nand multi-sentence extractions become more preferred, but this is tempered\nagainst entity-risk relations become more indirect. We discuss the implications\nof these observations on users, management of ambiguity and taxonomy expansion,\nand future system modifications.", "published": "2019-09-23 13:57:47", "link": "http://arxiv.org/abs/1909.10368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GNTeam at 2018 n2c2: Feature-augmented BiLSTM-CRF for drug-related\n  entity recognition in hospital discharge summaries", "abstract": "Monitoring the administration of drugs and adverse drug reactions are key\nparts of pharmacovigilance. In this paper, we explore the extraction of drug\nmentions and drug-related information (reason for taking a drug, route,\nfrequency, dosage, strength, form, duration, and adverse events) from hospital\ndischarge summaries through deep learning that relies on various\nrepresentations for clinical named entity recognition. This work was officially\npart of the 2018 n2c2 shared task, and we use the data supplied as part of the\ntask. We developed two deep learning architecture based on recurrent neural\nnetworks and pre-trained language models. We also explore the effect of\naugmenting word representations with semantic features for clinical named\nentity recognition. Our feature-augmented BiLSTM-CRF model performed with\nF1-score of 92.67% and ranked 4th for entity extraction sub-task among\nsubmitted systems to n2c2 challenge. The recurrent neural networks that use the\npre-trained domain-specific word embeddings and a CRF layer for label\noptimization perform drug, adverse event and related entities extraction with\nmicro-averaged F1-score of over 91%. The augmentation of word vectors with\nsemantic features extracted using available clinical NLP toolkits can further\nimprove the performance. Word embeddings that are pre-trained on a large\nunannotated corpus of relevant documents and further fine-tuned to the task\nperform rather well. However, the augmentation of word embeddings with semantic\nfeatures can help improve the performance (primarily by boosting precision) of\ndrug-related named entity recognition from electronic health records.", "published": "2019-09-23 14:35:23", "link": "http://arxiv.org/abs/1909.10390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Specificity-Based Sentence Ordering for Multi-Document Extractive Risk\n  Summarization", "abstract": "Risk mining technologies seek to find relevant textual extractions that\ncapture entity-risk relationships. However, when high volume data sets are\nprocessed, a multitude of relevant extractions can be returned, shifting the\nfocus to how best to present the results. We provide the details of a risk\nmining multi-document extractive summarization system that produces high\nquality output by modeling shifts in specificity that are characteristic of\nwell-formed discourses. In particular, we propose a novel selection algorithm\nthat alternates between extracts based on human curated or expanded autoencoded\nkey terms, which exhibit greater specificity or generality as it relates to an\nentity-risk relationship. Through this extract ordering, and without the need\nfor more complex discourse-aware NLP, we induce felicitous shifts in\nspecificity in the alternating summaries that outperform non-alternating\nsummaries on automatic ROUGE and BLEU scores, and manual understandability and\npreferences evaluations - achieving no statistically significant difference\nwhen compared to human authored summaries.", "published": "2019-09-23 14:37:30", "link": "http://arxiv.org/abs/1909.10393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Chess Commentator Powered by Neural Chess Engine", "abstract": "In this paper, we explore a new approach for automated chess commentary\ngeneration, which aims to generate chess commentary texts in different\ncategories (e.g., description, comparison, planning, etc.). We introduce a\nneural chess engine into text generation models to help with encoding boards,\npredicting moves, and analyzing situations. By jointly training the neural\nchess engine and the generation models for different categories, the models\nbecome more effective. We conduct experiments on 5 categories in a benchmark\nChess Commentary dataset and achieve inspiring results in both automatic and\nhuman evaluations.", "published": "2019-09-23 15:12:45", "link": "http://arxiv.org/abs/1909.10413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical Mention Disambiguation using a Deep Learning Approach", "abstract": "Automatically locating named entities in natural language text - named entity\nrecognition - is an important task in the biomedical domain. Many named entity\nmentions are ambiguous between several bioconcept types, however, causing text\nspans to be annotated as more than one type when simultaneously recognizing\nmultiple entity types. The straightforward solution is a rule-based approach\napplying a priority order based on the precision of each entity tagger (from\nhighest to lowest). While this method is straightforward and useful, imprecise\ndisambiguation remains a significant source of error. We address this issue by\ngenerating a partially labeled corpus of ambiguous concept mentions. We first\ncollect named entity mentions from multiple human-curated databases (e.g.\nCTDbase, gene2pubmed), then correlate them with the text mined span from\nPubTator to provide the context where the mention appears. Our corpus contains\nmore than 3 million concept mentions that ambiguous between one or more concept\ntypes in PubTator (about 3% of all mentions). We approached this task as a\nclassification problem and developed a deep learning-based method which uses\nthe semantics of the span being classified and the surrounding words to\nidentify the most likely bioconcept type. More specifically, we develop a\nconvolutional neural network (CNN) and along short-term memory (LSTM) network\nto respectively handle the semantic syntax features, then concatenate these\nwithin a fully connected layer for final classification. The priority ordering\nrule-based approach demonstrated F1-scores of 71.29% (micro-averaged) and\n41.19% (macro-averaged), while the new disambiguation method demonstrated\nF1-scores of 91.94% (micro-averaged) and 85.42% (macro-averaged), a very\nsubstantial increase.", "published": "2019-09-23 15:14:56", "link": "http://arxiv.org/abs/1909.10416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with\n  Contextualized Embeddings", "abstract": "Contextualized word embeddings (CWE) such as provided by ELMo (Peters et al.,\n2018), Flair NLP (Akbik et al., 2018), or BERT (Devlin et al., 2019) are a\nmajor recent innovation in NLP. CWEs provide semantic vector representations of\nwords depending on their respective context. Their advantage over static word\nembeddings has been shown for a number of tasks, such as text classification,\nsequence tagging, or machine translation. Since vectors of the same word type\ncan vary depending on the respective context, they implicitly provide a model\nfor word sense disambiguation (WSD). We introduce a simple but effective\napproach to WSD using a nearest neighbor classification on CWEs. We compare the\nperformance of different CWE models for the task and can report improvements\nabove the current state of the art for two standard WSD benchmark datasets. We\nfurther show that the pre-trained BERT model is able to place polysemic words\ninto distinct 'sense' regions of the embedding space, while ELMo and Flair NLP\ndo not seem to possess this ability.", "published": "2019-09-23 15:38:02", "link": "http://arxiv.org/abs/1909.10430v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Natural Language Generation via Pre-Training", "abstract": "In this work we focus on transferring supervision signals of natural language\ngeneration (NLG) tasks between multiple languages. We propose to pretrain the\nencoder and the decoder of a sequence-to-sequence model under both monolingual\nand cross-lingual settings. The pre-training objective encourages the model to\nrepresent different languages in the shared space, so that we can conduct\nzero-shot cross-lingual transfer. After the pre-training procedure, we use\nmonolingual data to fine-tune the pre-trained model on downstream NLG tasks.\nThen the sequence-to-sequence model trained in a single language can be\ndirectly evaluated beyond that language (i.e., accepting multi-lingual input\nand producing multi-lingual output). Experimental results on question\ngeneration and abstractive summarization show that our model outperforms the\nmachine-translation-based pipeline methods for zero-shot cross-lingual\ngeneration. Moreover, cross-lingual transfer improves NLG performance of\nlow-resource languages by leveraging rich-resource language data. Our\nimplementation and data are available at https://github.com/CZWin32768/xnlg.", "published": "2019-09-23 16:59:28", "link": "http://arxiv.org/abs/1909.10481v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Priming to Uncover the Organization of Syntactic Representations\n  in Neural Language Models", "abstract": "Neural language models (LMs) perform well on tasks that require sensitivity\nto syntactic structure. Drawing on the syntactic priming paradigm from\npsycholinguistics, we propose a novel technique to analyze the representations\nthat enable such success. By establishing a gradient similarity metric between\nstructures, this technique allows us to reconstruct the organization of the\nLMs' syntactic representational space. We use this technique to demonstrate\nthat LSTM LMs' representations of different types of sentences with relative\nclauses are organized hierarchically in a linguistically interpretable manner,\nsuggesting that the LMs track abstract properties of the sentence.", "published": "2019-09-23 19:13:33", "link": "http://arxiv.org/abs/1909.10579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-stage Pretraining for Abstractive Summarization", "abstract": "Neural models for abstractive summarization tend to achieve the best\nperformance in the presence of highly specialized, summarization specific\nmodeling add-ons such as pointer-generator, coverage-modeling, and\ninferencetime heuristics. We show here that pretraining can complement such\nmodeling advancements to yield improved results in both short-form and\nlong-form abstractive summarization using two key concepts: full-network\ninitialization and multi-stage pretraining. Our method allows the model to\ntransitively benefit from multiple pretraining tasks, from generic language\ntasks to a specialized summarization task to an even more specialized one such\nas bullet-based summarization. Using this approach, we demonstrate improvements\nof 1.05 ROUGE-L points on the Gigaword benchmark and 1.78 ROUGE-L points on the\nCNN/DailyMail benchmark, compared to a randomly-initialized baseline.", "published": "2019-09-23 20:10:56", "link": "http://arxiv.org/abs/1909.10599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Short Answer Grading via Multiway Attention Networks", "abstract": "Automatic short answer grading (ASAG), which autonomously score student\nanswers according to reference answers, provides a cost-effective and\nconsistent approach to teaching professionals and can reduce their monotonous\nand tedious grading workloads. However, ASAG is a very challenging task due to\ntwo reasons: (1) student answers are made up of free text which requires a deep\nsemantic understanding; and (2) the questions are usually open-ended and across\nmany domains in K-12 scenarios. In this paper, we propose a generalized\nend-to-end ASAG learning framework which aims to (1) autonomously extract\nlinguistic information from both student and reference answers; and (2)\naccurately model the semantic relations between free-text student and reference\nanswers in open-ended domain. The proposed ASAG model is evaluated on a large\nreal-world K-12 dataset and can outperform the state-of-the-art baselines in\nterms of various evaluation metrics.", "published": "2019-09-23 05:29:04", "link": "http://arxiv.org/abs/1909.10166v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "NLVR2 Visual Bias Analysis", "abstract": "NLVR2 (Suhr et al., 2019) was designed to be robust for language bias through\na data collection process that resulted in each natural language sentence\nappearing with both true and false labels. The process did not provide a\nsimilar measure of control for visual bias. This technical report analyzes the\npotential for visual bias in NLVR2. We show that some amount of visual bias\nlikely exists. Finally, we identify a subset of the test data that allows to\ntest for model performance in a way that is robust to such potential biases. We\nshow that the performance of existing models (Li et al., 2019; Tan and Bansal\n2019) is relatively robust to this potential bias. We propose to add the\nevaluation on this subset of the data to the NLVR2 evaluation protocol, and\nupdate the official release to include it. A notebook including an\nimplementation of the code used to replicate this analysis is available at\nhttp://nlvr.ai/NLVR2BiasAnalysis.html.", "published": "2019-09-23 15:10:41", "link": "http://arxiv.org/abs/1909.10411v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Data Ordering Patterns for Neural Machine Translation: An Empirical\n  Study", "abstract": "Recent works show that ordering of the training data affects the model\nperformance for Neural Machine Translation. Several approaches involving\ndynamic data ordering and data sharding based on curriculum learning have been\nanalysed for the their performance gains and faster convergence. In this work\nwe propose to empirically study several ordering approaches for the training\ndata based on different metrics and evaluate their impact on the model\nperformance. Results from our study show that pre-fixing the ordering of the\ntraining data based on perplexity scores from a pre-trained model performs the\nbest and outperforms the default approach of randomly shuffling the training\ndata every epoch.", "published": "2019-09-23 22:20:03", "link": "http://arxiv.org/abs/1909.10642v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sliding window property testing for regular languages", "abstract": "We study the problem of recognizing regular languages in a variant of the\nstreaming model of computation, called the sliding window model. In this model,\nwe are given a size of the sliding window $n$ and a stream of symbols. At each\ntime instant, we must decide whether the suffix of length $n$ of the current\nstream (\"the active window\") belongs to a given regular language.\n  Recent works showed that the space complexity of an optimal deterministic\nsliding window algorithm for this problem is either constant, logarithmic or\nlinear in the window size $n$ and provided natural language theoretic\ncharacterizations of the space complexity classes. Subsequently, those results\nwere extended to randomized algorithms to show that any such algorithm admits\neither constant, double logarithmic, logarithmic or linear space complexity.\n  In this work, we make an important step forward and combine the sliding\nwindow model with the property testing setting, which results in\nultra-efficient algorithms for all regular languages. Informally, a sliding\nwindow property tester must accept the active window if it belongs to the\nlanguage and reject it if it is far from the language. We consider\ndeterministic and randomized sliding window property testers with one-sided and\ntwo-sided errors. In particular, we show that for any regular language, there\nis a deterministic sliding window property tester that uses logarithmic space\nand a randomized sliding window property tester with two-sided error that uses\nconstant space.", "published": "2019-09-23 10:12:13", "link": "http://arxiv.org/abs/1909.10261v1", "categories": ["cs.DS", "cs.CL", "cs.FL"], "primary_category": "cs.DS"}
{"title": "TinyBERT: Distilling BERT for Natural Language Understanding", "abstract": "Language model pre-training, such as BERT, has significantly improved the\nperformances of many natural language processing tasks. However, pre-trained\nlanguage models are usually computationally expensive, so it is difficult to\nefficiently execute them on resource-restricted devices. To accelerate\ninference and reduce model size while maintaining accuracy, we first propose a\nnovel Transformer distillation method that is specially designed for knowledge\ndistillation (KD) of the Transformer-based models. By leveraging this new KD\nmethod, the plenty of knowledge encoded in a large teacher BERT can be\neffectively transferred to a small student Tiny-BERT. Then, we introduce a new\ntwo-stage learning framework for TinyBERT, which performs Transformer\ndistillation at both the pretraining and task-specific learning stages. This\nframework ensures that TinyBERT can capture he general-domain as well as the\ntask-specific knowledge in BERT.\n  TinyBERT with 4 layers is empirically effective and achieves more than 96.8%\nthe performance of its teacher BERTBASE on GLUE benchmark, while being 7.5x\nsmaller and 9.4x faster on inference. TinyBERT with 4 layers is also\nsignificantly better than 4-layer state-of-the-art baselines on BERT\ndistillation, with only about 28% parameters and about 31% inference time of\nthem. Moreover, TinyBERT with 6 layers performs on-par with its teacher\nBERTBASE.", "published": "2019-09-23 13:05:35", "link": "http://arxiv.org/abs/1909.10351v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Model Stability as a Function of Random Seed", "abstract": "In this paper, we focus on quantifying model stability as a function of\nrandom seed by investigating the effects of the induced randomness on model\nperformance and the robustness of the model in general. We specifically perform\na controlled study on the effect of random seeds on the behaviour of attention,\ngradient-based and surrogate model based (LIME) interpretations. Our analysis\nsuggests that random seeds can adversely affect the consistency of models\nresulting in counterfactual interpretations. We propose a technique called\nAggressive Stochastic Weight Averaging (ASWA)and an extension called\nNorm-filtered Aggressive Stochastic Weight Averaging (NASWA) which improves the\nstability of models over random seeds. With our ASWA and NASWA based\noptimization, we are able to improve the robustness of the original model, on\naverage reducing the standard deviation of the model's performance by 72%.", "published": "2019-09-23 16:00:06", "link": "http://arxiv.org/abs/1909.10447v1", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Dense Representations for Entity Retrieval", "abstract": "We show that it is feasible to perform entity linking by training a dual\nencoder (two-tower) model that encodes mentions and entities in the same dense\nvector space, where candidate entities are retrieved by approximate nearest\nneighbor search. Unlike prior work, this setup does not rely on an alias table\nfollowed by a re-ranker, and is thus the first fully learned entity retrieval\nmodel. We show that our dual encoder, trained using only anchor-text links in\nWikipedia, outperforms discrete alias table and BM25 baselines, and is\ncompetitive with the best comparable results on the standard TACKBP-2010\ndataset. In addition, it can retrieve candidates extremely fast, and\ngeneralizes well to a new dataset derived from Wikinews. On the modeling side,\nwe demonstrate the dramatic value of an unsupervised negative mining algorithm\nfor this task.", "published": "2019-09-23 17:52:34", "link": "http://arxiv.org/abs/1909.10506v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hypernym Detection Using Strict Partial Order Networks", "abstract": "This paper introduces Strict Partial Order Networks (SPON), a novel neural\nnetwork architecture designed to enforce asymmetry and transitive properties as\nsoft constraints. We apply it to induce hypernymy relations by training with\nis-a pairs. We also present an augmented variant of SPON that can generalize\ntype information learned for in-vocabulary terms to previously unseen ones. An\nextensive evaluation over eleven benchmarks across different tasks shows that\nSPON consistently either outperforms or attains the state of the art on all but\none of these benchmarks.", "published": "2019-09-23 18:54:52", "link": "http://arxiv.org/abs/1909.10572v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Portuguese Named Entity Recognition using BERT-CRF", "abstract": "Recent advances in language representation using neural networks have made it\nviable to transfer the learned internal states of a trained model to downstream\nnatural language processing tasks, such as named entity recognition (NER) and\nquestion answering. It has been shown that the leverage of pre-trained language\nmodels improves the overall performance on many tasks and is highly beneficial\nwhen labeled data is scarce. In this work, we train Portuguese BERT models and\nemploy a BERT-CRF architecture to the NER task on the Portuguese language,\ncombining the transfer capabilities of BERT with the structured predictions of\nCRF. We explore feature-based and fine-tuning training strategies for the BERT\nmodel. Our fine-tuning approach obtains new state-of-the-art results on the\nHAREM I dataset, improving the F1-score by 1 point on the selective scenario (5\nNE classes) and by 4 points on the total scenario (10 NE classes).", "published": "2019-09-23 23:21:42", "link": "http://arxiv.org/abs/1909.10649v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Generative Visual Dialog by Answering Diverse Questions", "abstract": "Prior work on training generative Visual Dialog models with reinforcement\nlearning(Das et al.) has explored a Qbot-Abot image-guessing game and shown\nthat this 'self-talk' approach can lead to improved performance at the\ndownstream dialog-conditioned image-guessing task. However, this improvement\nsaturates and starts degrading after a few rounds of interaction, and does not\nlead to a better Visual Dialog model. We find that this is due in part to\nrepeated interactions between Qbot and Abot during self-talk, which are not\ninformative with respect to the image. To improve this, we devise a simple\nauxiliary objective that incentivizes Qbot to ask diverse questions, thus\nreducing repetitions and in turn enabling Abot to explore a larger state space\nduring RL ie. be exposed to more visual concepts to talk about, and varied\nquestions to answer. We evaluate our approach via a host of automatic metrics\nand human studies, and demonstrate that it leads to better dialog, ie. dialog\nthat is more diverse (ie. less repetitive), consistent (ie. has fewer\nconflicting exchanges), fluent (ie. more human-like),and detailed, while still\nbeing comparably image-relevant as prior work and ablations.", "published": "2019-09-23 16:47:15", "link": "http://arxiv.org/abs/1909.10470v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Formalism for Supporting the Development of Verifiably Safe Medical\n  Guidelines with Statecharts", "abstract": "Improving the effectiveness and safety of patient care is the ultimate\nobjective for medical cyber-physical systems. Many medical best practice\nguidelines exist, but most of the existing guidelines in handbooks are\ndifficult for medical staff to remember and apply clinically. Furthermore,\nalthough the guidelines have gone through clinical validations, validations by\nmedical professionals alone do not provide guarantees for the safety of medical\ncyber-physical systems. Hence, formal verification is also needed. The paper\npresents the formal semantics for a framework that we developed to support the\ndevelopment of verifiably safe medical guidelines.\n  The framework allows computer scientists to work together with medical\nprofessionals to transform medical best practice guidelines into executable\nstatechart models, Yakindu in particular, so that medical functionalities and\nproperties can be quickly prototyped and validated. Existing formal\nverification technologies, UPPAAL timed automata in particular, is integrated\ninto the framework to provide formal verification capabilities to verify safety\nproperties. However, some components used/built into the framework, such as the\nopen-source Yakindu statecharts as well as the transformation rules from\nstatecharts to timed automata, do not have built-in semantics. The ambiguity\nbecomes unavoidable unless formal semantics is defined for the framework, which\nis what the paper is to present.", "published": "2019-09-23 17:25:50", "link": "http://arxiv.org/abs/1909.10493v1", "categories": ["cs.SE", "cs.CL", "cs.FL", "cs.LO", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Automatic Lyrics Alignment and Transcription in Polyphonic Music: Does\n  Background Music Help?", "abstract": "Background music affects lyrics intelligibility of singing vocals in a music\npiece. Automatic lyrics alignment and transcription in polyphonic music are\nchallenging tasks because the singing vocals are corrupted by the background\nmusic. In this work, we propose to learn music genre-specific characteristics\nto train polyphonic acoustic models. We first compare several automatic speech\nrecognition pipelines for the application of lyrics transcription. We then\npresent the lyrics alignment and transcription performance of music-informed\nacoustic models for the best-performing pipeline, and systematically study the\nimpact of music genre and language model on the performance. With such\ngenre-based approach, we explicitly model the music without removing it during\nacoustic modeling. The proposed approach outperforms all competing systems in\nthe lyrics alignment and transcription tasks on several well-known polyphonic\ntest datasets.", "published": "2019-09-23 07:57:07", "link": "http://arxiv.org/abs/1909.10200v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sequence to Sequence Neural Speech Synthesis with Prosody Modification\n  Capabilities", "abstract": "Modern sequence to sequence neural TTS systems provide close to natural\nspeech quality. Such systems usually comprise a network converting\nlinguistic/phonetic features sequence to an acoustic features sequence,\ncascaded with a neural vocoder. The generated speech prosody (i.e. phoneme\ndurations, pitch and loudness) is implicitly present in the acoustic features,\nbeing mixed with spectral information. Although the speech sounds natural, its\nprosody realization is randomly chosen and cannot be easily altered. The\nprosody control becomes an even more difficult task if no prosodic labeling is\npresent in the training data. Recently, much progress has been achieved in\nunsupervised speaking style learning and generation, however human inspection\nis still required after the training for discovery and interpretation of the\nspeaking styles learned by the system. In this work we introduce a fully\nautomatic method that makes the system aware of the prosody and enables\nsentence-wise speaking pace and expressiveness control on a continuous scale.\nWhile being useful by itself in many applications, the proposed prosody control\ncan also improve the overall quality and expressiveness of the synthesized\nspeech, as demonstrated by subjective listening evaluations. We also propose a\nnovel augmented attention mechanism, that facilitates better pace control\nsensitivity and faster attention convergence.", "published": "2019-09-23 11:43:30", "link": "http://arxiv.org/abs/1909.10302v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CochleaNet: A Robust Language-independent Audio-Visual Model for Speech\n  Enhancement", "abstract": "Noisy situations cause huge problems for suffers of hearing loss as hearing\naids often make the signal more audible but do not always restore the\nintelligibility. In noisy settings, humans routinely exploit the audio-visual\n(AV) nature of the speech to selectively suppress the background noise and to\nfocus on the target speaker. In this paper, we present a causal, language,\nnoise and speaker independent AV deep neural network (DNN) architecture for\nspeech enhancement (SE). The model exploits the noisy acoustic cues and noise\nrobust visual cues to focus on the desired speaker and improve the speech\nintelligibility. To evaluate the proposed SE framework a first of its kind AV\nbinaural speech corpus, called ASPIRE, is recorded in real noisy environments\nincluding cafeteria and restaurant. We demonstrate superior performance of our\napproach in terms of objective measures and subjective listening tests over the\nstate-of-the-art SE approaches as well as recent DNN based SE models. In\naddition, our work challenges a popular belief that a scarcity of\nmulti-language large vocabulary AV corpus and wide variety of noises is a major\nbottleneck to build a robust language, speaker and noise independent SE\nsystems. We show that a model trained on synthetic mixture of Grid corpus (with\n33 speakers and a small English vocabulary) and ChiME 3 Noises (consisting of\nonly bus, pedestrian, cafeteria, and street noises) generalise well not only on\nlarge vocabulary corpora but also on completely unrelated languages (such as\nMandarin), wide variety of speakers and noises.", "published": "2019-09-23 14:59:47", "link": "http://arxiv.org/abs/1909.10407v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
