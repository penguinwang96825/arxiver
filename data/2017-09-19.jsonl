{"title": "Dynamic Oracle for Neural Machine Translation in Decoding Phase", "abstract": "The past several years have witnessed the rapid progress of end-to-end Neural\nMachine Translation (NMT). However, there exists discrepancy between training\nand inference in NMT when decoding, which may lead to serious problems since\nthe model might be in a part of the state space it has never seen during\ntraining. To address the issue, Scheduled Sampling has been proposed. However,\nthere are certain limitations in Scheduled Sampling and we propose two dynamic\noracle-based methods to improve it. We manage to mitigate the discrepancy by\nchanging the training process towards a less guided scheme and meanwhile\naggregating the oracle's demonstrations. Experimental results show that the\nproposed approaches improve translation quality over standard NMT system.", "published": "2017-09-19 06:07:12", "link": "http://arxiv.org/abs/1709.06265v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Fast and Accurate Vietnamese Word Segmenter", "abstract": "We propose a novel approach to Vietnamese word segmentation. Our approach is\nbased on the Single Classification Ripple Down Rules methodology (Compton and\nJansen, 1990), where rules are stored in an exception structure and new rules\nare only added to correct segmentation errors given by existing rules.\nExperimental results on the benchmark Vietnamese treebank show that our\napproach outperforms previous state-of-the-art approaches JVnSegmenter,\nvnTokenizer, DongDu and UETsegmenter in terms of both accuracy and performance\nspeed. Our code is open-source and available at:\nhttps://github.com/datquocnguyen/RDRsegmenter.", "published": "2017-09-19 09:16:09", "link": "http://arxiv.org/abs/1709.06307v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-Based Relational Sentiment Analysis Using a Stacked Neural\n  Network Architecture", "abstract": "Sentiment analysis can be regarded as a relation extraction problem in which\nthe sentiment of some opinion holder towards a certain aspect of a product,\ntheme or event needs to be extracted. We present a novel neural architecture\nfor sentiment analysis as a relation extraction problem that addresses this\nproblem by dividing it into three subtasks: i) identification of aspect and\nopinion terms, ii) labeling of opinion terms with a sentiment, and iii)\nextraction of relations between opinion terms and aspect terms. For each\nsubtask, we propose a neural network based component and combine all of them\ninto a complete system for relational sentiment analysis. The component for\naspect and opinion term extraction is a hybrid architecture consisting of a\nrecurrent neural network stacked on top of a convolutional neural network. This\napproach outperforms a standard convolutional deep neural architecture as well\nas a recurrent network architecture and performs competitively compared to\nother methods on two datasets of annotated customer reviews. To extract\nsentiments for individual opinion terms, we propose a recurrent architecture in\ncombination with word distance features and achieve promising results,\noutperforming a majority baseline by 18% accuracy and providing the first\nresults for the USAGE dataset. Our relation extraction component outperforms\nthe current state-of-the-art in aspect-opinion relation extraction by 15%\nF-Measure.", "published": "2017-09-19 09:22:12", "link": "http://arxiv.org/abs/1709.06309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-Based Sentiment Analysis Using a Two-Step Neural Network\n  Architecture", "abstract": "The World Wide Web holds a wealth of information in the form of unstructured\ntexts such as customer reviews for products, events and more. By extracting and\nanalyzing the expressed opinions in customer reviews in a fine-grained way,\nvaluable opportunities and insights for customers and businesses can be gained.\nWe propose a neural network based system to address the task of Aspect-Based\nSentiment Analysis to compete in Task 2 of the ESWC-2016 Challenge on Semantic\nSentiment Analysis. Our proposed architecture divides the task in two subtasks:\naspect term extraction and aspect-specific sentiment extraction. This approach\nis flexible in that it allows to address each subtask independently. As a first\nstep, a recurrent neural network is used to extract aspects from a text by\nframing the problem as a sequence labeling task. In a second step, a recurrent\nnetwork processes each extracted aspect with respect to its context and\npredicts a sentiment label. The system uses pretrained semantic word embedding\nfeatures which we experimentally enhance with semantic knowledge extracted from\nWordNet. Further features extracted from SenticNet prove to be beneficial for\nthe extraction of sentiment labels. As the best performing system in its\ncategory, our proposed system proves to be an effective approach for the\nAspect-Based Sentiment Analysis.", "published": "2017-09-19 09:30:35", "link": "http://arxiv.org/abs/1709.06311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Opinion-Target Extraction with Character-Level Word Embeddings", "abstract": "Fine-grained sentiment analysis is receiving increasing attention in recent\nyears. Extracting opinion target expressions (OTE) in reviews is often an\nimportant step in fine-grained, aspect-based sentiment analysis. Retrieving\nthis information from user-generated text, however, can be difficult. Customer\nreviews, for instance, are prone to contain misspelled words and are difficult\nto process due to their domain-specific language. In this work, we investigate\nwhether character-level models can improve the performance for the\nidentification of opinion target expressions. We integrate information about\nthe character structure of a word into a sequence labeling system using\ncharacter-level word embeddings and show their positive impact on the system's\nperformance. Specifically, we obtain an increase by 3.3 points F1-score with\nrespect to our baseline model. In further experiments, we reveal encoded\ncharacter patterns of the learned embeddings and give a nuanced view of the\nperformance differences of both models.", "published": "2017-09-19 09:46:11", "link": "http://arxiv.org/abs/1709.06317v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Modeling with Highway LSTM", "abstract": "Language models (LMs) based on Long Short Term Memory (LSTM) have shown good\ngains in many automatic speech recognition tasks. In this paper, we extend an\nLSTM by adding highway networks inside an LSTM and use the resulting Highway\nLSTM (HW-LSTM) model for language modeling. The added highway networks increase\nthe depth in the time dimension. Since a typical LSTM has two internal states,\na memory cell and a hidden state, we compare various types of HW-LSTM by adding\nhighway networks onto the memory cell and/or the hidden state. Experimental\nresults on English broadcast news and conversational telephone speech\nrecognition show that the proposed HW-LSTM LM improves speech recognition\naccuracy on top of a strong LSTM LM baseline. We report 5.1% and 9.9% on the\nSwitchboard and CallHome subsets of the Hub5 2000 evaluation, which reaches the\nbest performance numbers reported on these tasks to date.", "published": "2017-09-19 14:04:15", "link": "http://arxiv.org/abs/1709.06436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Recorded Debating Dataset", "abstract": "This paper describes an English audio and textual dataset of debating\nspeeches, a unique resource for the growing research field of computational\nargumentation and debating technologies. We detail the process of speech\nrecording by professional debaters, the transcription of the speeches with an\nAutomatic Speech Recognition (ASR) system, their consequent automatic\nprocessing to produce a text that is more \"NLP-friendly\", and in parallel --\nthe manual transcription of the speeches in order to produce gold-standard\n\"reference\" transcripts. We release 60 speeches on various controversial\ntopics, each in five formats corresponding to the different stages in the\nproduction of the data. The intention is to allow utilizing this resource for\nmultiple research purposes, be it the addition of in-domain training data for a\ndebate-specific ASR system, or applying argumentation mining on either noisy or\nclean debate transcripts. We intend to make further releases of this data in\nthe future.", "published": "2017-09-19 14:09:03", "link": "http://arxiv.org/abs/1709.06438v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MetaLDA: a Topic Model that Efficiently Incorporates Meta information", "abstract": "Besides the text content, documents and their associated words usually come\nwith rich sets of meta informa- tion, such as categories of documents and\nsemantic/syntactic features of words, like those encoded in word embeddings.\nIncorporating such meta information directly into the generative process of\ntopic models can improve modelling accuracy and topic quality, especially in\nthe case where the word-occurrence information in the training data is\ninsufficient. In this paper, we present a topic model, called MetaLDA, which is\nable to leverage either document or word meta information, or both of them\njointly. With two data argumentation techniques, we can derive an efficient\nGibbs sampling algorithm, which benefits from the fully local conjugacy of the\nmodel. Moreover, the algorithm is favoured by the sparsity of the meta\ninformation. Extensive experiments on several real world datasets demonstrate\nthat our model achieves comparable or improved performance in terms of both\nperplexity and topic quality, particularly in handling sparse texts. In\naddition, compared with other models using meta information, our model runs\nsignificantly faster.", "published": "2017-09-19 12:09:21", "link": "http://arxiv.org/abs/1709.06365v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Neural Networks for Text Correction and Completion in Keyboard Decoding", "abstract": "Despite the ubiquity of mobile and wearable text messaging applications, the\nproblem of keyboard text decoding is not tackled sufficiently in the light of\nthe enormous success of the deep learning Recurrent Neural Network (RNN) and\nConvolutional Neural Networks (CNN) for natural language understanding. In\nparticular, considering that the keyboard decoders should operate on devices\nwith memory and processor resource constraints, makes it challenging to deploy\nindustrial scale deep neural network (DNN) models. This paper proposes a\nsequence-to-sequence neural attention network system for automatic text\ncorrection and completion. Given an erroneous sequence, our model encodes\ncharacter level hidden representations and then decodes the revised sequence\nthus enabling auto-correction and completion. We achieve this by a combination\nof character level CNN and gated recurrent unit (GRU) encoder along with and a\nword level gated recurrent unit (GRU) attention decoder. Unlike traditional\nlanguage models that learn from billions of words, our corpus size is only 12\nmillion words; an order of magnitude smaller. The memory footprint of our\nlearnt model for inference and prediction is also an order of magnitude smaller\nthan the conventional language model based text decoders. We report baseline\nperformance for neural keyboard decoders in such limited domain. Our models\nachieve a word level accuracy of $90\\%$ and a character error rate CER of\n$2.4\\%$ over the Twitter typo dataset. We present a novel dataset of noisy to\ncorrected mappings by inducing the noise distribution from the Twitter data\nover the OpenSubtitles 2009 dataset; on which our model predicts with a word\nlevel accuracy of $98\\%$ and sequence accuracy of $68.9\\%$. In our user study,\nour model achieved an average CER of $2.6\\%$ with the state-of-the-art\nnon-neural touch-screen keyboard decoder at CER of $1.6\\%$.", "published": "2017-09-19 13:52:28", "link": "http://arxiv.org/abs/1709.06429v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Methodology and Results for the Competition on Semantic Similarity\n  Evaluation and Entailment Recognition for PROPOR 2016", "abstract": "In this paper, we present the methodology and the results obtained by our\nteams, dubbed Blue Man Group, in the ASSIN (from the Portuguese {\\it\nAvalia\\c{c}\\~ao de Similaridade Sem\\^antica e Infer\\^encia Textual})\ncompetition, held at PROPOR 2016\\footnote{International Conference on the\nComputational Processing of the Portuguese Language -\nhttp://propor2016.di.fc.ul.pt/}. Our team's strategy consisted of evaluating\nmethods based on semantic word vectors, following two distinct directions: 1)\nto make use of low-dimensional, compact, feature sets, and 2) deep\nlearning-based strategies dealing with high-dimensional feature vectors.\nEvaluation results demonstrated that the first strategy was more promising, so\nthat the results from the second strategy have been discarded. As a result, by\nconsidering the best run of each of the six teams, we have been able to achieve\nthe best accuracy and F1 values in entailment recognition, in the Brazilian\nPortuguese set, and the best F1 score overall. In the semantic similarity task,\nour team was ranked second in the Brazilian Portuguese set, and third\nconsidering both sets.", "published": "2017-09-19 18:02:51", "link": "http://arxiv.org/abs/1709.08694v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Think Globally, Embed Locally --- Locally Linear Meta-embedding of Words", "abstract": "Distributed word embeddings have shown superior performances in numerous\nNatural Language Processing (NLP) tasks. However, their performances vary\nsignificantly across different tasks, implying that the word embeddings learnt\nby those methods capture complementary aspects of lexical semantics. Therefore,\nwe believe that it is important to combine the existing word embeddings to\nproduce more accurate and complete \\emph{meta-embeddings} of words. For this\npurpose, we propose an unsupervised locally linear meta-embedding learning\nmethod that takes pre-trained word embeddings as the input, and produces more\naccurate meta embeddings. Unlike previously proposed meta-embedding learning\nmethods that learn a global projection over all words in a vocabulary, our\nproposed method is sensitive to the differences in local neighbourhoods of the\nindividual source word embeddings. Moreover, we show that vector concatenation,\na previously proposed highly competitive baseline approach for integrating word\nembeddings, can be derived as a special case of the proposed method.\nExperimental results on semantic similarity, word analogy, relation\nclassification, and short-text classification tasks show that our\nmeta-embeddings to significantly outperform prior methods in several benchmark\ndatasets, establishing a new state of the art for meta-embeddings.", "published": "2017-09-19 22:58:02", "link": "http://arxiv.org/abs/1709.06671v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational\n  Compositional Operators for Analogy Detection", "abstract": "Representing the semantic relations that exist between two given words (or\nentities) is an important first step in a wide-range of NLP applications such\nas analogical reasoning, knowledge base completion and relational information\nretrieval. A simple, yet surprisingly accurate method for representing a\nrelation between two words is to compute the vector offset (\\PairDiff) between\ntheir corresponding word embeddings. Despite the empirical success, it remains\nunclear as to whether \\PairDiff is the best operator for obtaining a relational\nrepresentation from word embeddings. We conduct a theoretical analysis of\ngeneralised bilinear operators that can be used to measure the $\\ell_{2}$\nrelational distance between two word-pairs. We show that, if the word\nembeddings are standardised and uncorrelated, such an operator will be\nindependent of bilinear terms, and can be simplified to a linear form, where\n\\PairDiff is a special case. For numerous word embedding types, we empirically\nverify the uncorrelation assumption, demonstrating the general applicability of\nour theoretical result. Moreover, we experimentally discover \\PairDiff from the\nbilinear relation composition operator on several benchmark analogy datasets.", "published": "2017-09-19 23:09:15", "link": "http://arxiv.org/abs/1709.06673v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Linear Computer-Music through Sequences over Galois Fields", "abstract": "It is shown how binary sequences can be associated with automatic composition\nof monophonic pieces. We are concerned with the composition of e-music from\nfinite field structures. The information at the input may be either random or\ninformation from a black-and-white, grayscale or color picture. New\ne-compositions and music score are made available, including a new piece from\nthe famous Lenna picture: the score of the e-music <<Between Lenna's eyes in C\nmajor.>> The corresponding stretch of music score are presented. Some\nparticular structures, including clock arithmetic (mod 12), GF(7), GF(8),\nGF(13) and GF(17) are addressed. Further, multilevel block-codes are also used\nin a new approach of e-music composition, engendering a particular style as an\ne-composer. As an example, Pascal multilevel block codes recently introduced\nare handled to generate a new style of electronic music over GF(13).", "published": "2017-09-19 22:36:16", "link": "http://arxiv.org/abs/1709.06663v1", "categories": ["cs.SD", "eess.AS", "68U07, 68W05, 11B50, 12E20", "H.5.5; J.5; I.5.4; F.2.1"], "primary_category": "cs.SD"}
{"title": "MuseGAN: Multi-track Sequential Generative Adversarial Networks for\n  Symbolic Music Generation and Accompaniment", "abstract": "Generating music has a few notable differences from generating images and\nvideos. First, music is an art of time, necessitating a temporal model. Second,\nmusic is usually composed of multiple instruments/tracks with their own\ntemporal dynamics, but collectively they unfold over time interdependently.\nLastly, musical notes are often grouped into chords, arpeggios or melodies in\npolyphonic music, and thereby introducing a chronological ordering of notes is\nnot naturally suitable. In this paper, we propose three models for symbolic\nmulti-track music generation under the framework of generative adversarial\nnetworks (GANs). The three models, which differ in the underlying assumptions\nand accordingly the network architectures, are referred to as the jamming\nmodel, the composer model and the hybrid model. We trained the proposed models\non a dataset of over one hundred thousand bars of rock music and applied them\nto generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.\nA few intra-track and inter-track objective metrics are also proposed to\nevaluate the generative results, in addition to a subjective user study. We\nshow that our models can generate coherent music of four bars right from\nscratch (i.e. without human inputs). We also extend our models to human-AI\ncooperative music generation: given a specific track composed by human, we can\ngenerate four additional tracks to accompany it. All code, the dataset and the\nrendered audio samples are available at https://salu133445.github.io/musegan/ .", "published": "2017-09-19 08:49:40", "link": "http://arxiv.org/abs/1709.06298v2", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
