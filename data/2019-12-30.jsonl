{"title": "Deep Reinforced Self-Attention Masks for Abstractive Summarization\n  (DR.SAS)", "abstract": "We present a novel architectural scheme to tackle the abstractive\nsummarization problem based on the CNN/DMdataset which fuses Reinforcement\nLearning (RL) withUniLM, which is a pre-trained Deep Learning Model, to solve\nvarious natural language tasks. We have tested the limits of learning\nfine-grained attention in Transformers to improve the summarization quality.\nUniLM applies attention to the entire token space in a global fashion. We\npropose DR.SAS which applies the Actor-Critic (AC) algorithm to learn a dynamic\nself-attention distribution over the tokens to reduce redundancy and generate\nfactual and coherent summaries to improve the quality of summarization. After\nperforming hyperparameter tuning, we achievedbetter ROUGE results compared to\nthe baseline. Our model tends to be more extractive/factual yet coherent in\ndetail because of optimization over ROUGE rewards. We present detailed error\nanalysis with examples of the strengths and limitations of our model. Our\ncodebase will be publicly available on our GitHub.", "published": "2019-12-30 01:32:42", "link": "http://arxiv.org/abs/2001.00009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Likelihood Ratios and Generative Classifiers for Unsupervised\n  Out-of-Domain Detection In Task Oriented Dialog", "abstract": "The task of identifying out-of-domain (OOD) input examples directly at\ntest-time has seen renewed interest recently due to increased real world\ndeployment of models. In this work, we focus on OOD detection for natural\nlanguage sentence inputs to task-based dialog systems. Our findings are\nthree-fold: First, we curate and release ROSTD (Real Out-of-Domain Sentences\nFrom Task-oriented Dialog) - a dataset of 4K OOD examples for the publicly\navailable dataset from (Schuster et al. 2019). In contrast to existing settings\nwhich synthesize OOD examples by holding out a subset of classes, our examples\nwere authored by annotators with apriori instructions to be out-of-domain with\nrespect to the sentences in an existing dataset. Second, we explore likelihood\nratio based approaches as an alternative to currently prevalent paradigms.\nSpecifically, we reformulate and apply these approaches to natural language\ninputs. We find that they match or outperform the latter on all datasets, with\nlarger improvements on non-artificial OOD benchmarks such as our dataset. Our\nablations validate that specifically using likelihood ratios rather than plain\nlikelihood is necessary to discriminate well between OOD and in-domain data.\nThird, we propose learning a generative classifier and computing a marginal\nlikelihood (ratio) for OOD detection. This allows us to use a principled\nlikelihood while at the same time exploiting training-time labels. We find that\nthis approach outperforms both simple likelihood (ratio) based and other prior\napproaches. We are hitherto the first to investigate the use of generative\nclassifiers for OOD detection at test-time.", "published": "2019-12-30 03:31:17", "link": "http://arxiv.org/abs/1912.12800v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Shmoop Corpus: A Dataset of Stories with Loosely Aligned Summaries", "abstract": "Understanding stories is a challenging reading comprehension problem for\nmachines as it requires reading a large volume of text and following long-range\ndependencies. In this paper, we introduce the Shmoop Corpus: a dataset of 231\nstories that are paired with detailed multi-paragraph summaries for each\nindividual chapter (7,234 chapters), where the summary is chronologically\naligned with respect to the story chapter. From the corpus, we construct a set\nof common NLP tasks, including Cloze-form question answering and a simplified\nform of abstractive summarization, as benchmarks for reading comprehension on\nstories. We then show that the chronological alignment provides a strong\nsupervisory signal that learning-based methods can exploit leading to\nsignificant improvements on these tasks. We believe that the unique structure\nof this corpus provides an important foothold towards making machine story\ncomprehension more approachable.", "published": "2019-12-30 21:03:59", "link": "http://arxiv.org/abs/1912.13082v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Factors Affecting Language-Independent Models", "abstract": "Scaling existing applications and solutions to multiple human languages has\ntraditionally proven to be difficult, mainly due to the language-dependent\nnature of preprocessing and feature engineering techniques employed in\ntraditional approaches. In this work, we empirically investigate the factors\naffecting language-independent models built with multilingual representations,\nincluding task type, language set and data resource. On two most representative\nNLP tasks -- sentence classification and sequence labeling, we show that\nlanguage-independent models can be comparable to or even outperforms the models\ntrained using monolingual data, and they are generally more effective on\nsentence classification. We experiment language-independent models with many\ndifferent languages and show that they are more suitable for typologically\nsimilar languages. We also explore the effects of different data sizes when\ntraining and testing language-independent models, and demonstrate that they are\nnot only suitable for high-resource languages, but also very effective in\nlow-resource languages.", "published": "2019-12-30 22:41:57", "link": "http://arxiv.org/abs/1912.13106v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Causal-Anticausal Decomposition of Speech using Complex Cepstrum for\n  Glottal Source Estimation", "abstract": "Complex cepstrum is known in the literature for linearly separating causal\nand anticausal components. Relying on advances achieved by the Zeros of the\nZ-Transform (ZZT) technique, we here investigate the possibility of using\ncomplex cepstrum for glottal flow estimation on a large-scale database. Via a\nsystematic study of the windowing effects on the deconvolution quality, we show\nthat the complex cepstrum causal-anticausal decomposition can be effectively\nused for glottal flow estimation when specific windowing criteria are met. It\nis also shown that this complex cepstral decomposition gives similar glottal\nestimates as obtained with the ZZT method. However, as complex cepstrum uses\nFFT operations instead of requiring the factoring of high-degree polynomials,\nthe method benefits from a much higher speed. Finally in our tests on a large\ncorpus of real expressive speech, we show that the proposed method has the\npotential to be used for voice quality analysis.", "published": "2019-12-30 08:12:03", "link": "http://arxiv.org/abs/1912.12843v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Using a Pitch-Synchronous Residual Codebook for Hybrid HMM/Frame\n  Selection Speech Synthesis", "abstract": "This paper proposes a method to improve the quality delivered by statistical\nparametric speech synthesizers. For this, we use a codebook of\npitch-synchronous residual frames, so as to construct a more realistic source\nsignal. First a limited codebook of typical excitations is built from some\ntraining database. During the synthesis part, HMMs are used to generate filter\nand source coefficients. The latter coefficients contain both the pitch and a\ncompact representation of target residual frames. The source signal is obtained\nby concatenating excitation frames picked up from the codebook, based on a\nselection criterion and taking target residual coefficients as input.\nSubjective results show a relevant improvement compared to the basic technique.", "published": "2019-12-30 11:34:39", "link": "http://arxiv.org/abs/1912.12887v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks", "abstract": "Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.", "published": "2019-12-30 16:44:41", "link": "http://arxiv.org/abs/1912.12999v3", "categories": ["cs.LG", "cs.CL", "cs.CY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AraNet: A Deep Learning Toolkit for Arabic Social Media", "abstract": "We describe AraNet, a collection of deep learning Arabic social media\nprocessing tools. Namely, we exploit an extensive host of publicly available\nand novel social media datasets to train bidirectional encoders from\ntransformer models (BERT) to predict age, dialect, gender, emotion, irony, and\nsentiment. AraNet delivers state-of-the-art performance on a number of the\ncited tasks and competitively on others. In addition, AraNet has the advantage\nof being exclusively based on a deep learning framework and hence feature\nengineering free. To the best of our knowledge, AraNet is the first to performs\npredictions across such a wide range of tasks for Arabic NLP and thus meets a\ncritical needs. We publicly release AraNet to accelerate research and\nfacilitate comparisons across the different tasks.", "published": "2019-12-30 20:05:37", "link": "http://arxiv.org/abs/1912.13072v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teaching a New Dog Old Tricks: Resurrecting Multilingual Retrieval Using\n  Zero-shot Learning", "abstract": "While billions of non-English speaking users rely on search engines every\nday, the problem of ad-hoc information retrieval is rarely studied for\nnon-English languages. This is primarily due to a lack of data set that are\nsuitable to train ranking algorithms. In this paper, we tackle the lack of data\nby leveraging pre-trained multilingual language models to transfer a retrieval\nsystem trained on English collections to non-English queries and documents. Our\nmodel is evaluated in a zero-shot setting, meaning that we use them to predict\nrelevance scores for query-document pairs in languages never seen during\ntraining. Our results show that the proposed approach can significantly\noutperform unsupervised retrieval techniques for Arabic, Chinese Mandarin, and\nSpanish. We also show that augmenting the English training collection with some\nexamples from the target language can sometimes improve performance.", "published": "2019-12-30 20:46:38", "link": "http://arxiv.org/abs/1912.13080v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "\"Hinglish\" Language -- Modeling a Messy Code-Mixed Language", "abstract": "With a sharp rise in fluency and users of \"Hinglish\" in linguistically\ndiverse country, India, it has increasingly become important to analyze social\ncontent written in this language in platforms such as Twitter, Reddit,\nFacebook. This project focuses on using deep learning techniques to tackle a\nclassification problem in categorizing social content written in Hindi-English\ninto Abusive, Hate-Inducing and Not offensive categories. We utilize\nbi-directional sequence models with easy text augmentation techniques such as\nsynonym replacement, random insertion, random swap, and random deletion to\nproduce a state of the art classifier that outperforms the previous work done\non analyzing this dataset.", "published": "2019-12-30 23:01:28", "link": "http://arxiv.org/abs/1912.13109v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Objective Study of Sensor Relevance for Automatic Cough Detection", "abstract": "The development of a system for the automatic, objective and reliable\ndetection of cough events is a need underlined by the medical literature for\nyears. The benefit of such a tool is clear as it would allow the assessment of\npathology severity in chronic cough diseases. Even though some approaches have\nrecently reported solutions achieving this task with a relative success, there\nis still no standardization about the method to adopt or the sensors to use.\nThe goal of this paper is to study objectively the performance of several\nsensors for cough detection: ECG, thermistor, chest belt, accelerometer,\ncontact and audio microphones. Experiments are carried out on a database of 32\nhealthy subjects producing, in a confined room and in three situations,\nvoluntary cough at various volumes as well as other event categories which can\npossibly lead to some detection errors: background noise, forced expiration,\nthroat clearing, speech and laugh. The relevance of each sensor is evaluated at\nthree stages: mutual information conveyed by the features, ability to\ndiscriminate at the frame level cough from these latter other sources of\nambiguity, and ability to detect cough events. In this latter experiment, with\nboth an averaged sensitivity and specificity of about 94.5%, the proposed\napproach is shown to clearly outperform the commercial Karmelsonix system which\nachieved a specificity of 95.3% and a sensitivity of 64.9%.", "published": "2019-12-30 11:31:44", "link": "http://arxiv.org/abs/2001.00537v1", "categories": ["physics.med-ph", "cs.SD", "eess.AS"], "primary_category": "physics.med-ph"}
{"title": "Neural Architecture Search on Acoustic Scene Classification", "abstract": "Convolutional neural networks are widely adopted in Acoustic Scene\nClassification (ASC) tasks, but they generally carry a heavy computational\nburden. In this work, we propose a lightweight yet high-performing baseline\nnetwork inspired by MobileNetV2, which replaces square convolutional kernels\nwith unidirectional ones to extract features alternately in temporal and\nfrequency dimensions. Furthermore, we explore a dynamic architecture space\nbuilt on the basis of the proposed baseline with the recent Neural Architecture\nSearch (NAS) paradigm, which first trains a supernet that incorporates all\ncandidate networks and then applies a well-known evolutionary algorithm NSGA-II\nto discover more efficient networks with higher accuracy and lower\ncomputational cost. Experimental results demonstrate that our searched network\nis competent in ASC tasks, which achieves 90.3% F1-score on the DCASE2018 task\n5 evaluation set, marking a new state-of-the-art performance while saving 25%\nof FLOPs compared to our baseline network.", "published": "2019-12-30 06:35:12", "link": "http://arxiv.org/abs/1912.12825v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
