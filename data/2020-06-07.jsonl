{"title": "Medical Concept Normalization in User Generated Texts by Learning Target\n  Concept Embeddings", "abstract": "Medical concept normalization helps in discovering standard concepts in\nfree-form text i.e., maps health-related mentions to standard concepts in a\nvocabulary. It is much beyond simple string matching and requires a deep\nsemantic understanding of concept mentions. Recent research approach concept\nnormalization as either text classification or text matching. The main drawback\nin existing a) text classification approaches is ignoring valuable target\nconcepts information in learning input concept mention representation b) text\nmatching approach is the need to separately generate target concept embeddings\nwhich is time and resource consuming. Our proposed model overcomes these\ndrawbacks by jointly learning the representations of input concept mention and\ntarget concepts. First, it learns the input concept mention representation\nusing RoBERTa. Second, it finds cosine similarity between embeddings of input\nconcept mention and all the target concepts. Here, embeddings of target\nconcepts are randomly initialized and then updated during training. Finally,\nthe target concept with maximum cosine similarity is assigned to the input\nconcept mention. Our model surpasses all the existing methods across three\nstandard datasets by improving accuracy up to 2.31%.", "published": "2020-06-07 01:17:18", "link": "http://arxiv.org/abs/2006.04014v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training Polish Transformer-based Language Models at Scale", "abstract": "Transformer-based language models are now widely used in Natural Language\nProcessing (NLP). This statement is especially true for English language, in\nwhich many pre-trained models utilizing transformer-based architecture have\nbeen published in recent years. This has driven forward the state of the art\nfor a variety of standard NLP tasks such as classification, regression, and\nsequence labeling, as well as text-to-text tasks, such as machine translation,\nquestion answering, or summarization. The situation have been different for\nlow-resource languages, such as Polish, however. Although some\ntransformer-based language models for Polish are available, none of them have\ncome close to the scale, in terms of corpus size and the number of parameters,\nof the largest English-language models. In this study, we present two language\nmodels for Polish based on the popular BERT architecture. The larger model was\ntrained on a dataset consisting of over 1 billion polish sentences, or 135GB of\nraw text. We describe our methodology for collecting the data, preparing the\ncorpus, and pre-training the model. We then evaluate our models on thirteen\nPolish linguistic tasks, and demonstrate improvements over previous approaches\nin eleven of them.", "published": "2020-06-07 18:48:58", "link": "http://arxiv.org/abs/2006.04229v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multitask Learning Approach for Diacritic Restoration", "abstract": "In many languages like Arabic, diacritics are used to specify pronunciations\nas well as meanings. Such diacritics are often omitted in written text,\nincreasing the number of possible pronunciations and meanings for a word. This\nresults in a more ambiguous text making computational processing on such text\nmore difficult. Diacritic restoration is the task of restoring missing\ndiacritics in the written text. Most state-of-the-art diacritic restoration\nmodels are built on character level information which helps generalize the\nmodel to unseen data, but presumably lose useful information at the word level.\nThus, to compensate for this loss, we investigate the use of multi-task\nlearning to jointly optimize diacritic restoration with related NLP problems\nnamely word segmentation, part-of-speech tagging, and syntactic diacritization.\nWe use Arabic as a case study since it has sufficient data resources for tasks\nthat we consider in our joint modeling. Our joint models significantly\noutperform the baselines and are comparable to the state-of-the-art models that\nare more complex relying on morphological analyzers and/or a lot more data\n(e.g. dialectal data).", "published": "2020-06-07 01:20:40", "link": "http://arxiv.org/abs/2006.04016v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Loss Application to Entity Relation Recognition", "abstract": "Usually, entity relation recognition systems either use a pipe-lined model\nthat treats the entity tagging and relation identification as separate tasks or\na joint model that simultaneously identifies the relation and entities. This\npaper compares these two general approaches for the entity relation\nrecognition. State-of-the-art entity relation recognition systems are built\nusing deep recurrent neural networks which often does not capture the symbolic\nknowledge or the logical constraints in the problem. The main contribution of\nthis paper is an end-to-end neural model for joint entity relation extraction\nwhich incorporates a novel loss function. This novel loss function encodes the\nconstraint information in the problem to guide the model training effectively.\nWe show that addition of this loss function to the existing typical loss\nfunctions has a positive impact over the performance of the models. This model\nis truly end-to-end, requires no feature engineering and easily extensible.\nExtensive experimentation has been conducted to evaluate the significance of\ncapturing symbolic knowledge for natural language understanding. Models using\nthis loss function are observed to be outperforming their counterparts and\nconverging faster. Experimental results in this work suggest the use of this\nmethodology for other language understanding applications.", "published": "2020-06-07 03:12:38", "link": "http://arxiv.org/abs/2006.04031v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Models as Fact Checkers?", "abstract": "Recent work has suggested that language models (LMs) store both common-sense\nand factual knowledge learned from pre-training data. In this paper, we\nleverage this implicit knowledge to create an effective end-to-end fact checker\nusing a solely a language model, without any external knowledge or explicit\nretrieval components. While previous work on extracting knowledge from LMs have\nfocused on the task of open-domain question answering, to the best of our\nknowledge, this is the first work to examine the use of language models as fact\ncheckers. In a closed-book setting, we show that our zero-shot LM approach\noutperforms a random baseline on the standard FEVER task, and that our\nfine-tuned LM compares favorably with standard baselines. Though we do not\nultimately outperform methods which use explicit knowledge bases, we believe\nour exploration shows that this method is viable and has much room for\nexploration.", "published": "2020-06-07 09:52:05", "link": "http://arxiv.org/abs/2006.04102v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analysis and Synthesis of Hypo and Hyperarticulated Speech", "abstract": "This paper focuses on the analysis and synthesis of hypo and hyperarticulated\nspeech in the framework of HMM-based speech synthesis. First of all, a new\nFrench database matching our needs was created, which contains three identical\nsets, pronounced with three different degrees of articulation: neutral, hypo\nand hyperarticulated speech. On that basis, acoustic and phonetic analyses were\nperformed. It is shown that the degrees of articulation significantly\ninfluence, on one hand, both vocal tract and glottal characteristics, and on\nthe other hand, speech rate, phone durations, phone variations and the presence\nof glottal stops. Finally, neutral, hypo and hyperarticulated speech are\nsynthesized using HMM-based speech synthesis and both objective and subjective\ntests aiming at assessing the generated speech quality are performed. These\ntests show that synthesized hypoarticulated speech seems to be less naturally\nrendered than neutral and hyperarticulated speech.", "published": "2020-06-07 12:21:16", "link": "http://arxiv.org/abs/2006.04136v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Interactive Extractive Search over Biomedical Corpora", "abstract": "We present a system that allows life-science researchers to search a\nlinguistically annotated corpus of scientific texts using patterns over\ndependency graphs, as well as using patterns over token sequences and a\npowerful variant of boolean keyword queries. In contrast to previous attempts\nto dependency-based search, we introduce a light-weight query language that\ndoes not require the user to know the details of the underlying linguistic\nrepresentations, and instead to query the corpus by providing an example\nsentence coupled with simple markup. Search is performed at an interactive\nspeed due to efficient linguistic graph-indexing and retrieval engine. This\nallows for rapid exploration, development and refinement of user queries. We\ndemonstrate the system using example workflows over two corpora: the PubMed\ncorpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a\ncollection of over 45,000 research papers focused on COVID-19 research. The\nsystem is publicly available at https://allenai.github.io/spike", "published": "2020-06-07 13:26:32", "link": "http://arxiv.org/abs/2006.04148v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BERT Loses Patience: Fast and Robust Inference with Early Exit", "abstract": "In this paper, we propose Patience-based Early Exit, a straightforward yet\neffective inference method that can be used as a plug-and-play technique to\nsimultaneously improve the efficiency and robustness of a pretrained language\nmodel (PLM). To achieve this, our approach couples an internal-classifier with\neach layer of a PLM and dynamically stops inference when the intermediate\npredictions of the internal classifiers remain unchanged for a pre-defined\nnumber of steps. Our approach improves inference efficiency as it allows the\nmodel to make a prediction with fewer layers. Meanwhile, experimental results\nwith an ALBERT model show that our method can improve the accuracy and\nrobustness of the model by preventing it from overthinking and exploiting\nmultiple classifiers for prediction, yielding a better accuracy-speed trade-off\ncompared to existing early exit methods.", "published": "2020-06-07 13:38:32", "link": "http://arxiv.org/abs/2006.04152v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tensors over Semirings for Latent-Variable Weighted Logic Programs", "abstract": "Semiring parsing is an elegant framework for describing parsers by using\nsemiring weighted logic programs. In this paper we present a generalization of\nthis concept: latent-variable semiring parsing. With our framework, any\nsemiring weighted logic program can be latentified by transforming weights from\nscalar values of a semiring to rank-n arrays, or tensors, of semiring values,\nallowing the modelling of latent variables within the semiring parsing\nframework. Semiring is too strong a notion when dealing with tensors, and we\nhave to resort to a weaker structure: a partial semiring. We prove that this\ngeneralization preserves all the desired properties of the original semiring\nframework while strictly increasing its expressiveness.", "published": "2020-06-07 18:52:58", "link": "http://arxiv.org/abs/2006.04232v1", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Growing Together: Modeling Human Language Learning With n-Best\n  Multi-Checkpoint Machine Translation", "abstract": "We describe our submission to the 2020 Duolingo Shared Task on Simultaneous\nTranslation And Paraphrase for Language Education (STAPLE) (Mayhew et al.,\n2020). We view MT models at various training stages (i.e., checkpoints) as\nhuman learners at different levels. Hence, we employ an ensemble of\nmulti-checkpoints from the same model to generate translation sequences with\nvarious levels of fluency. From each checkpoint, for our best model, we sample\nn-Best sequences (n=10) with a beam width =100. We achieve 37.57 macro F1 with\na 6 checkpoint model ensemble on the official English to Portuguese shared task\ntest data, outperforming a baseline Amazon translation system of 21.30 macro F1\nand ultimately demonstrating the utility of our intuitive method.", "published": "2020-06-07 05:46:15", "link": "http://arxiv.org/abs/2006.04050v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Incorporating Pragmatic Reasoning Communication into Emergent Language", "abstract": "Emergentism and pragmatics are two research fields that study the dynamics of\nlinguistic communication along substantially different timescales and\nintelligence levels. From the perspective of multi-agent reinforcement\nlearning, they correspond to stochastic games with reinforcement training and\nstage games with opponent awareness. Given that their combination has been\nexplored in linguistics, we propose computational models that combine\nshort-term mutual reasoning-based pragmatics with long-term language\nemergentism. We explore this for agent communication referential games as well\nas in Starcraft II, assessing the relative merits of different kinds of mutual\nreasoning pragmatics models both empirically and theoretically. Our results\nshed light on their importance for making inroads towards getting more natural,\naccurate, robust, fine-grained, and succinct utterances.", "published": "2020-06-07 10:31:06", "link": "http://arxiv.org/abs/2006.04109v2", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Maximum Phase Modeling for Sparse Linear Prediction of Speech", "abstract": "Linear prediction (LP) is an ubiquitous analysis method in speech processing.\nVarious studies have focused on sparse LP algorithms by introducing sparsity\nconstraints into the LP framework. Sparse LP has been shown to be effective in\nseveral issues related to speech modeling and coding. However, all existing\napproaches assume the speech signal to be minimum-phase. Because speech is\nknown to be mixed-phase, the resulting residual signal contains a persistent\nmaximum-phase component. The aim of this paper is to propose a novel technique\nwhich incorporates a modeling of the maximum-phase contribution of speech, and\ncan be applied to any filter representation. The proposed method is shown to\nsignificantly increase the sparsity of the LP residual signal and to be\neffective in two illustrative applications: speech polarity detection and\nexcitation modeling.", "published": "2020-06-07 12:34:20", "link": "http://arxiv.org/abs/2006.04138v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Parametric Representation for Singing Voice Synthesis: a Comparative\n  Evaluation", "abstract": "Various parametric representations have been proposed to model the speech\nsignal. While the performance of such vocoders is well-known in the context of\nspeech processing, their extrapolation to singing voice synthesis might not be\nstraightforward. The goal of this paper is twofold. First, a comparative\nsubjective evaluation is performed across four existing techniques suitable for\nstatistical parametric synthesis: traditional pulse vocoder, Deterministic plus\nStochastic Model, Harmonic plus Noise Model and GlottHMM. The behavior of these\ntechniques as a function of the singer type (baritone, counter-tenor and\nsoprano) is studied. Secondly, the artifacts occurring in high-pitched voices\nare discussed and possible approaches to overcome them are suggested.", "published": "2020-06-07 13:06:30", "link": "http://arxiv.org/abs/2006.04142v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Probing Neural Dialog Models for Conversational Understanding", "abstract": "The predominant approach to open-domain dialog generation relies on\nend-to-end training of neural models on chat datasets. However, this approach\nprovides little insight as to what these models learn (or do not learn) about\nengaging in dialog. In this study, we analyze the internal representations\nlearned by neural open-domain dialog systems and evaluate the quality of these\nrepresentations for learning basic conversational skills. Our results suggest\nthat standard open-domain dialog systems struggle with answering questions,\ninferring contradiction, and determining the topic of conversation, among other\ntasks. We also find that the dyadic, turn-taking nature of dialog is not fully\nleveraged by these models. By exploring these limitations, we highlight the\nneed for additional research into architectures and training methods that can\nbetter capture high-level information about dialog.", "published": "2020-06-07 17:32:00", "link": "http://arxiv.org/abs/2006.08331v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net\n  architecture", "abstract": "Voice conversion (VC) is a task that transforms the source speaker's timbre,\naccent, and tones in audio into another one's while preserving the linguistic\ncontent. It is still a challenging work, especially in a one-shot setting.\nAuto-encoder-based VC methods disentangle the speaker and the content in input\nspeech without given the speaker's identity, so these methods can further\ngeneralize to unseen speakers. The disentangle capability is achieved by vector\nquantization (VQ), adversarial training, or instance normalization (IN).\nHowever, the imperfect disentanglement may harm the quality of output speech.\nIn this work, to further improve audio quality, we use the U-Net architecture\nwithin an auto-encoder-based VC system. We find that to leverage the U-Net\narchitecture, a strong information bottleneck is necessary. The VQ-based\nmethod, which quantizes the latent vectors, can serve the purpose. The\nobjective and the subjective evaluations show that the proposed method performs\nwell in both audio naturalness and speaker similarity.", "published": "2020-06-07 14:01:16", "link": "http://arxiv.org/abs/2006.04154v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
