{"title": "Multi-Task Generative Adversarial Nets with Shared Memory for Cross-Domain Coordination Control", "abstract": "Generating sequential decision process from huge amounts of measured process data is a future research direction for collaborative factory automation, making full use of those online or offline process data to directly design flexible make decisions policy, and evaluate performance. The key challenges for the sequential decision process is to online generate sequential decision-making policy directly, and transferring knowledge across tasks domain. Most multi-task policy generating algorithms often suffer from insufficient generating cross-task sharing structure at discrete-time nonlinear systems with applications. This paper proposes the multi-task generative adversarial nets with shared memory for cross-domain coordination control, which can generate sequential decision policy directly from raw sensory input of all of tasks, and online evaluate performance of system actions in discrete-time nonlinear systems. Experiments have been undertaken using a professional flexible manufacturing testbed deployed within a smart factory of Weichai Power in China. Results on three groups of discrete-time nonlinear control tasks show that our proposed model can availably improve the performance of task with the help of other related tasks.", "published": "2018-07-01 09:07:04", "link": "http://arxiv.org/abs/1807.00298v1", "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Fast Fourier-Based Generation of the Compression Matrix for Deterministic Compressed Sensing", "abstract": "The primary goal of this work is to review the importance of data compression and present a fast Fourier-based method for generating the deterministic compression matrix in the area of deterministic compressed sensing. The principle concepts of data compression such as general process of data compression, sparse signals, coherence matrix and Restricted Isometry Property (RIP) have been defined. We have introduced two methods of sparse data compression. The first method is formed by utilizing a stochastic matrix which is a common approach, and the second method is created by utilizing a deterministic matrix which is proposed more recently. The main goal of this work is to improve the execution time of the deterministic matrix generation. The execution time is related to the generation method of the deterministic matrix. Furthermore, we have implemented a software which makes it possible to compare different methods of reconstructing data compression. To make this comparison, it is necessary to draw and compare certain graphs, e.g. phase transition, the ratio of output signal to noise and input signal to noise, signal to noise output and also the ratio of percentage of accurate reconstructing and order of sparse signals for various reconstructing methods. To facilitate this process, the user would be able to draw his/her favorite graphs in GUI environment.", "published": "2018-07-01 04:51:35", "link": "http://arxiv.org/abs/1807.01238v1", "categories": ["eess.SP", "cs.CV"], "primary_category": "eess.SP"}
{"title": "Towards Mixed Optimization for Reinforcement Learning with Program Synthesis", "abstract": "Deep reinforcement learning has led to several recent breakthroughs, though the learned policies are often based on black-box neural networks. This makes them difficult to interpret and to impose desired specification constraints during learning. We present an iterative framework, MORL, for improving the learned policies using program synthesis. Concretely, we propose to use synthesis techniques to obtain a symbolic representation of the learned policy, which can then be debugged manually or automatically using program repair. After the repair step, we use behavior cloning to obtain the policy corresponding to the repaired program, which is then further improved using gradient descent. This process continues until the learned policy satisfies desired constraints. We instantiate MORL for the simple CartPole problem and show that the programmatic representation allows for high-level modifications that in turn lead to improved learning of the policies.", "published": "2018-07-01 21:52:07", "link": "http://arxiv.org/abs/1807.00403v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning to Drive in a Day", "abstract": "We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.", "published": "2018-07-01 22:47:08", "link": "http://arxiv.org/abs/1807.00412v2", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "primary_category": "cs.LG"}
