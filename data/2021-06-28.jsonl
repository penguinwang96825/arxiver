{"title": "A Span-Based Model for Joint Overlapped and Discontinuous Named Entity\n  Recognition", "abstract": "Research on overlapped and discontinuous named entity recognition (NER) has\nreceived increasing attention. The majority of previous work focuses on either\noverlapped or discontinuous entities. In this paper, we propose a novel\nspan-based model that can recognize both overlapped and discontinuous entities\njointly. The model includes two major steps. First, entity fragments are\nrecognized by traversing over all possible text spans, thus, overlapped\nentities can be recognized. Second, we perform relation classification to judge\nwhether a given pair of entity fragments to be overlapping or succession. In\nthis way, we can recognize not only discontinuous entities, and meanwhile\ndoubly check the overlapped entities. As a whole, our model can be regarded as\na relation extraction paradigm essentially. Experimental results on multiple\nbenchmark datasets (i.e., CLEF, GENIA and ACE05) show that our model is highly\ncompetitive for overlapped and discontinuous NER.", "published": "2021-06-28 02:37:20", "link": "http://arxiv.org/abs/2106.14373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Dialogue State Tracking by Masked Hierarchical Transformer", "abstract": "This paper describes our approach to DSTC 9 Track 2: Cross-lingual\nMulti-domain Dialog State Tracking, the task goal is to build a Cross-lingual\ndialog state tracker with a training set in rich resource language and a\ntesting set in low resource language. We formulate a method for joint learning\nof slot operation classification task and state tracking task respectively.\nFurthermore, we design a novel mask mechanism for fusing contextual information\nabout dialogue, the results show the proposed model achieves excellent\nperformance on DSTC Challenge II with a joint accuracy of 62.37% and 23.96% in\nMultiWOZ(en - zh) dataset and CrossWOZ(zh - en) dataset, respectively.", "published": "2021-06-28 07:35:49", "link": "http://arxiv.org/abs/2106.14433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Current Landscape of the Russian Sentiment Corpora", "abstract": "Currently, there are more than a dozen Russian-language corpora for sentiment\nanalysis, differing in the source of the texts, domain, size, number and ratio\nof sentiment classes, and annotation method. This work examines publicly\navailable Russian-language corpora, presents their qualitative and quantitative\ncharacteristics, which make it possible to get an idea of the current landscape\nof the corpora for sentiment analysis. The ranking of corpora by annotation\nquality is proposed, which can be useful when choosing corpora for training and\ntesting. The influence of the training dataset on the performance of sentiment\nanalysis is investigated based on the use of the deep neural network model\nBERT. The experiments with review corpora allow us to conclude that on average\nthe quality of models increases with an increase in the number of training\ncorpora. For the first time, quality scores were obtained for the corpus of\nreviews of ROMIP seminars based on the BERT model. Also, the study proposes the\ntask of the building a universal model for sentiment analysis.", "published": "2021-06-28 07:36:09", "link": "http://arxiv.org/abs/2106.14434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Traditional Machine Learning and Deep Learning Models for Argumentation\n  Mining in Russian Texts", "abstract": "Argumentation mining is a field of computational linguistics that is devoted\nto extracting from texts and classifying arguments and relations between them,\nas well as constructing an argumentative structure. A significant obstacle to\nresearch in this area for the Russian language is the lack of annotated\nRussian-language text corpora. This article explores the possibility of\nimproving the quality of argumentation mining using the extension of the\nRussian-language version of the Argumentative Microtext Corpus (ArgMicro) based\non the machine translation of the Persuasive Essays Corpus (PersEssays). To\nmake it possible to use these two corpora combined, we propose a Joint Argument\nAnnotation Scheme based on the schemes used in ArgMicro and PersEssays. We\nsolve the problem of classifying argumentative discourse units (ADUs) into two\nclasses - \"pro\" (\"for\") and \"opp\" (\"against\") using traditional machine\nlearning techniques (SVM, Bagging and XGBoost) and a deep neural network (BERT\nmodel). An ensemble of XGBoost and BERT models was proposed, which showed the\nhighest performance of ADUs classification for both corpora.", "published": "2021-06-28 07:44:43", "link": "http://arxiv.org/abs/2106.14438v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Knowledge-Grounded Dialog System Based on Pre-Trained Language Models", "abstract": "We present a knowledge-grounded dialog system developed for the ninth Dialog\nSystem Technology Challenge (DSTC9) Track 1 - Beyond Domain APIs: Task-oriented\nConversational Modeling with Unstructured Knowledge Access. We leverage\ntransfer learning with existing language models to accomplish the tasks in this\nchallenge track. Specifically, we divided the task into four sub-tasks and\nfine-tuned several Transformer models on each of the sub-tasks. We made\nadditional changes that yielded gains in both performance and efficiency,\nincluding the combination of the model with traditional entity-matching\ntechniques, and the addition of a pointer network to the output layer of the\nlanguage model.", "published": "2021-06-28 07:56:10", "link": "http://arxiv.org/abs/2106.14444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying Social Biases in NLP: A Generalization and Empirical\n  Comparison of Extrinsic Fairness Metrics", "abstract": "Measuring bias is key for better understanding and addressing unfairness in\nNLP/ML models. This is often done via fairness metrics which quantify the\ndifferences in a model's behaviour across a range of demographic groups. In\nthis work, we shed more light on the differences and similarities between the\nfairness metrics used in NLP. First, we unify a broad range of existing metrics\nunder three generalized fairness metrics, revealing the connections between\nthem. Next, we carry out an extensive empirical comparison of existing metrics\nand demonstrate that the observed differences in bias measurement can be\nsystematically explained via differences in parameter choices for our\ngeneralized metrics.", "published": "2021-06-28 11:02:33", "link": "http://arxiv.org/abs/2106.14574v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's in a Measurement? Using GPT-3 on SemEval 2021 Task 8 -- MeasEval", "abstract": "In the summer of 2020 OpenAI released its GPT-3 autoregressive language model\nto much fanfare. While the model has shown promise on tasks in several areas,\nit has not always been clear when the results were cherry-picked or when they\nwere the unvarnished output. We were particularly interested in what benefits\nGPT-3 could bring to the SemEval 2021 MeasEval task - identifying measurements\nand their associated attributes in scientific literature. We had already\nexperimented with multi-turn questions answering as a solution to this task. We\nwanted to see if we could use GPT-3's few-shot learning capabilities to more\neasily develop a solution that would have better performance than our prior\nwork. Unfortunately, we have not been successful in that effort. This paper\ndiscusses the approach we used, challenges we encountered, and results we\nobserved. Some of the problems we encountered were simply due to the state of\nthe art. For example, the limits on the size of the prompt and answer limited\nthe amount of the training signal that could be offered. Others are more\nfundamental. We are unaware of generative models that excel in retaining\nfactual information. Also, the impact of changes in the prompts is\nunpredictable, making it hard to reliably improve performance.", "published": "2021-06-28 13:48:25", "link": "http://arxiv.org/abs/2106.14720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word2Box: Capturing Set-Theoretic Semantics of Words using Box\n  Embeddings", "abstract": "Learning representations of words in a continuous space is perhaps the most\nfundamental task in NLP, however words interact in ways much richer than vector\ndot product similarity can provide. Many relationships between words can be\nexpressed set-theoretically, for example, adjective-noun compounds (eg. \"red\ncars\"$\\subseteq$\"cars\") and homographs (eg. \"tongue\"$\\cap$\"body\" should be\nsimilar to \"mouth\", while \"tongue\"$\\cap$\"language\" should be similar to\n\"dialect\") have natural set-theoretic interpretations. Box embeddings are a\nnovel region-based representation which provide the capability to perform these\nset-theoretic operations. In this work, we provide a fuzzy-set interpretation\nof box embeddings, and learn box representations of words using a set-theoretic\ntraining objective. We demonstrate improved performance on various word\nsimilarity tasks, particularly on less common words, and perform a quantitative\nand qualitative analysis exploring the additional unique expressivity provided\nby Word2Box.", "published": "2021-06-28 01:17:11", "link": "http://arxiv.org/abs/2106.14361v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Political Ideology and Polarization of Policy Positions: A\n  Multi-dimensional Approach", "abstract": "Analyzing ideology and polarization is of critical importance in advancing\nour grasp of modern politics. Recent research has made great strides towards\nunderstanding the ideological bias (i.e., stance) of news media along the\nleft-right spectrum. In this work, we instead take a novel and more nuanced\napproach for the study of ideology based on its left or right positions on the\nissue being discussed. Aligned with the theoretical accounts in political\nscience, we treat ideology as a multi-dimensional construct, and introduce the\nfirst diachronic dataset of news articles whose ideological positions are\nannotated by trained political scientists and linguists at the paragraph level.\nWe showcase that, by controlling for the author's stance, our method allows for\nthe quantitative and temporal measurement and analysis of polarization as a\nmultidimensional ideological distance. We further present baseline models for\nideology prediction, outlining a challenging task distinct from stance\ndetection.", "published": "2021-06-28 04:03:04", "link": "http://arxiv.org/abs/2106.14387v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Enhancing the Generalization for Intent Classification and Out-of-Domain\n  Detection in SLU", "abstract": "Intent classification is a major task in spoken language understanding (SLU).\nSince most models are built with pre-collected in-domain (IND) training\nutterances, their ability to detect unsupported out-of-domain (OOD) utterances\nhas a critical effect in practical use. Recent works have shown that using\nextra data and labels can improve the OOD detection performance, yet it could\nbe costly to collect such data. This paper proposes to train a model with only\nIND data while supporting both IND intent classification and OOD detection. Our\nmethod designs a novel domain-regularized module (DRM) to reduce the\noverconfident phenomenon of a vanilla classifier, achieving a better\ngeneralization in both cases. Besides, DRM can be used as a drop-in replacement\nfor the last layer in any neural network-based intent classifier, providing a\nlow-cost strategy for a significant improvement. The evaluation on four\ndatasets shows that our method built on BERT and RoBERTa models achieves\nstate-of-the-art performance against existing approaches and the strong\nbaselines we created for the comparisons.", "published": "2021-06-28 08:27:38", "link": "http://arxiv.org/abs/2106.14464v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Keyphrase Generation for Scientific Document Retrieval", "abstract": "Sequence-to-sequence models have lead to significant progress in keyphrase\ngeneration, but it remains unknown whether they are reliable enough to be\nbeneficial for document retrieval. This study provides empirical evidence that\nsuch models can significantly improve retrieval performance, and introduces a\nnew extrinsic evaluation framework that allows for a better understanding of\nthe limitations of keyphrase generation models. Using this framework, we point\nout and discuss the difficulties encountered with supplementing documents with\n-- not present in text -- keyphrases, and generalizing models across domains.\nOur code is available at https://github.com/boudinfl/ir-using-kg", "published": "2021-06-28 13:55:49", "link": "http://arxiv.org/abs/2106.14726v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Few Brief Notes on DeepImpact, COIL, and a Conceptual Framework for\n  Information Retrieval Techniques", "abstract": "Recent developments in representational learning for information retrieval\ncan be organized in a conceptual framework that establishes two pairs of\ncontrasts: sparse vs. dense representations and unsupervised vs. learned\nrepresentations. Sparse learned representations can further be decomposed into\nexpansion and term weighting components. This framework allows us to understand\nthe relationship between recently proposed techniques such as DPR, ANCE,\nDeepCT, DeepImpact, and COIL, and furthermore, gaps revealed by our analysis\npoint to \"low hanging fruit\" in terms of techniques that have yet to be\nexplored. We present a novel technique dubbed \"uniCOIL\", a simple extension of\nCOIL that achieves to our knowledge the current state-of-the-art in sparse\nretrieval on the popular MS MARCO passage ranking dataset. Our implementation\nusing the Anserini IR toolkit is built on the Lucene search library and thus\nfully compatible with standard inverted indexes.", "published": "2021-06-28 15:30:42", "link": "http://arxiv.org/abs/2106.14807v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Priority prediction of Asian Hornet sighting report using machine\n  learning methods", "abstract": "As infamous invaders to the North American ecosystem, the Asian giant hornet\n(Vespa mandarinia) is devastating not only to native bee colonies, but also to\nlocal apiculture. One of the most effective way to combat the harmful species\nis to locate and destroy their nests. By mobilizing the public to actively\nreport possible sightings of the Asian giant hornet, the governmentcould timely\nsend inspectors to confirm and possibly destroy the nests. However, such\nconfirmation requires lab expertise, where manually checking the reports one by\none is extremely consuming of human resources. Further given the limited\nknowledge of the public about the Asian giant hornet and the randomness of\nreport submission, only few of the numerous reports proved positive, i.e.\nexisting nests. How to classify or prioritize the reports efficiently and\nautomatically, so as to determine the dispatch of personnel, is of great\nsignificance to the control of the Asian giant hornet. In this paper, we\npropose a method to predict the priority of sighting reports based on machine\nlearning. We model the problem of optimal prioritization of sighting reports as\na problem of classification and prediction. We extracted a variety of rich\nfeatures in the report: location, time, image(s), and textual description.\nBased on these characteristics, we propose a classification model based on\nlogistic regression to predict the credibility of a certain report.\nFurthermore, our model quantifies the impact between reports to get the\npriority ranking of the reports. Extensive experiments on the public dataset\nfrom the WSDA (the Washington State Department of Agriculture) have proved the\neffectiveness of our method.", "published": "2021-06-28 07:33:53", "link": "http://arxiv.org/abs/2107.05465v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Integrating topic modeling and word embedding to characterize violent\n  deaths", "abstract": "There is an escalating need for methods to identify latent patterns in text\ndata from many domains. We introduce a new method to identify topics in a\ncorpus and represent documents as topic sequences. Discourse Atom Topic\nModeling draws on advances in theoretical machine learning to integrate topic\nmodeling and word embedding, capitalizing on the distinct capabilities of each.\nWe first identify a set of vectors (\"discourse atoms\") that provide a sparse\nrepresentation of an embedding space. Atom vectors can be interpreted as latent\ntopics: Through a generative model, atoms map onto distributions over words;\none can also infer the topic that generated a sequence of words. We illustrate\nour method with a prominent example of underutilized text: the U.S. National\nViolent Death Reporting System (NVDRS). The NVDRS summarizes violent death\nincidents with structured variables and unstructured narratives. We identify\n225 latent topics in the narratives (e.g., preparation for death and physical\naggression); many of these topics are not captured by existing structured\nvariables. Motivated by known patterns in suicide and homicide by gender, and\nrecent research on gender biases in semantic space, we identify the gender bias\nof our topics (e.g., a topic about pain medication is feminine). We then\ncompare the gender bias of topics to their prevalence in narratives of female\nversus male victims. Results provide a detailed quantitative picture of\nreporting about lethal violence and its gendered nature. Our method offers a\nflexible and broadly applicable approach to model topics in text data.", "published": "2021-06-28 01:53:20", "link": "http://arxiv.org/abs/2106.14365v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sparsely Overlapped Speech Training in the Time Domain: Joint Learning\n  of Target Speech Separation and Personal VAD Benefits", "abstract": "Target speech separation is the process of filtering a certain speaker's\nvoice out of speech mixtures according to the additional speaker identity\ninformation provided. Recent works have made considerable improvement by\nprocessing signals in the time domain directly. The majority of them take fully\noverlapped speech mixtures for training. However, since most real-life\nconversations occur randomly and are sparsely overlapped, we argue that\ntraining with different overlap ratio data benefits. To do so, an unavoidable\nproblem is that the popularly used SI-SNR loss has no definition for silent\nsources. This paper proposes the weighted SI-SNR loss, together with the joint\nlearning of target speech separation and personal VAD. The weighted SI-SNR loss\nimposes a weight factor that is proportional to the target speaker's duration\nand returns zero when the target speaker is absent. Meanwhile, the personal VAD\ngenerates masks and sets non-target speech to silence. Experiments show that\nour proposed method outperforms the baseline by 1.73 dB in terms of SDR on\nfully overlapped speech, as well as by 4.17 dB and 0.9 dB on sparsely\noverlapped speech of clean and noisy conditions. Besides, with slight\ndegradation in performance, our model could reduce the time costs in inference.", "published": "2021-06-28 02:35:03", "link": "http://arxiv.org/abs/2106.14371v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RadGraph: Extracting Clinical Entities and Relations from Radiology\n  Reports", "abstract": "Extracting structured clinical information from free-text radiology reports\ncan enable the use of radiology report information for a variety of critical\nhealthcare applications. In our work, we present RadGraph, a dataset of\nentities and relations in full-text chest X-ray radiology reports based on a\nnovel information extraction schema we designed to structure radiology reports.\nWe release a development dataset, which contains board-certified radiologist\nannotations for 500 radiology reports from the MIMIC-CXR dataset (14,579\nentities and 10,889 relations), and a test dataset, which contains two\nindependent sets of board-certified radiologist annotations for 100 radiology\nreports split equally across the MIMIC-CXR and CheXpert datasets. Using these\ndatasets, we train and test a deep learning model, RadGraph Benchmark, that\nachieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR\nand CheXpert test sets respectively. Additionally, we release an inference\ndataset, which contains annotations automatically generated by RadGraph\nBenchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4\nmillion relations) and 500 CheXpert reports (13,783 entities and 9,908\nrelations) with mappings to associated chest radiographs. Our freely available\ndataset can facilitate a wide range of research in medical natural language\nprocessing, as well as computer vision and multi-modal learning when linked to\nchest radiographs.", "published": "2021-06-28 08:24:23", "link": "http://arxiv.org/abs/2106.14463v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Overview of BioASQ 2020: The eighth BioASQ challenge on Large-Scale\n  Biomedical Semantic Indexing and Question Answering", "abstract": "In this paper, we present an overview of the eighth edition of the BioASQ\nchallenge, which ran as a lab in the Conference and Labs of the Evaluation\nForum (CLEF) 2020. BioASQ is a series of challenges aiming at the promotion of\nsystems and methodologies for large-scale biomedical semantic indexing and\nquestion answering. To this end, shared tasks are organized yearly since 2012,\nwhere different teams develop systems that compete on the same demanding\nbenchmark datasets that represent the real information needs of experts in the\nbiomedical domain. This year, the challenge has been extended with the\nintroduction of a new task on medical semantic indexing in Spanish. In total,\n34 teams with more than 100 systems participated in the three tasks of the\nchallenge. As in previous years, the results of the evaluation reveal that the\ntop-performing systems managed to outperform the strong baselines, which\nsuggests that state-of-the-art systems keep pushing the frontier of research\nthrough continuous improvements.", "published": "2021-06-28 12:24:17", "link": "http://arxiv.org/abs/2106.14618v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Overview of BioASQ 2021: The ninth BioASQ challenge on Large-Scale\n  Biomedical Semantic Indexing and Question Answering", "abstract": "Advancing the state-of-the-art in large-scale biomedical semantic indexing\nand question answering is the main focus of the BioASQ challenge. BioASQ\norganizes respective tasks where different teams develop systems that are\nevaluated on the same benchmark datasets that represent the real information\nneeds of experts in the biomedical domain. This paper presents an overview of\nthe ninth edition of the BioASQ challenge in the context of the Conference and\nLabs of the Evaluation Forum (CLEF) 2021. In this year, a new question\nanswering task, named Synergy, is introduced to support researchers studying\nthe COVID-19 disease and measure the ability of the participating teams to\ndiscern information while the problem is still developing. In total, 42 teams\nwith more than 170 systems were registered to participate in the four tasks of\nthe challenge. The evaluation results, similarly to previous years, show a\nperformance gain against the baselines which indicates the continuous\nimprovement of the state-of-the-art in this field.", "published": "2021-06-28 10:03:11", "link": "http://arxiv.org/abs/2106.14885v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Mobile Microphone Array Speech Detection and Localization in Diverse\n  Everyday Environments", "abstract": "Joint sound event localization and detection (SELD) is an integral part of\ndeveloping context awareness into communication interfaces of mobile robots,\nsmartphones, and home assistants. For example, an automatic audio focus for\nvideo capture on a mobile phone requires robust detection of relevant acoustic\nevents around the device and their direction. Existing SELD approaches have\nbeen evaluated using material produced in controlled indoor environments, or\nthe audio is simulated by mixing isolated sounds to different spatial\nlocations. This paper studies SELD of speech in diverse everyday environments,\nwhere the audio corresponds to typical usage scenarios of handheld mobile\ndevices. In order to allow weighting the relative importance of localization\nvs. detection, we will propose a two-stage hierarchical system, where the first\nstage is to detect the target events, and the second stage is to localize them.\n  The proposed method utilizes convolutional recurrent neural network (CRNN)\nand is evaluated on a database of manually annotated microphone array\nrecordings from various acoustic conditions. The array is embedded in a\ncontemporary mobile phone form factor. The obtained results show good speech\ndetection and localization accuracy of the proposed method in contrast to a\nnon-hierarchical flat classification model.", "published": "2021-06-28 15:07:48", "link": "http://arxiv.org/abs/2106.14787v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
