{"title": "An Investigation of the Sampling-Based Alignment Method and Its\n  Contributions", "abstract": "By investigating the distribution of phrase pairs in phrase translation\ntables, the work in this paper describes an approach to increase the number of\nn-gram alignments in phrase translation tables output by a sampling-based\nalignment method. This approach consists in enforcing the alignment of n-grams\nin distinct translation subtables so as to increase the number of n-grams.\nStandard normal distribution is used to allot alignment time among translation\nsubtables, which results in adjustment of the distribution of n- grams. This\nleads to better evaluation results on statistical machine translation tasks\nthan the original sampling-based alignment approach. Furthermore, the\ntranslation quality obtained by merging phrase translation tables computed from\nthe sampling-based alignment method and from MGIZA++ is examined.", "published": "2013-08-21 03:44:04", "link": "http://arxiv.org/abs/1308.4479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PACE: Pattern Accurate Computationally Efficient Bootstrapping for\n  Timely Discovery of Cyber-Security Concepts", "abstract": "Public disclosure of important security information, such as knowledge of\nvulnerabilities or exploits, often occurs in blogs, tweets, mailing lists, and\nother online sources months before proper classification into structured\ndatabases. In order to facilitate timely discovery of such knowledge, we\npropose a novel semi-supervised learning algorithm, PACE, for identifying and\nclassifying relevant entities in text sources. The main contribution of this\npaper is an enhancement of the traditional bootstrapping method for entity\nextraction by employing a time-memory trade-off that simultaneously circumvents\na costly corpus search while strengthening pattern nomination, which should\nincrease accuracy. An implementation in the cyber-security domain is discussed\nas well as challenges to Natural Language Processing imposed by the security\ndomain.", "published": "2013-08-21 18:01:42", "link": "http://arxiv.org/abs/1308.4648v3", "categories": ["cs.IR", "cs.CL", "IEEE"], "primary_category": "cs.IR"}
{"title": "A proposal for a Chinese keyboard for cellphones, smartphones, ipads and\n  tablets", "abstract": "In this paper, we investigate the possibility to use two tilings of the\nhyperbolic plane as basic frame for devising a way to input texts in Chinese\ncharacters into messages of cellphones, smartphones, ipads and tablets.", "published": "2013-08-21 17:53:37", "link": "http://arxiv.org/abs/1308.4965v1", "categories": ["cs.HC", "cs.CL", "69U99, 94A99", "H.1.2; H.5.2"], "primary_category": "cs.HC"}
{"title": "Can inferred provenance and its visualisation be used to detect\n  erroneous annotation? A case study using UniProtKB", "abstract": "A constant influx of new data poses a challenge in keeping the annotation in\nbiological databases current. Most biological databases contain significant\nquantities of textual annotation, which often contains the richest source of\nknowledge. Many databases reuse existing knowledge, during the curation process\nannotations are often propagated between entries. However, this is often not\nmade explicit. Therefore, it can be hard, potentially impossible, for a reader\nto identify where an annotation originated from. Within this work we attempt to\nidentify annotation provenance and track its subsequent propagation.\nSpecifically, we exploit annotation reuse within the UniProt Knowledgebase\n(UniProtKB), at the level of individual sentences. We describe a visualisation\napproach for the provenance and propagation of sentences in UniProtKB which\nenables a large-scale statistical analysis. Initially levels of sentence reuse\nwithin UniProtKB were analysed, showing that reuse is heavily prevalent, which\nenables the tracking of provenance and propagation. By analysing sentences\nthroughout UniProtKB, a number of interesting propagation patterns were\nidentified, covering over 100, 000 sentences. Over 8000 sentences remain in the\ndatabase after they have been removed from the entries where they originally\noccurred. Analysing a subset of these sentences suggest that approximately 30%\nare erroneous, whilst 35% appear to be inconsistent. These results suggest that\nbeing able to visualise sentence propagation and provenance can aid in the\ndetermination of the accuracy and quality of textual annotation. Source code\nand supplementary data are available from the authors website.", "published": "2013-08-21 15:49:43", "link": "http://arxiv.org/abs/1308.4618v1", "categories": ["cs.CL", "cs.CE", "cs.DL", "q-bio.QM"], "primary_category": "cs.CL"}
